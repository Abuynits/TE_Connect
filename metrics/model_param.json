{"GAMMA": 0.99, "BATCH_SIZE": 2048, "LEARNING_RATE": 0.005, "EPOCHS": 50, "MODEL_CHOICE": "seq2seq", "LSTM_INP_SIZE": 3, "LSTM_OUT_SIZE": 1, "LSTM_HIDDEN_SIZE": 128, "LSTM_DROPOUT": 0.0, "LSTM_LAYER_COUNT": 2, "SEQ2SEQ_ENCODER_DROPOUT": 0.25, "SEQ2SEQ_DECODER_DROPOUT": 0.25, "SEQ2SEQ_HIDDEN_SIZE": 128, "SEQ2SEQ_DROPOUT": 0.0, "SEQ2SEQ_LAYER_COUNT": 2, "SEQ2SEQ_INPUT_SEQ_LENGTH": 10}