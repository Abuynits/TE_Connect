{"GAMMA": 0.95, "BATCH_SIZE": 2048, "LEARNING_RATE": 0.001, "EPOCHS": 1, "MODEL_CHOICE": "transformer", "LSTM_INP_SIZE": 3, "LSTM_OUT_SIZE": 1, "LSTM_HIDDEN_SIZE": 128, "LSTM_DROPOUT": 0.0, "LSTM_LAYER_COUNT": 2, "SEQ2SEQ_ENCODER_DROPOUT": 0.1, "SEQ2SEQ_DECODER_DROPOUT": 0.1, "SEQ2SEQ_HIDDEN_SIZE": 128, "SEQ2SEQ_DROPOUT": 0.0, "SEQ2SEQ_LAYER_COUNT": 2, "SEQ2SEQ_INPUT_SEQ_LENGTH": 100}