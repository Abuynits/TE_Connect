{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArZ3YFw97Xvw"
      },
      "source": [
        "## TE Connect CNN-LSTM Attempt\n",
        "\n",
        "Author: Alexiy Buynitsky\n",
        "\n",
        "Resources:\n",
        "https://towardsdatascience.com/cnn-lstm-based-models-for-multiple-parallel-input-and-multi-step-forecast-6fe2172f7668\n",
        "\n",
        "https://github.com/lkulowski/LSTM_encoder_decoder\n",
        "\n",
        "https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_lstm_neuralnetwork/\n",
        "\n",
        "TODO:\n",
        "- Add baseline model using running averages as a comparison\n",
        "- Add ways to control all paramters in global classes\n",
        "- add cnn-lstm model\n",
        "- Double check all data is added as training and testing split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVeKEVlh7Xv0"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ySj02QB_7Xv1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from pandas import DataFrame\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optimizer\n",
        "from torchvision import datasets, transforms\n",
        "import random as random\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "w7asRJoE7puG",
        "outputId": "bc45523c-b21a-413a-e02b-0926c3cfed99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arlrfoF87Xv2"
      },
      "source": [
        "## Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zow8tIwX7Xv2",
        "outputId": "8c1e1d77-0611-4c78-f571-942b78701de0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num rows: 522698\n",
            "num cols: 10\n",
            "['E77' '053' '202' 'ABP' 'AC5' '607' 'AC6' '088' 'H98' 'DK4' 'N65' '372'\n",
            " 'FG2' '251' '208' 'F49' 'H90' 'J67' 'J63' '073' '351' '050' 'K70' '301'\n",
            " 'J37' 'A13' 'AQ9' '038' '025' '440' '481' '145' '230' 'K85' 'JB3' '547'\n",
            " '239' '912' '281' '231' 'LT0' '214' 'JF1' 'A28' '567' 'B91' '438' '430'\n",
            " 'K00' 'J89' 'E31' 'Z27' '291' 'Z83' 'G60' '518' '472' 'F52' 'G59' '042'\n",
            " 'N09' '323' '715' 'A05' '072' '397' '957' 'J25' '217' '014' '224' 'G49'\n",
            " '344' '207' 'AP2' '002' '529' '077' 'E82' '835' 'LV4' '728' '890' '032'\n",
            " '757' 'E79' '097' 'Z34' '057' 'F38' 'Z43' 'F83' 'F82' 'G74' 'AG7' '685'\n",
            " '977' '009' 'A92' '712' 'F50' '001' 'JH4' '402' '124' '023' '961' '313'\n",
            " 'G61' 'F48' '056' 'G41' '232' '766' '519' 'J12' '243' 'LV1' '204' 'F41'\n",
            " '450' '516' 'W02' 'Z40' '080' '289' '036' '394' '150' 'JC1' 'J46' 'AH8'\n",
            " '046' 'F40' '716' 'G30' 'B77' 'JJ4' 'C19' 'DA8' 'K80' '327' 'E83' 'F46'\n",
            " '350' 'J45' '748' 'Z77' 'N73' '914' 'JE2' '085' 'JC3' '312' '127' 'J96'\n",
            " '760' '076' 'K18' 'N38' '144' '403' '405' '413' 'F34' 'N05' 'J04' 'JC2'\n",
            " '753' '521' 'G67' '240' '004' '318' 'K21' 'K01' '101' 'LR0' 'Z16' 'K09'\n",
            " 'J35' 'B75' '238' '223' 'G65' '234' '103' '333' '215' '236' '827' '686'\n",
            " '814' 'F24' 'J09' '035' '252' '040' '024' 'Z23' '296' 'G83' 'Z33' '733'\n",
            " 'C89' 'C04' '299' 'K71' 'E25' '584' '399' 'P17' '442' 'AK0' 'J10' '751'\n",
            " 'H95' '398' 'K77' '039' '822' 'A60' '051' '267' '755' 'K78' 'LR5' 'E22'\n",
            " '377' '652' 'Z44' '250' 'J41' '043' 'A09' '979' '311' 'Z35' '956' 'A76'\n",
            " 'G16' 'E32' 'W04' 'N06' '277' '253' '176' '096' 'AI4' 'K48' 'J30' 'F43'\n",
            " 'K86' 'K74' 'N41' '148' '978' 'N99' 'A15' '390' 'F03' 'F44' '364' 'G85'\n",
            " '059' '915' 'AC7' 'JA9' '955' 'Z04' 'B79' '723' '210' 'J21' '237' 'Z45'\n",
            " 'LR2' 'AC9' 'LS0' '984' 'JF9' 'K50' 'J24' 'BV4' '586' '048' '104' 'J42'\n",
            " 'K88' '553' '012' 'JC8' 'C18' 'J93' '749' 'N03' 'DK1' 'Z54' 'N18' 'LV5'\n",
            " 'J14' '003' 'Z75' 'J11' 'Z28' '907' '826' 'JE8' 'F33' 'JF5' 'LV3' 'K73'\n",
            " '750' 'B54' 'B90' 'K24' 'KA8' 'K79' 'Z92' 'H83' '341' 'Z78' 'F14' '517'\n",
            " '815' 'DK6' 'K05' '962' 'Z20' '884' 'K72' 'K13' 'C08' '326' '976' '343'\n",
            " 'H82' '013' 'Z82' 'D51' 'N01' 'K31' 'W83' '022' 'JC5' 'LT1' 'F45' 'A87'\n",
            " '582' 'N02' '244' 'P23' 'F39' 'Z32' 'A94' '902' 'AA1' '913' 'G11' 'JC9'\n",
            " 'A67' 'J71' 'JA1' 'E46' 'KA4' '731' 'Z24' 'K75' 'J83' '100' 'JD8' 'N17'\n",
            " '523' '015' 'J80' 'JB2' 'DJ5' '597' 'Z15' 'J23' '752' '525' 'G31' 'JB9'\n",
            " '034' '953' '973' 'AC8' 'Z81' '152' 'KA5' 'F35' '201' '758' '095' 'J03'\n",
            " 'G12' 'G63' 'Z36' 'E84' 'A50' 'K42' 'JC4' 'JC6' 'DK2' '571' 'J44' 'F25'\n",
            " 'N04' '471' 'E78' 'A52' 'G05' '274' 'DK3' 'A46' '094' 'LR1' 'AJ9' '706'\n",
            " '141' 'JD2' 'Z17' 'KB2' 'A39' '131' 'G06' '588' 'J43' '228' '113' 'E21'\n",
            " 'Z29' '389' 'H96' '257' '526' 'LV7' 'Z72' '583' 'K03' 'JC0' 'H94' '429'\n",
            " 'AI8' 'O34' '960' 'B81' '479' 'JD1' 'Z13' 'A07' 'JE3' '212' 'J97' 'K61'\n",
            " 'A27' '284' 'G50' '746' 'G72' 'N20' 'F89' '213' 'A47' 'JE9' 'JE4' 'K04'\n",
            " 'K97' '573' 'JB6' 'K76' '941' 'Z76' 'K65' 'Z30' 'AG6' 'A01' 'G81' '952'\n",
            " 'DJ6' 'J31' 'DJ4' 'K81' 'JJ9' 'G64' 'G87' 'JK1' 'A20' 'A54' '940' 'AB4'\n",
            " '903' '060' 'LT6' 'LU4' 'LT7' '942' 'LV6' 'O27' 'AK1' 'JJ5' 'A64' 'AI7'\n",
            " '945' 'A55' 'J8A' 'AM4' 'P40' 'D49' 'AL8' 'AA3' 'AM0' 'AL6' 'AL9' 'AL0'\n",
            " 'V45' '125' 'Z26' 'A63' '061' 'AP6' 'AM5' 'AD1' 'ABT' 'ABN' 'ABW' 'ABU'\n",
            " 'ABR' 'ABO' 'ABY' 'ABX' 'ABS' 'B55' '062' 'Z39']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   fiscal_year_historical  fiscal_quarter_historical  fiscal_month_historical  \\\n",
              "0                    2015                          1                        1   \n",
              "1                    2015                          1                        1   \n",
              "2                    2015                          1                        1   \n",
              "3                    2015                          1                        1   \n",
              "4                    2015                          1                        1   \n",
              "5                    2015                          1                        1   \n",
              "6                    2015                          1                        1   \n",
              "7                    2015                          1                        1   \n",
              "8                    2015                          1                        1   \n",
              "9                    2015                          1                        1   \n",
              "\n",
              "   fiscal_week_historical              business_unit_group_name  \\\n",
              "0                       1                                Energy   \n",
              "1                       1            Channel - Data and Devices   \n",
              "2                       1                  Channel - Industrial   \n",
              "3                       1                            Industrial   \n",
              "4                       1                      Data and Devices   \n",
              "5                       1                            Appliances   \n",
              "6                       1                      Data and Devices   \n",
              "7                       1           Aerospace, Defense & Marine   \n",
              "8                       1  Industrial Commercial Transportation   \n",
              "9                       1                            Industrial   \n",
              "\n",
              "  company_region_name_level_1 product_line_code         product_line_name  \\\n",
              "0                        EMEA               E77     LV/MV Surge Arresters   \n",
              "1          Asia Pacific & ANZ               053            Memory Sockets   \n",
              "2                        EMEA               202     PLASTI-GRIP Terminals   \n",
              "3                    Americas               ABP  Specific terminal blocks   \n",
              "4                        EMEA               AC5   Antennas, Custom Others   \n",
              "5                        EMEA               607    DW-All Other Dual Wall   \n",
              "6                        EMEA               AC6        Antennas, Standard   \n",
              "7                    Americas               088         G Series Products   \n",
              "8                    Americas               H98                       DTP   \n",
              "9                        EMEA               DK4        Signal Proprietary   \n",
              "\n",
              "   sales_quantity  sales_amount  year_week_ordered      Price  \n",
              "0         1641.00     126789.47             201501  77.263541  \n",
              "1        14417.92      17379.52             201501   1.205411  \n",
              "2       142820.40      19666.38             201501   0.137700  \n",
              "3        14528.00     -12089.77             201501  -0.832170  \n",
              "4        34400.00      30357.47             201501   0.882485  \n",
              "5       201134.00      99060.41             201501   0.492510  \n",
              "6         1020.00      14178.82             201501  13.900804  \n",
              "7        22403.00     -11833.37             201501  -0.528205  \n",
              "8        95563.00      82885.19             201501   0.867336  \n",
              "9         1894.00      16306.23             201501   8.609414  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c86343f-8cb2-40ab-b1ce-729a3595a5c1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fiscal_year_historical</th>\n",
              "      <th>fiscal_quarter_historical</th>\n",
              "      <th>fiscal_month_historical</th>\n",
              "      <th>fiscal_week_historical</th>\n",
              "      <th>business_unit_group_name</th>\n",
              "      <th>company_region_name_level_1</th>\n",
              "      <th>product_line_code</th>\n",
              "      <th>product_line_name</th>\n",
              "      <th>sales_quantity</th>\n",
              "      <th>sales_amount</th>\n",
              "      <th>year_week_ordered</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Energy</td>\n",
              "      <td>EMEA</td>\n",
              "      <td>E77</td>\n",
              "      <td>LV/MV Surge Arresters</td>\n",
              "      <td>1641.00</td>\n",
              "      <td>126789.47</td>\n",
              "      <td>201501</td>\n",
              "      <td>77.263541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Channel - Data and Devices</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>053</td>\n",
              "      <td>Memory Sockets</td>\n",
              "      <td>14417.92</td>\n",
              "      <td>17379.52</td>\n",
              "      <td>201501</td>\n",
              "      <td>1.205411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>EMEA</td>\n",
              "      <td>202</td>\n",
              "      <td>PLASTI-GRIP Terminals</td>\n",
              "      <td>142820.40</td>\n",
              "      <td>19666.38</td>\n",
              "      <td>201501</td>\n",
              "      <td>0.137700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>ABP</td>\n",
              "      <td>Specific terminal blocks</td>\n",
              "      <td>14528.00</td>\n",
              "      <td>-12089.77</td>\n",
              "      <td>201501</td>\n",
              "      <td>-0.832170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Data and Devices</td>\n",
              "      <td>EMEA</td>\n",
              "      <td>AC5</td>\n",
              "      <td>Antennas, Custom Others</td>\n",
              "      <td>34400.00</td>\n",
              "      <td>30357.47</td>\n",
              "      <td>201501</td>\n",
              "      <td>0.882485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Appliances</td>\n",
              "      <td>EMEA</td>\n",
              "      <td>607</td>\n",
              "      <td>DW-All Other Dual Wall</td>\n",
              "      <td>201134.00</td>\n",
              "      <td>99060.41</td>\n",
              "      <td>201501</td>\n",
              "      <td>0.492510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Data and Devices</td>\n",
              "      <td>EMEA</td>\n",
              "      <td>AC6</td>\n",
              "      <td>Antennas, Standard</td>\n",
              "      <td>1020.00</td>\n",
              "      <td>14178.82</td>\n",
              "      <td>201501</td>\n",
              "      <td>13.900804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Aerospace, Defense &amp; Marine</td>\n",
              "      <td>Americas</td>\n",
              "      <td>088</td>\n",
              "      <td>G Series Products</td>\n",
              "      <td>22403.00</td>\n",
              "      <td>-11833.37</td>\n",
              "      <td>201501</td>\n",
              "      <td>-0.528205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Industrial Commercial Transportation</td>\n",
              "      <td>Americas</td>\n",
              "      <td>H98</td>\n",
              "      <td>DTP</td>\n",
              "      <td>95563.00</td>\n",
              "      <td>82885.19</td>\n",
              "      <td>201501</td>\n",
              "      <td>0.867336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>EMEA</td>\n",
              "      <td>DK4</td>\n",
              "      <td>Signal Proprietary</td>\n",
              "      <td>1894.00</td>\n",
              "      <td>16306.23</td>\n",
              "      <td>201501</td>\n",
              "      <td>8.609414</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c86343f-8cb2-40ab-b1ce-729a3595a5c1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c86343f-8cb2-40ab-b1ce-729a3595a5c1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c86343f-8cb2-40ab-b1ce-729a3595a5c1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/te_ai_cup_sales_forecasting_data.csv\")\n",
        "print(\"num rows:\", len(df))\n",
        "print(\"num cols:\", df.shape[1])\n",
        "df[\"year_week_ordered\"] = df['fiscal_year_historical']*100 + \\\n",
        "    df['fiscal_week_historical']\n",
        "df.sort_values(by=['fiscal_year_historical'] +\n",
        "               ['fiscal_week_historical'], inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "u_prod_code = df[\"product_line_code\"].unique()\n",
        "print(u_prod_code)\n",
        "df[\"Price\"] = df[\"sales_amount\"]/df[\"sales_quantity\"]\n",
        "display(df.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6GPpk1F7Xv4"
      },
      "source": [
        "## Splitting the Data based on Specific Paramters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MSuCzd_w7Xv4",
        "outputId": "d6c59c7b-c1b6-40f3-c929-4f8304b5fd06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   fiscal_year_historical  fiscal_quarter_historical  fiscal_month_historical  \\\n",
              "0                    2015                          1                        1   \n",
              "1                    2015                          1                        1   \n",
              "2                    2015                          1                        1   \n",
              "3                    2015                          1                        1   \n",
              "4                    2015                          1                        1   \n",
              "5                    2015                          1                        1   \n",
              "6                    2015                          1                        1   \n",
              "7                    2015                          1                        1   \n",
              "8                    2015                          1                        1   \n",
              "9                    2015                          1                        1   \n",
              "\n",
              "   fiscal_week_historical              business_unit_group_name  \\\n",
              "0                       1                                Energy   \n",
              "1                       1            Channel - Data and Devices   \n",
              "2                       1                  Channel - Industrial   \n",
              "3                       1                            Industrial   \n",
              "4                       1                      Data and Devices   \n",
              "5                       1                            Appliances   \n",
              "6                       1                      Data and Devices   \n",
              "7                       1           Aerospace, Defense & Marine   \n",
              "8                       1  Industrial Commercial Transportation   \n",
              "9                       1                            Industrial   \n",
              "\n",
              "  company_region_name_level_1 product_line_code         product_line_name  \\\n",
              "0                        EMEA               E77     LV/MV Surge Arresters   \n",
              "1          Asia Pacific & ANZ               053            Memory Sockets   \n",
              "2                        EMEA               202     PLASTI-GRIP Terminals   \n",
              "3                    Americas               ABP  Specific terminal blocks   \n",
              "4                        EMEA               AC5   Antennas, Custom Others   \n",
              "5                        EMEA               607    DW-All Other Dual Wall   \n",
              "6                        EMEA               AC6        Antennas, Standard   \n",
              "7                    Americas               088         G Series Products   \n",
              "8                    Americas               H98                       DTP   \n",
              "9                        EMEA               DK4        Signal Proprietary   \n",
              "\n",
              "   sales_quantity  sales_amount  year_week_ordered      Price  \n",
              "0         1641.00     126789.47             201501  77.263541  \n",
              "1        14417.92      17379.52             201501   1.205411  \n",
              "2       142820.40      19666.38             201501   0.137700  \n",
              "3        14528.00     -12089.77             201501  -0.832170  \n",
              "4        34400.00      30357.47             201501   0.882485  \n",
              "5       201134.00      99060.41             201501   0.492510  \n",
              "6         1020.00      14178.82             201501  13.900804  \n",
              "7        22403.00     -11833.37             201501  -0.528205  \n",
              "8        95563.00      82885.19             201501   0.867336  \n",
              "9         1894.00      16306.23             201501   8.609414  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5e0875b-e1cf-4a63-a53c-8bf19af8f73a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fiscal_year_historical</th>\n",
              "      <th>fiscal_quarter_historical</th>\n",
              "      <th>fiscal_month_historical</th>\n",
              "      <th>fiscal_week_historical</th>\n",
              "      <th>business_unit_group_name</th>\n",
              "      <th>company_region_name_level_1</th>\n",
              "      <th>product_line_code</th>\n",
              "      <th>product_line_name</th>\n",
              "      <th>sales_quantity</th>\n",
              "      <th>sales_amount</th>\n",
              "      <th>year_week_ordered</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Energy</td>\n",
              "      <td>EMEA</td>\n",
              "      <td>E77</td>\n",
              "      <td>LV/MV Surge Arresters</td>\n",
              "      <td>1641.00</td>\n",
              "      <td>126789.47</td>\n",
              "      <td>201501</td>\n",
              "      <td>77.263541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Channel - Data and Devices</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>053</td>\n",
              "      <td>Memory Sockets</td>\n",
              "      <td>14417.92</td>\n",
              "      <td>17379.52</td>\n",
              "      <td>201501</td>\n",
              "      <td>1.205411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>EMEA</td>\n",
              "      <td>202</td>\n",
              "      <td>PLASTI-GRIP Terminals</td>\n",
              "      <td>142820.40</td>\n",
              "      <td>19666.38</td>\n",
              "      <td>201501</td>\n",
              "      <td>0.137700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>ABP</td>\n",
              "      <td>Specific terminal blocks</td>\n",
              "      <td>14528.00</td>\n",
              "      <td>-12089.77</td>\n",
              "      <td>201501</td>\n",
              "      <td>-0.832170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Data and Devices</td>\n",
              "      <td>EMEA</td>\n",
              "      <td>AC5</td>\n",
              "      <td>Antennas, Custom Others</td>\n",
              "      <td>34400.00</td>\n",
              "      <td>30357.47</td>\n",
              "      <td>201501</td>\n",
              "      <td>0.882485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Appliances</td>\n",
              "      <td>EMEA</td>\n",
              "      <td>607</td>\n",
              "      <td>DW-All Other Dual Wall</td>\n",
              "      <td>201134.00</td>\n",
              "      <td>99060.41</td>\n",
              "      <td>201501</td>\n",
              "      <td>0.492510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Data and Devices</td>\n",
              "      <td>EMEA</td>\n",
              "      <td>AC6</td>\n",
              "      <td>Antennas, Standard</td>\n",
              "      <td>1020.00</td>\n",
              "      <td>14178.82</td>\n",
              "      <td>201501</td>\n",
              "      <td>13.900804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Aerospace, Defense &amp; Marine</td>\n",
              "      <td>Americas</td>\n",
              "      <td>088</td>\n",
              "      <td>G Series Products</td>\n",
              "      <td>22403.00</td>\n",
              "      <td>-11833.37</td>\n",
              "      <td>201501</td>\n",
              "      <td>-0.528205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Industrial Commercial Transportation</td>\n",
              "      <td>Americas</td>\n",
              "      <td>H98</td>\n",
              "      <td>DTP</td>\n",
              "      <td>95563.00</td>\n",
              "      <td>82885.19</td>\n",
              "      <td>201501</td>\n",
              "      <td>0.867336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>EMEA</td>\n",
              "      <td>DK4</td>\n",
              "      <td>Signal Proprietary</td>\n",
              "      <td>1894.00</td>\n",
              "      <td>16306.23</td>\n",
              "      <td>201501</td>\n",
              "      <td>8.609414</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5e0875b-e1cf-4a63-a53c-8bf19af8f73a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5e0875b-e1cf-4a63-a53c-8bf19af8f73a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5e0875b-e1cf-4a63-a53c-8bf19af8f73a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def get_raw_data(filtered_df, business_unit_group_name=None, company_region_name_level1=None, product_line_code=None):\n",
        "    if business_unit_group_name is not None:\n",
        "        filtered_df = filtered_df[filtered_df['business_unit_group_name']\n",
        "                                  == business_unit_group_name]\n",
        "    if company_region_name_level1 is not None:\n",
        "        filtered_df = filtered_df[filtered_df['company_region_name_level_1']\n",
        "                                  == company_region_name_level1]\n",
        "    if product_line_code is not None:\n",
        "        filtered_df = filtered_df[filtered_df['product_line_code']\n",
        "                                  == product_line_code]\n",
        "\n",
        "    if len(filtered_df) == 0:\n",
        "        raise Exception(\"ERROR: empty dataset\")\n",
        "    return filtered_df\n",
        "\n",
        "# raw_df = get_raw_data(df,company_region_name_level1= \"EMEA\")\n",
        "raw_df = get_raw_data(df)\n",
        "display(raw_df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u53Pbbds7Xv5"
      },
      "outputs": [],
      "source": [
        "def group_by_unique(local_df, product_line=False, business_unit=False, company_region=False):\n",
        "\n",
        "    group_by_list = []\n",
        "    if (product_line):\n",
        "        group_by_list.append(\"product_line_code\")\n",
        "    if (company_region):\n",
        "        group_by_list.append(\"company_region_name_level_1\")\n",
        "    if (business_unit):\n",
        "        group_by_list.append(\"business_unit_group_name\")\n",
        "    grouped_df = local_df.groupby(group_by_list)\n",
        "    print(len(grouped_df))\n",
        "    return grouped_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l9B5p5Nk7Xv6",
        "outputId": "4fc28b77-5a41-4990-9460-f2f8b64dc2f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1339\n",
            "('001', 'Asia Pacific & ANZ', 'Channel - Industrial')\n",
            "418\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       fiscal_year_historical  fiscal_quarter_historical  \\\n",
              "108                      2015                          1   \n",
              "1299                     2015                          1   \n",
              "2484                     2015                          1   \n",
              "3699                     2015                          1   \n",
              "5763                     2015                          1   \n",
              "6981                     2015                          1   \n",
              "8179                     2015                          1   \n",
              "9390                     2015                          1   \n",
              "10605                    2015                          1   \n",
              "10902                    2015                          1   \n",
              "\n",
              "       fiscal_month_historical  fiscal_week_historical  \\\n",
              "108                          1                       1   \n",
              "1299                         1                       2   \n",
              "2484                         1                       3   \n",
              "3699                         1                       4   \n",
              "5763                         2                       5   \n",
              "6981                         2                       6   \n",
              "8179                         2                       7   \n",
              "9390                         2                       8   \n",
              "10605                        2                       9   \n",
              "10902                        3                      10   \n",
              "\n",
              "      business_unit_group_name company_region_name_level_1 product_line_code  \\\n",
              "108       Channel - Industrial          Asia Pacific & ANZ               001   \n",
              "1299      Channel - Industrial          Asia Pacific & ANZ               001   \n",
              "2484      Channel - Industrial          Asia Pacific & ANZ               001   \n",
              "3699      Channel - Industrial          Asia Pacific & ANZ               001   \n",
              "5763      Channel - Industrial          Asia Pacific & ANZ               001   \n",
              "6981      Channel - Industrial          Asia Pacific & ANZ               001   \n",
              "8179      Channel - Industrial          Asia Pacific & ANZ               001   \n",
              "9390      Channel - Industrial          Asia Pacific & ANZ               001   \n",
              "10605     Channel - Industrial          Asia Pacific & ANZ               001   \n",
              "10902     Channel - Industrial          Asia Pacific & ANZ               001   \n",
              "\n",
              "           product_line_name  sales_quantity  sales_amount  year_week_ordered  \\\n",
              "108    Miscellaneous AMPMODU       305278.80      33869.70             201501   \n",
              "1299   Miscellaneous AMPMODU       396862.44      44030.61             201502   \n",
              "2484   Miscellaneous AMPMODU       396862.44      44030.61             201503   \n",
              "3699   Miscellaneous AMPMODU       427390.32      47417.58             201504   \n",
              "5763   Miscellaneous AMPMODU       317301.14      43076.34             201505   \n",
              "6981   Miscellaneous AMPMODU       367401.32      49877.86             201506   \n",
              "8179   Miscellaneous AMPMODU       334001.20      45343.51             201507   \n",
              "9390   Miscellaneous AMPMODU       334001.20      45343.51             201508   \n",
              "10605  Miscellaneous AMPMODU       317301.14      43076.34             201509   \n",
              "10902  Miscellaneous AMPMODU       152336.00      35769.20             201510   \n",
              "\n",
              "          Price  \n",
              "108    0.110947  \n",
              "1299   0.110947  \n",
              "2484   0.110947  \n",
              "3699   0.110947  \n",
              "5763   0.135759  \n",
              "6981   0.135759  \n",
              "8179   0.135759  \n",
              "9390   0.135759  \n",
              "10605  0.135759  \n",
              "10902  0.234805  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f555964-1e9e-4b08-ae2f-0a16176739b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fiscal_year_historical</th>\n",
              "      <th>fiscal_quarter_historical</th>\n",
              "      <th>fiscal_month_historical</th>\n",
              "      <th>fiscal_week_historical</th>\n",
              "      <th>business_unit_group_name</th>\n",
              "      <th>company_region_name_level_1</th>\n",
              "      <th>product_line_code</th>\n",
              "      <th>product_line_name</th>\n",
              "      <th>sales_quantity</th>\n",
              "      <th>sales_amount</th>\n",
              "      <th>year_week_ordered</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>305278.80</td>\n",
              "      <td>33869.70</td>\n",
              "      <td>201501</td>\n",
              "      <td>0.110947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1299</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>396862.44</td>\n",
              "      <td>44030.61</td>\n",
              "      <td>201502</td>\n",
              "      <td>0.110947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2484</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>396862.44</td>\n",
              "      <td>44030.61</td>\n",
              "      <td>201503</td>\n",
              "      <td>0.110947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3699</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>427390.32</td>\n",
              "      <td>47417.58</td>\n",
              "      <td>201504</td>\n",
              "      <td>0.110947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5763</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>317301.14</td>\n",
              "      <td>43076.34</td>\n",
              "      <td>201505</td>\n",
              "      <td>0.135759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6981</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>367401.32</td>\n",
              "      <td>49877.86</td>\n",
              "      <td>201506</td>\n",
              "      <td>0.135759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8179</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>334001.20</td>\n",
              "      <td>45343.51</td>\n",
              "      <td>201507</td>\n",
              "      <td>0.135759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9390</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>334001.20</td>\n",
              "      <td>45343.51</td>\n",
              "      <td>201508</td>\n",
              "      <td>0.135759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10605</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>317301.14</td>\n",
              "      <td>43076.34</td>\n",
              "      <td>201509</td>\n",
              "      <td>0.135759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10902</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>152336.00</td>\n",
              "      <td>35769.20</td>\n",
              "      <td>201510</td>\n",
              "      <td>0.234805</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f555964-1e9e-4b08-ae2f-0a16176739b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f555964-1e9e-4b08-ae2f-0a16176739b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f555964-1e9e-4b08-ae2f-0a16176739b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('001', 'Asia Pacific & ANZ', 'Industrial')\n",
            "415\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       fiscal_year_historical  fiscal_quarter_historical  \\\n",
              "1043                     2015                          1   \n",
              "2258                     2015                          1   \n",
              "3515                     2015                          1   \n",
              "4608                     2015                          1   \n",
              "5090                     2015                          1   \n",
              "6667                     2015                          1   \n",
              "7636                     2015                          1   \n",
              "8485                     2015                          1   \n",
              "10715                    2015                          1   \n",
              "11456                    2015                          1   \n",
              "\n",
              "       fiscal_month_historical  fiscal_week_historical  \\\n",
              "1043                         1                       1   \n",
              "2258                         1                       2   \n",
              "3515                         1                       3   \n",
              "4608                         1                       4   \n",
              "5090                         2                       5   \n",
              "6667                         2                       6   \n",
              "7636                         2                       7   \n",
              "8485                         2                       8   \n",
              "10715                        2                       9   \n",
              "11456                        3                      10   \n",
              "\n",
              "      business_unit_group_name company_region_name_level_1 product_line_code  \\\n",
              "1043                Industrial          Asia Pacific & ANZ               001   \n",
              "2258                Industrial          Asia Pacific & ANZ               001   \n",
              "3515                Industrial          Asia Pacific & ANZ               001   \n",
              "4608                Industrial          Asia Pacific & ANZ               001   \n",
              "5090                Industrial          Asia Pacific & ANZ               001   \n",
              "6667                Industrial          Asia Pacific & ANZ               001   \n",
              "7636                Industrial          Asia Pacific & ANZ               001   \n",
              "8485                Industrial          Asia Pacific & ANZ               001   \n",
              "10715               Industrial          Asia Pacific & ANZ               001   \n",
              "11456               Industrial          Asia Pacific & ANZ               001   \n",
              "\n",
              "           product_line_name  sales_quantity  sales_amount  year_week_ordered  \\\n",
              "1043   Miscellaneous AMPMODU        513152.0      76599.06             201501   \n",
              "2258   Miscellaneous AMPMODU        179474.0      30120.36             201502   \n",
              "3515   Miscellaneous AMPMODU        473700.0      42911.32             201503   \n",
              "4608   Miscellaneous AMPMODU        331975.0      17220.96             201504   \n",
              "5090   Miscellaneous AMPMODU        515725.0      55527.06             201505   \n",
              "6667   Miscellaneous AMPMODU        265937.0      74272.87             201506   \n",
              "7636   Miscellaneous AMPMODU        399465.0      96394.33             201507   \n",
              "8485   Miscellaneous AMPMODU        713300.0      52651.69             201508   \n",
              "10715  Miscellaneous AMPMODU         94396.0      46691.94             201509   \n",
              "11456  Miscellaneous AMPMODU        156210.0      63392.99             201510   \n",
              "\n",
              "          Price  \n",
              "1043   0.149272  \n",
              "2258   0.167826  \n",
              "3515   0.090588  \n",
              "4608   0.051874  \n",
              "5090   0.107668  \n",
              "6667   0.279287  \n",
              "7636   0.241309  \n",
              "8485   0.073814  \n",
              "10715  0.494639  \n",
              "11456  0.405819  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-933199bb-2525-4616-83bb-f2fd42821873\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fiscal_year_historical</th>\n",
              "      <th>fiscal_quarter_historical</th>\n",
              "      <th>fiscal_month_historical</th>\n",
              "      <th>fiscal_week_historical</th>\n",
              "      <th>business_unit_group_name</th>\n",
              "      <th>company_region_name_level_1</th>\n",
              "      <th>product_line_code</th>\n",
              "      <th>product_line_name</th>\n",
              "      <th>sales_quantity</th>\n",
              "      <th>sales_amount</th>\n",
              "      <th>year_week_ordered</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1043</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>513152.0</td>\n",
              "      <td>76599.06</td>\n",
              "      <td>201501</td>\n",
              "      <td>0.149272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2258</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>179474.0</td>\n",
              "      <td>30120.36</td>\n",
              "      <td>201502</td>\n",
              "      <td>0.167826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3515</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>473700.0</td>\n",
              "      <td>42911.32</td>\n",
              "      <td>201503</td>\n",
              "      <td>0.090588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4608</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>331975.0</td>\n",
              "      <td>17220.96</td>\n",
              "      <td>201504</td>\n",
              "      <td>0.051874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5090</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>515725.0</td>\n",
              "      <td>55527.06</td>\n",
              "      <td>201505</td>\n",
              "      <td>0.107668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6667</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>265937.0</td>\n",
              "      <td>74272.87</td>\n",
              "      <td>201506</td>\n",
              "      <td>0.279287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7636</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>399465.0</td>\n",
              "      <td>96394.33</td>\n",
              "      <td>201507</td>\n",
              "      <td>0.241309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8485</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>713300.0</td>\n",
              "      <td>52651.69</td>\n",
              "      <td>201508</td>\n",
              "      <td>0.073814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10715</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>94396.0</td>\n",
              "      <td>46691.94</td>\n",
              "      <td>201509</td>\n",
              "      <td>0.494639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11456</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>156210.0</td>\n",
              "      <td>63392.99</td>\n",
              "      <td>201510</td>\n",
              "      <td>0.405819</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-933199bb-2525-4616-83bb-f2fd42821873')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-933199bb-2525-4616-83bb-f2fd42821873 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-933199bb-2525-4616-83bb-f2fd42821873');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('002', 'Americas', 'Channel - Industrial')\n",
            "418\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       fiscal_year_historical  fiscal_quarter_historical  \\\n",
              "696                      2015                          1   \n",
              "1894                     2015                          1   \n",
              "3117                     2015                          1   \n",
              "4288                     2015                          1   \n",
              "5765                     2015                          1   \n",
              "6983                     2015                          1   \n",
              "8181                     2015                          1   \n",
              "9392                     2015                          1   \n",
              "10607                    2015                          1   \n",
              "11890                    2015                          1   \n",
              "\n",
              "       fiscal_month_historical  fiscal_week_historical  \\\n",
              "696                          1                       1   \n",
              "1894                         1                       2   \n",
              "3117                         1                       3   \n",
              "4288                         1                       4   \n",
              "5765                         2                       5   \n",
              "6983                         2                       6   \n",
              "8181                         2                       7   \n",
              "9392                         2                       8   \n",
              "10607                        2                       9   \n",
              "11890                        3                      10   \n",
              "\n",
              "      business_unit_group_name company_region_name_level_1 product_line_code  \\\n",
              "696       Channel - Industrial                    Americas               002   \n",
              "1894      Channel - Industrial                    Americas               002   \n",
              "3117      Channel - Industrial                    Americas               002   \n",
              "4288      Channel - Industrial                    Americas               002   \n",
              "5765      Channel - Industrial                    Americas               002   \n",
              "6983      Channel - Industrial                    Americas               002   \n",
              "8181      Channel - Industrial                    Americas               002   \n",
              "9392      Channel - Industrial                    Americas               002   \n",
              "10607     Channel - Industrial                    Americas               002   \n",
              "11890     Channel - Industrial                    Americas               002   \n",
              "\n",
              "       product_line_name  sales_quantity  sales_amount  year_week_ordered  \\\n",
              "696    AMPMODU System 50        17098.00      30641.84             201501   \n",
              "1894   AMPMODU System 50        22227.40      39834.40             201502   \n",
              "3117   AMPMODU System 50        22227.40      39834.40             201503   \n",
              "4288   AMPMODU System 50        23937.20      42898.58             201504   \n",
              "5765   AMPMODU System 50        18016.37      36681.44             201505   \n",
              "6983   AMPMODU System 50        20861.06      42473.25             201506   \n",
              "8181   AMPMODU System 50        18964.60      38612.04             201507   \n",
              "9392   AMPMODU System 50        18964.60      38612.04             201508   \n",
              "10607  AMPMODU System 50        18016.37      36681.44             201509   \n",
              "11890  AMPMODU System 50        24050.75      42878.82             201510   \n",
              "\n",
              "          Price  \n",
              "696    1.792130  \n",
              "1894   1.792130  \n",
              "3117   1.792130  \n",
              "4288   1.792130  \n",
              "5765   2.036006  \n",
              "6983   2.036006  \n",
              "8181   2.036006  \n",
              "9392   2.036006  \n",
              "10607  2.036006  \n",
              "11890  1.782848  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a870ed4b-0556-4dcd-b825-5938c06087d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fiscal_year_historical</th>\n",
              "      <th>fiscal_quarter_historical</th>\n",
              "      <th>fiscal_month_historical</th>\n",
              "      <th>fiscal_week_historical</th>\n",
              "      <th>business_unit_group_name</th>\n",
              "      <th>company_region_name_level_1</th>\n",
              "      <th>product_line_code</th>\n",
              "      <th>product_line_name</th>\n",
              "      <th>sales_quantity</th>\n",
              "      <th>sales_amount</th>\n",
              "      <th>year_week_ordered</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>17098.00</td>\n",
              "      <td>30641.84</td>\n",
              "      <td>201501</td>\n",
              "      <td>1.792130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1894</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>22227.40</td>\n",
              "      <td>39834.40</td>\n",
              "      <td>201502</td>\n",
              "      <td>1.792130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3117</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>22227.40</td>\n",
              "      <td>39834.40</td>\n",
              "      <td>201503</td>\n",
              "      <td>1.792130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4288</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>23937.20</td>\n",
              "      <td>42898.58</td>\n",
              "      <td>201504</td>\n",
              "      <td>1.792130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5765</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>18016.37</td>\n",
              "      <td>36681.44</td>\n",
              "      <td>201505</td>\n",
              "      <td>2.036006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6983</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>20861.06</td>\n",
              "      <td>42473.25</td>\n",
              "      <td>201506</td>\n",
              "      <td>2.036006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8181</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>18964.60</td>\n",
              "      <td>38612.04</td>\n",
              "      <td>201507</td>\n",
              "      <td>2.036006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9392</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>18964.60</td>\n",
              "      <td>38612.04</td>\n",
              "      <td>201508</td>\n",
              "      <td>2.036006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10607</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>18016.37</td>\n",
              "      <td>36681.44</td>\n",
              "      <td>201509</td>\n",
              "      <td>2.036006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11890</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>24050.75</td>\n",
              "      <td>42878.82</td>\n",
              "      <td>201510</td>\n",
              "      <td>1.782848</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a870ed4b-0556-4dcd-b825-5938c06087d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a870ed4b-0556-4dcd-b825-5938c06087d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a870ed4b-0556-4dcd-b825-5938c06087d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('002', 'Americas', 'Industrial')\n",
            "418\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       fiscal_year_historical  fiscal_quarter_historical  \\\n",
              "176                      2015                          1   \n",
              "1679                     2015                          1   \n",
              "3127                     2015                          1   \n",
              "4002                     2015                          1   \n",
              "5857                     2015                          1   \n",
              "6518                     2015                          1   \n",
              "8112                     2015                          1   \n",
              "8956                     2015                          1   \n",
              "10581                    2015                          1   \n",
              "11004                    2015                          1   \n",
              "\n",
              "       fiscal_month_historical  fiscal_week_historical  \\\n",
              "176                          1                       1   \n",
              "1679                         1                       2   \n",
              "3127                         1                       3   \n",
              "4002                         1                       4   \n",
              "5857                         2                       5   \n",
              "6518                         2                       6   \n",
              "8112                         2                       7   \n",
              "8956                         2                       8   \n",
              "10581                        2                       9   \n",
              "11004                        3                      10   \n",
              "\n",
              "      business_unit_group_name company_region_name_level_1 product_line_code  \\\n",
              "176                 Industrial                    Americas               002   \n",
              "1679                Industrial                    Americas               002   \n",
              "3127                Industrial                    Americas               002   \n",
              "4002                Industrial                    Americas               002   \n",
              "5857                Industrial                    Americas               002   \n",
              "6518                Industrial                    Americas               002   \n",
              "8112                Industrial                    Americas               002   \n",
              "8956                Industrial                    Americas               002   \n",
              "10581               Industrial                    Americas               002   \n",
              "11004               Industrial                    Americas               002   \n",
              "\n",
              "       product_line_name  sales_quantity  sales_amount  year_week_ordered  \\\n",
              "176    AMPMODU System 50         38784.0      48835.78             201501   \n",
              "1679   AMPMODU System 50         60028.0      80518.56             201502   \n",
              "3127   AMPMODU System 50         28550.0      38572.70             201503   \n",
              "4002   AMPMODU System 50         52851.0      71123.96             201504   \n",
              "5857   AMPMODU System 50         40697.0      41301.96             201505   \n",
              "6518   AMPMODU System 50         31013.0      49768.85             201506   \n",
              "8112   AMPMODU System 50         62659.0     101831.63             201507   \n",
              "8956   AMPMODU System 50         38068.0      55429.44             201508   \n",
              "10581  AMPMODU System 50         16364.0      24064.56             201509   \n",
              "11004  AMPMODU System 50         35642.0      66100.95             201510   \n",
              "\n",
              "          Price  \n",
              "176    1.259173  \n",
              "1679   1.341350  \n",
              "3127   1.351058  \n",
              "4002   1.345745  \n",
              "5857   1.014865  \n",
              "6518   1.604774  \n",
              "8112   1.625172  \n",
              "8956   1.456064  \n",
              "10581  1.470579  \n",
              "11004  1.854580  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-207ab3c6-7bac-4ac5-bea5-4d2e3eb03d9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fiscal_year_historical</th>\n",
              "      <th>fiscal_quarter_historical</th>\n",
              "      <th>fiscal_month_historical</th>\n",
              "      <th>fiscal_week_historical</th>\n",
              "      <th>business_unit_group_name</th>\n",
              "      <th>company_region_name_level_1</th>\n",
              "      <th>product_line_code</th>\n",
              "      <th>product_line_name</th>\n",
              "      <th>sales_quantity</th>\n",
              "      <th>sales_amount</th>\n",
              "      <th>year_week_ordered</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>38784.0</td>\n",
              "      <td>48835.78</td>\n",
              "      <td>201501</td>\n",
              "      <td>1.259173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1679</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>60028.0</td>\n",
              "      <td>80518.56</td>\n",
              "      <td>201502</td>\n",
              "      <td>1.341350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3127</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>28550.0</td>\n",
              "      <td>38572.70</td>\n",
              "      <td>201503</td>\n",
              "      <td>1.351058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4002</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>52851.0</td>\n",
              "      <td>71123.96</td>\n",
              "      <td>201504</td>\n",
              "      <td>1.345745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5857</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>40697.0</td>\n",
              "      <td>41301.96</td>\n",
              "      <td>201505</td>\n",
              "      <td>1.014865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6518</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>31013.0</td>\n",
              "      <td>49768.85</td>\n",
              "      <td>201506</td>\n",
              "      <td>1.604774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8112</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>62659.0</td>\n",
              "      <td>101831.63</td>\n",
              "      <td>201507</td>\n",
              "      <td>1.625172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8956</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>38068.0</td>\n",
              "      <td>55429.44</td>\n",
              "      <td>201508</td>\n",
              "      <td>1.456064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10581</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>16364.0</td>\n",
              "      <td>24064.56</td>\n",
              "      <td>201509</td>\n",
              "      <td>1.470579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11004</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>Industrial</td>\n",
              "      <td>Americas</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>35642.0</td>\n",
              "      <td>66100.95</td>\n",
              "      <td>201510</td>\n",
              "      <td>1.854580</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-207ab3c6-7bac-4ac5-bea5-4d2e3eb03d9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-207ab3c6-7bac-4ac5-bea5-4d2e3eb03d9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-207ab3c6-7bac-4ac5-bea5-4d2e3eb03d9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('002', 'Asia Pacific & ANZ', 'Channel - Industrial')\n",
            "418\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       fiscal_year_historical  fiscal_quarter_historical  \\\n",
              "563                      2015                          1   \n",
              "1763                     2015                          1   \n",
              "2981                     2015                          1   \n",
              "4153                     2015                          1   \n",
              "5426                     2015                          1   \n",
              "6678                     2015                          1   \n",
              "7881                     2015                          1   \n",
              "9089                     2015                          1   \n",
              "10264                    2015                          1   \n",
              "10836                    2015                          1   \n",
              "\n",
              "       fiscal_month_historical  fiscal_week_historical  \\\n",
              "563                          1                       1   \n",
              "1763                         1                       2   \n",
              "2981                         1                       3   \n",
              "4153                         1                       4   \n",
              "5426                         2                       5   \n",
              "6678                         2                       6   \n",
              "7881                         2                       7   \n",
              "9089                         2                       8   \n",
              "10264                        2                       9   \n",
              "10836                        3                      10   \n",
              "\n",
              "      business_unit_group_name company_region_name_level_1 product_line_code  \\\n",
              "563       Channel - Industrial          Asia Pacific & ANZ               002   \n",
              "1763      Channel - Industrial          Asia Pacific & ANZ               002   \n",
              "2981      Channel - Industrial          Asia Pacific & ANZ               002   \n",
              "4153      Channel - Industrial          Asia Pacific & ANZ               002   \n",
              "5426      Channel - Industrial          Asia Pacific & ANZ               002   \n",
              "6678      Channel - Industrial          Asia Pacific & ANZ               002   \n",
              "7881      Channel - Industrial          Asia Pacific & ANZ               002   \n",
              "9089      Channel - Industrial          Asia Pacific & ANZ               002   \n",
              "10264     Channel - Industrial          Asia Pacific & ANZ               002   \n",
              "10836     Channel - Industrial          Asia Pacific & ANZ               002   \n",
              "\n",
              "       product_line_name  sales_quantity  sales_amount  year_week_ordered  \\\n",
              "563    AMPMODU System 50         3875.80       6389.06             201501   \n",
              "1763   AMPMODU System 50         5038.54       8305.78             201502   \n",
              "2981   AMPMODU System 50         5038.54       8305.78             201503   \n",
              "4153   AMPMODU System 50         5426.12       8944.69             201504   \n",
              "5426   AMPMODU System 50         8444.93      13086.15             201505   \n",
              "6678   AMPMODU System 50         9778.34      15152.39             201506   \n",
              "7881   AMPMODU System 50         8889.40      13774.90             201507   \n",
              "9089   AMPMODU System 50         8889.40      13774.90             201508   \n",
              "10264  AMPMODU System 50         8444.93      13086.15             201509   \n",
              "10836  AMPMODU System 50        10031.25      15437.74             201510   \n",
              "\n",
              "          Price  \n",
              "563    1.648449  \n",
              "1763   1.648450  \n",
              "2981   1.648450  \n",
              "4153   1.648450  \n",
              "5426   1.549587  \n",
              "6678   1.549587  \n",
              "7881   1.549587  \n",
              "9089   1.549587  \n",
              "10264  1.549587  \n",
              "10836  1.538965  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8bd1511e-96e9-4ec6-b307-16387feff0a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fiscal_year_historical</th>\n",
              "      <th>fiscal_quarter_historical</th>\n",
              "      <th>fiscal_month_historical</th>\n",
              "      <th>fiscal_week_historical</th>\n",
              "      <th>business_unit_group_name</th>\n",
              "      <th>company_region_name_level_1</th>\n",
              "      <th>product_line_code</th>\n",
              "      <th>product_line_name</th>\n",
              "      <th>sales_quantity</th>\n",
              "      <th>sales_amount</th>\n",
              "      <th>year_week_ordered</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>563</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>3875.80</td>\n",
              "      <td>6389.06</td>\n",
              "      <td>201501</td>\n",
              "      <td>1.648449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1763</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>5038.54</td>\n",
              "      <td>8305.78</td>\n",
              "      <td>201502</td>\n",
              "      <td>1.648450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2981</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>5038.54</td>\n",
              "      <td>8305.78</td>\n",
              "      <td>201503</td>\n",
              "      <td>1.648450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4153</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>5426.12</td>\n",
              "      <td>8944.69</td>\n",
              "      <td>201504</td>\n",
              "      <td>1.648450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5426</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>8444.93</td>\n",
              "      <td>13086.15</td>\n",
              "      <td>201505</td>\n",
              "      <td>1.549587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6678</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>9778.34</td>\n",
              "      <td>15152.39</td>\n",
              "      <td>201506</td>\n",
              "      <td>1.549587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7881</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>8889.40</td>\n",
              "      <td>13774.90</td>\n",
              "      <td>201507</td>\n",
              "      <td>1.549587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9089</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>8889.40</td>\n",
              "      <td>13774.90</td>\n",
              "      <td>201508</td>\n",
              "      <td>1.549587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10264</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>8444.93</td>\n",
              "      <td>13086.15</td>\n",
              "      <td>201509</td>\n",
              "      <td>1.549587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10836</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>002</td>\n",
              "      <td>AMPMODU System 50</td>\n",
              "      <td>10031.25</td>\n",
              "      <td>15437.74</td>\n",
              "      <td>201510</td>\n",
              "      <td>1.538965</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bd1511e-96e9-4ec6-b307-16387feff0a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8bd1511e-96e9-4ec6-b307-16387feff0a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8bd1511e-96e9-4ec6-b307-16387feff0a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "grouped_df = group_by_unique(\n",
        "    df, product_line=True, business_unit=True, company_region=True)\n",
        "count = 0\n",
        "for name, group in grouped_df:\n",
        "    print(name)\n",
        "    print(len(group))\n",
        "    display(group.head(10))\n",
        "    # display(group.head())\n",
        "    count = count+1\n",
        "    if count == 5:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KNBaRY6q7Xv7"
      },
      "outputs": [],
      "source": [
        "groups = [grouped_df.get_group(x) for x in grouped_df.groups]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-Q8QDhK7Xv8"
      },
      "source": [
        "## Preparing the Data for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wwCeRHOW7Xv8"
      },
      "outputs": [],
      "source": [
        "class Data_Prep:\n",
        "    # must contain each one of these labels\n",
        "    data_filter = [\"Asia Pacific & ANZ\",\"Channel - Industrial\"]\n",
        "    #data_filter = [\"Asia Pacific & ANZ\"]\n",
        "    # collumns of interest\n",
        "    input_data_cols = [\"sales_amount\", \"sales_quantity\", \"Price\"] # add features to end to make itself predict the output col - lstm not limit to 1 feature\n",
        "    # input_data_cols = [\"sales_amount\"]\n",
        "    output_data_cols = [\"sales_amount\"]\n",
        "    percent = 0.8 # test-train split percentage\n",
        "    lookback = 20 # number of units used to make prediction\n",
        "    predict = 5 # number of units that will be predicted\n",
        "    check_dl = False # debugging purposes for checking if dataloader works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CB0sF-_87Xv8",
        "outputId": "39797afd-ff25-402f-f750-6e9434bc7cd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      fiscal_year_historical  fiscal_quarter_historical  \\\n",
              "108                     2015                          1   \n",
              "1299                    2015                          1   \n",
              "2484                    2015                          1   \n",
              "3699                    2015                          1   \n",
              "5763                    2015                          1   \n",
              "\n",
              "      fiscal_month_historical  fiscal_week_historical  \\\n",
              "108                         1                       1   \n",
              "1299                        1                       2   \n",
              "2484                        1                       3   \n",
              "3699                        1                       4   \n",
              "5763                        2                       5   \n",
              "\n",
              "     business_unit_group_name company_region_name_level_1 product_line_code  \\\n",
              "108      Channel - Industrial          Asia Pacific & ANZ               001   \n",
              "1299     Channel - Industrial          Asia Pacific & ANZ               001   \n",
              "2484     Channel - Industrial          Asia Pacific & ANZ               001   \n",
              "3699     Channel - Industrial          Asia Pacific & ANZ               001   \n",
              "5763     Channel - Industrial          Asia Pacific & ANZ               001   \n",
              "\n",
              "          product_line_name  sales_quantity  sales_amount  year_week_ordered  \\\n",
              "108   Miscellaneous AMPMODU       305278.80      33869.70             201501   \n",
              "1299  Miscellaneous AMPMODU       396862.44      44030.61             201502   \n",
              "2484  Miscellaneous AMPMODU       396862.44      44030.61             201503   \n",
              "3699  Miscellaneous AMPMODU       427390.32      47417.58             201504   \n",
              "5763  Miscellaneous AMPMODU       317301.14      43076.34             201505   \n",
              "\n",
              "         Price  \n",
              "108   0.110947  \n",
              "1299  0.110947  \n",
              "2484  0.110947  \n",
              "3699  0.110947  \n",
              "5763  0.135759  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b63fa07-6a2c-437f-b6dd-64edc0a3dbbb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fiscal_year_historical</th>\n",
              "      <th>fiscal_quarter_historical</th>\n",
              "      <th>fiscal_month_historical</th>\n",
              "      <th>fiscal_week_historical</th>\n",
              "      <th>business_unit_group_name</th>\n",
              "      <th>company_region_name_level_1</th>\n",
              "      <th>product_line_code</th>\n",
              "      <th>product_line_name</th>\n",
              "      <th>sales_quantity</th>\n",
              "      <th>sales_amount</th>\n",
              "      <th>year_week_ordered</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>305278.80</td>\n",
              "      <td>33869.70</td>\n",
              "      <td>201501</td>\n",
              "      <td>0.110947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1299</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>396862.44</td>\n",
              "      <td>44030.61</td>\n",
              "      <td>201502</td>\n",
              "      <td>0.110947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2484</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>396862.44</td>\n",
              "      <td>44030.61</td>\n",
              "      <td>201503</td>\n",
              "      <td>0.110947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3699</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>427390.32</td>\n",
              "      <td>47417.58</td>\n",
              "      <td>201504</td>\n",
              "      <td>0.110947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5763</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>317301.14</td>\n",
              "      <td>43076.34</td>\n",
              "      <td>201505</td>\n",
              "      <td>0.135759</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b63fa07-6a2c-437f-b6dd-64edc0a3dbbb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b63fa07-6a2c-437f-b6dd-64edc0a3dbbb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b63fa07-6a2c-437f-b6dd-64edc0a3dbbb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "for group in groups:\n",
        "    #TODO: uncommented this line \n",
        "    #df2 = group[group.duplicated('year_week_ordered')]\n",
        "    # duplicate = df[df.duplicated('City')]\n",
        "    display(group.head(5))\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_EpZeP97Xv8"
      },
      "source": [
        "Note:\n",
        "Found that there were some outlier values - might want to remove them and then interpolate on them depending on the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3LVYNRJu7Xv9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def clean_dataset(df):\n",
        "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
        "\n",
        "    df.dropna(inplace=True)\n",
        "    print(\"new len:\", len(df.columns))\n",
        "    return df\n",
        "\n",
        "# TODO: need to implement removal of outliers\n",
        "def removeOutliers(group, col):\n",
        "    return group\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nBMPy3cR7Xv9"
      },
      "outputs": [],
      "source": [
        "def key_filter_match(name,data_filter):\n",
        "    if len(data_filter)==0:\n",
        "        return True\n",
        "    for e in data_filter:\n",
        "        if not e in name:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def transform_norm_rem_out(grouped_df, input_data_cols,output_data_cols,data_filter):\n",
        "    transformed_data = {}\n",
        "    reg_data = {}\n",
        "    input_transformations = {}\n",
        "    output_transformations = {}\n",
        "    display_once = True\n",
        "    count = 0\n",
        "    data_cols = input_data_cols + list(set(output_data_cols) - set(input_data_cols))\n",
        "    print(input_data_cols)\n",
        "    print(output_data_cols)\n",
        "    for name, group in grouped_df:\n",
        "        if key_filter_match(name,data_filter):\n",
        "            for col in data_cols:\n",
        "\n",
        "                if len(group[col]) == 0:\n",
        "                    raise Exception(\"Collumn does not exist!\")\n",
        "                # removeOutliers(group[col],col)\n",
        "                # interpolate the mission values\n",
        "\n",
        "            scalar1 = MinMaxScaler()\n",
        "            scalar2 = MinMaxScaler()\n",
        "            # group[data_cols] = clean_dataset(group[data_cols]) # this line\n",
        "            for i in range(0, len(group.columns)):\n",
        "                group.iloc[:, i].interpolate(inplace=True)\n",
        "            group = group.replace((np.inf, -np.inf, np.nan),\n",
        "                                0).reset_index(drop=True)\n",
        "     \n",
        "            reg_data[name] = group.copy()\n",
        "            input_transformations[name] = scalar1.fit(group[input_data_cols])\n",
        "            output_transformations[name] = scalar2.fit(group[output_data_cols])\n",
        "            group[data_cols] = scalar1.fit_transform(group[input_data_cols])\n",
        "            transformed_data[name] = group\n",
        "            if display_once:\n",
        "                print(\"\\n\")\n",
        "                print(name)\n",
        "                display(transformed_data[name])\n",
        "                display_once = False\n",
        "            count += 1\n",
        "            print(count, \"/\", len(grouped_df), end=\"\\r\")\n",
        "\n",
        "    \n",
        "\n",
        "    return reg_data, transformed_data, input_transformations,output_transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ay7wUaWx7Xv9",
        "outputId": "d878f979-67d8-43db-e3d6-9c9484094d4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sales_amount', 'sales_quantity', 'Price']\n",
            "['sales_amount']\n",
            "\n",
            "\n",
            "('001', 'Asia Pacific & ANZ', 'Channel - Industrial')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     fiscal_year_historical  fiscal_quarter_historical  \\\n",
              "0                      2015                          1   \n",
              "1                      2015                          1   \n",
              "2                      2015                          1   \n",
              "3                      2015                          1   \n",
              "4                      2015                          1   \n",
              "..                      ...                        ...   \n",
              "413                    2022                          4   \n",
              "414                    2022                          4   \n",
              "415                    2022                          4   \n",
              "416                    2022                          4   \n",
              "417                    2022                          4   \n",
              "\n",
              "     fiscal_month_historical  fiscal_week_historical business_unit_group_name  \\\n",
              "0                          1                       1     Channel - Industrial   \n",
              "1                          1                       2     Channel - Industrial   \n",
              "2                          1                       3     Channel - Industrial   \n",
              "3                          1                       4     Channel - Industrial   \n",
              "4                          2                       5     Channel - Industrial   \n",
              "..                       ...                     ...                      ...   \n",
              "413                       12                      49     Channel - Industrial   \n",
              "414                       12                      50     Channel - Industrial   \n",
              "415                       12                      51     Channel - Industrial   \n",
              "416                       12                      52     Channel - Industrial   \n",
              "417                       12                      53     Channel - Industrial   \n",
              "\n",
              "    company_region_name_level_1 product_line_code      product_line_name  \\\n",
              "0            Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "1            Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "2            Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "3            Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "4            Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "..                          ...               ...                    ...   \n",
              "413          Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "414          Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "415          Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "416          Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "417          Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "\n",
              "     sales_quantity  sales_amount  year_week_ordered     Price  \n",
              "0          0.307948      0.093309             201501  0.018802  \n",
              "1          0.409376      0.129342             201502  0.018802  \n",
              "2          0.409376      0.129342             201503  0.018802  \n",
              "3          0.443185      0.141354             201504  0.018802  \n",
              "4          0.321262      0.125958             201505  0.060800  \n",
              "..              ...           ...                ...       ...  \n",
              "413        0.782539      0.437068             202249  0.132730  \n",
              "414        0.872838      0.488609             202250  0.132730  \n",
              "415        0.782539      0.437068             202251  0.132730  \n",
              "416        0.963136      0.540150             202252  0.132730  \n",
              "417        0.963136      0.540150             202253  0.132730  \n",
              "\n",
              "[418 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01796ca7-2b1e-4ecb-82d6-17829f402106\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fiscal_year_historical</th>\n",
              "      <th>fiscal_quarter_historical</th>\n",
              "      <th>fiscal_month_historical</th>\n",
              "      <th>fiscal_week_historical</th>\n",
              "      <th>business_unit_group_name</th>\n",
              "      <th>company_region_name_level_1</th>\n",
              "      <th>product_line_code</th>\n",
              "      <th>product_line_name</th>\n",
              "      <th>sales_quantity</th>\n",
              "      <th>sales_amount</th>\n",
              "      <th>year_week_ordered</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.307948</td>\n",
              "      <td>0.093309</td>\n",
              "      <td>201501</td>\n",
              "      <td>0.018802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.409376</td>\n",
              "      <td>0.129342</td>\n",
              "      <td>201502</td>\n",
              "      <td>0.018802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.409376</td>\n",
              "      <td>0.129342</td>\n",
              "      <td>201503</td>\n",
              "      <td>0.018802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.443185</td>\n",
              "      <td>0.141354</td>\n",
              "      <td>201504</td>\n",
              "      <td>0.018802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.321262</td>\n",
              "      <td>0.125958</td>\n",
              "      <td>201505</td>\n",
              "      <td>0.060800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>49</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.782539</td>\n",
              "      <td>0.437068</td>\n",
              "      <td>202249</td>\n",
              "      <td>0.132730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>50</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.872838</td>\n",
              "      <td>0.488609</td>\n",
              "      <td>202250</td>\n",
              "      <td>0.132730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>51</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.782539</td>\n",
              "      <td>0.437068</td>\n",
              "      <td>202251</td>\n",
              "      <td>0.132730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>52</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.963136</td>\n",
              "      <td>0.540150</td>\n",
              "      <td>202252</td>\n",
              "      <td>0.132730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>53</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.963136</td>\n",
              "      <td>0.540150</td>\n",
              "      <td>202253</td>\n",
              "      <td>0.132730</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>418 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01796ca7-2b1e-4ecb-82d6-17829f402106')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01796ca7-2b1e-4ecb-82d6-17829f402106 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01796ca7-2b1e-4ecb-82d6-17829f402106');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "source": [
        "reg_data,transformed_data, input_transformations,output_transformations = transform_norm_rem_out(\n",
        "    grouped_df, Data_Prep.input_data_cols,Data_Prep.output_data_cols, Data_Prep.data_filter)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfcpMwps7Xv-"
      },
      "source": [
        "This was a check to make sure that transforms were being saved - they were"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XuXXjFpr7Xv-",
        "outputId": "01c8f56b-5f62-420c-9d6c-013e63c44166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "k = '202', 'Asia Pacific & ANZ', 'Channel - Industrial'\n",
        "\n",
        "#display(transformed_data[k])\n",
        "plt.title(\"Data Input\")\n",
        "plt.plot(reg_data[k]['sales_amount'])\n",
        "plt.show()\n",
        "plt.title(\"Normalized Data\")\n",
        "plt.plot(transformed_data[k]['sales_amount'])\n",
        "plt.show()\n",
        "transform = output_transformations[k]\n",
        "plt.title(\"un-Normalized Tranform Data\")\n",
        "inv_t_data = transform.inverse_transform(transformed_data[k][Data_Prep.output_data_cols])\n",
        "#display(inv_t_data)\n",
        "#print(np.asarray(inv_t_data).shape)\n",
        "plt.plot(inv_t_data)\n",
        "plt.show()\n",
        "# shape is __ x 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zEgxBiWx7Xv-"
      },
      "outputs": [],
      "source": [
        "\n",
        "def prep_data(data, past, future, input_data_cols,output_data_cols):\n",
        "    x, y = list(), list()\n",
        "    inp_data_arr = data[input_data_cols].to_numpy()\n",
        "    out_data_arr = data[output_data_cols].to_numpy()\n",
        "    for i in range(len(inp_data_arr)):\n",
        "        lag_end = i+past\n",
        "        forcast_end = lag_end+future\n",
        "        if forcast_end > len(data):\n",
        "            break\n",
        "        x.append(inp_data_arr[i:lag_end])\n",
        "        y.append(out_data_arr[lag_end:forcast_end])\n",
        "    return np.array(x), np.array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gLelUaxk7Xv-"
      },
      "outputs": [],
      "source": [
        "\n",
        "num_features = len(Data_Prep.input_data_cols)\n",
        "show_sample = False\n",
        "dict_train_data = {}\n",
        "dict_valid_data = {}\n",
        "all_valid_data = []\n",
        "all_train_data = []\n",
        "for key, group in transformed_data.items():\n",
        "    split = (int)(len(group)*Data_Prep.percent)# TODO: check the test train split\n",
        "    train_data = group[0:split]\n",
        "    valid_data = group[split:]\n",
        "    x_train, x_test = prep_data(train_data, Data_Prep.lookback, Data_Prep.predict, Data_Prep.input_data_cols,Data_Prep.output_data_cols)\n",
        "    y_train, y_test = prep_data(valid_data, Data_Prep.lookback, Data_Prep.predict, Data_Prep.input_data_cols,Data_Prep.output_data_cols)\n",
        "\n",
        "    if show_sample:\n",
        "        print(\"train:\")\n",
        "        print(x_train.shape)\n",
        "        print(x_train[0])\n",
        "        print(x_test.shape)\n",
        "        print(x_test[0])\n",
        "        print(\"valid:\")\n",
        "        print(y_train.shape)\n",
        "        print(y_train[0])\n",
        "        print(y_test.shape)\n",
        "        print(y_test[0])\n",
        "        show_sample = False\n",
        "    all_train_data.append((x_train, x_test))\n",
        "    all_valid_data.append((y_train, y_test))\n",
        "    dict_valid_data[key] = (x_train, x_test)\n",
        "    dict_train_data[key] = (y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wYtyNOwe7Xv_",
        "outputId": "7f0d5d8c-228e-4589-ac9a-ed4c66141f9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56\n",
            "56\n",
            "(56, 2)\n",
            "(56, 2)\n",
            "y train shape: (3336, 20, 3)\n",
            "y test shape: (3336, 5, 1)\n",
            "x train shape: (17261, 20, 3)\n",
            "x test shape: (17261, 5, 1)\n"
          ]
        }
      ],
      "source": [
        "all_valid_data = np.array(all_valid_data,dtype=object)\n",
        "all_train_data = np.array(all_train_data,dtype=object)\n",
        "print(len(all_valid_data))\n",
        "print(len(all_train_data))\n",
        "\n",
        "print(all_valid_data.shape)\n",
        "print(all_train_data.shape)\n",
        "\n",
        "def get_all_data_arr(all_data):\n",
        "    tr = []\n",
        "    te= []\n",
        "    for i in range(len(all_data)):\n",
        "        x_tr = all_data[i][0]\n",
        "        x_te = all_data[i][1]\n",
        "        for j in range(len(x_tr)):\n",
        "            tr.append(x_tr[j])\n",
        "            te.append(x_te[j])\n",
        "    return np.array(tr),np.array(te)\n",
        "\n",
        "train_y,test_y = get_all_data_arr(all_valid_data)\n",
        "train_x,test_x = get_all_data_arr(all_train_data)\n",
        "\n",
        "print(\"y train shape:\",train_y.shape)\n",
        "print(\"y test shape:\",test_y.shape)\n",
        "\n",
        "print(\"x train shape:\",train_x.shape)\n",
        "print(\"x test shape:\",test_x.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECP9dvO17Xv_"
      },
      "source": [
        "## Model Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "ZyLgMR927Xv_"
      },
      "outputs": [],
      "source": [
        "class Model_Info:\n",
        "    batch_size = 128\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    count_print_batch = 4 # the number of times training loss printed for each epoch\n",
        "    learning_rate = 5e-3\n",
        "    epochs = 10_000\n",
        "    model_save_path = \"/home/abuynits/Projects/TE_Connect/savedModels/\"\n",
        "    save_model = False\n",
        "    hidden_size = 32 # the number of features in the stacked lstm\n",
        "    enc_drop = 0.\n",
        "    dec_drop = 0.\n",
        "    num_layers = 32\n",
        "    train_prediction = 'recursive'\n",
        "    display_batch_train_data = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "lZ_PHKMb7Xv_",
        "outputId": "3797210e-4eab-4785-b47f-be96f93e72e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(310, 20, 3)\n",
            "(310, 20, 3)\n",
            "batches in test dl: 27\n",
            "batches in train dl: 135\n",
            " Input seq: tensor([[0.0933, 0.3079, 0.0188],\n",
            "        [0.1293, 0.4094, 0.0188],\n",
            "        [0.1293, 0.4094, 0.0188],\n",
            "        ...,\n",
            "        [0.1448, 0.4345, 0.0263],\n",
            "        [0.1448, 0.4345, 0.0263],\n",
            "        [0.1366, 0.4124, 0.0263]])\n",
            " Out seq: tensor([[0.1203],\n",
            "        [0.1285],\n",
            "        [0.1022],\n",
            "        [0.1022],\n",
            "        [0.1280]])\n",
            " Input seq: tensor([[0.1293, 0.4094, 0.0188],\n",
            "        [0.1293, 0.4094, 0.0188],\n",
            "        [0.1414, 0.4432, 0.0188],\n",
            "        ...,\n",
            "        [0.1448, 0.4345, 0.0263],\n",
            "        [0.1366, 0.4124, 0.0263],\n",
            "        [0.1203, 0.3681, 0.0263]])\n",
            " Out seq: tensor([[0.1285],\n",
            "        [0.1022],\n",
            "        [0.1022],\n",
            "        [0.1280],\n",
            "        [0.2118]])\n",
            " Input seq: tensor([[0.0933, 0.3079, 0.0188],\n",
            "        [0.1293, 0.4094, 0.0188],\n",
            "        [0.1293, 0.4094, 0.0188],\n",
            "        ...,\n",
            "        [0.1448, 0.4345, 0.0263],\n",
            "        [0.1448, 0.4345, 0.0263],\n",
            "        [0.1366, 0.4124, 0.0263]])\n",
            " Out seq: tensor([[0.1203],\n",
            "        [0.1285],\n",
            "        [0.1022],\n",
            "        [0.1022],\n",
            "        [0.1280]])\n",
            " Input seq: tensor([[0.1293, 0.4094, 0.0188],\n",
            "        [0.1293, 0.4094, 0.0188],\n",
            "        [0.1414, 0.4432, 0.0188],\n",
            "        ...,\n",
            "        [0.1448, 0.4345, 0.0263],\n",
            "        [0.1366, 0.4124, 0.0263],\n",
            "        [0.1203, 0.3681, 0.0263]])\n",
            " Out seq: tensor([[0.1285],\n",
            "        [0.1022],\n",
            "        [0.1022],\n",
            "        [0.1280],\n",
            "        [0.2118]])\n",
            "torch.Size([128, 20, 3])\n",
            "torch.Size([128, 5, 1])\n",
            "torch.Size([128, 20, 3])\n",
            "torch.Size([128, 5, 1])\n"
          ]
        }
      ],
      "source": [
        "def createList(l,h):\n",
        "    return [i for i in range(l,h)]\n",
        "\n",
        "def print_data_loader(inp_seq,out_seq,num_print):\n",
        "    for i in range(num_print):\n",
        "        print(\" Input seq:\",inp_seq[i])\n",
        "        print(\" Out seq:\",out_seq[i])\n",
        "\n",
        "def check_data_loader(dl_train_item,dl_test_item):\n",
        "    #print(dl_train_item.shape)\n",
        "    #print(dl_test_item.shape)\n",
        "    train_low = 0\n",
        "    train_high = len(dl_train_item[0])\n",
        "    test_low = 0\n",
        "    test_high = len(dl_test_item[0])\n",
        "    for seq in dl_train_item:\n",
        "        plt.plot(createList(train_low,train_high),seq.squeeze(),color='blue')\n",
        "        train_low+=1\n",
        "        train_high+=1\n",
        "    plt.title(\"train plot\")\n",
        "    plt.show()\n",
        "    for seq in dl_test_item:\n",
        "        if len(seq) == 1:\n",
        "            #print(seq.shape)\n",
        "            #print(createList(test_low,test_high))\n",
        "            plt.scatter(createList(test_low,test_high),seq)\n",
        "        else:\n",
        "            plt.plot(createList(test_low,test_high),seq.squeeze())\n",
        "        test_low+=1\n",
        "        test_high+=1\n",
        "    plt.title(\"test plot\")\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "class finance_data_set(Dataset):\n",
        "    def __init__(self, trainDT, testDT):\n",
        "        super().__init__()\n",
        "        self.train = trainDT\n",
        "        self.test = testDT\n",
        "        self.data_len = len(trainDT)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_len\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        tr = torch.from_numpy(self.train[i]).float()\n",
        "        te = torch.from_numpy(self.test[i]).float()\n",
        "        return (tr,te)\n",
        "\n",
        "\n",
        "# train_ds = finance_data_set(x_train, x_test)\n",
        "# test_ds = finance_data_set(y_train, y_test)\n",
        "\n",
        "train_ds = finance_data_set(train_x, test_x)\n",
        "test_ds = finance_data_set(train_y, test_y)\n",
        "print(x_train.shape)\n",
        "print(all_train_data[1][0].shape)\n",
        "#train_ds = finance_data_set(all_train_data[0], all_train_data[1])\n",
        "#test_ds = finance_data_set(all_valid_data[0], all_valid_data[1])\n",
        "\n",
        "test_dl = DataLoader(test_ds, batch_size=Model_Info.batch_size, shuffle=True)\n",
        "print(f\"batches in test dl: {len(test_dl)}\")\n",
        "train_dl = DataLoader(train_ds, batch_size=Model_Info.batch_size, shuffle=False)\n",
        "print(f\"batches in train dl: {len(train_dl)}\")\n",
        "\n",
        "\n",
        "if Data_Prep.check_dl:\n",
        "    check_data_loader(next(iter(train_dl))[0],next(iter(train_dl))[1])\n",
        "print_data_loader(next(iter(train_dl))[0],next(iter(train_dl))[1],2)\n",
        "print_data_loader(next(iter(train_dl))[0],next(iter(train_dl))[1],2)\n",
        "print(next(iter(train_dl))[0].shape)\n",
        "print(next(iter(train_dl))[1].shape)\n",
        "print(next(iter(test_dl))[0].shape)\n",
        "print(next(iter(test_dl))[1].shape)\n",
        "\n",
        " #         "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "os6Sf8x-7XwA"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "stacked lstm: each layer contains multiple memory cells\n",
        "make the model deeper\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class enc_lstm(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout=0.25, num_layers=1):\n",
        "        super(enc_lstm, self).__init__()\n",
        "        self.input_size = input_size  # number of input features\n",
        "        self.hidden_size = hidden_size  # number of features in hidden state\n",
        "        self.num_layers = num_layers  # number of stacked LSTM's\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=self.input_size,\n",
        "                            hidden_size=self.hidden_size, num_layers=self.num_layers, dropout=self.dropout)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inp: input of shape (seq_len, # in batch, input_size)\n",
        "            return lstm_out, hidden\n",
        "            lstm_out: hive hidden states in seq\n",
        "            hidden: gives hidden state and cell state for last element in seq\n",
        "\n",
        "        lstm_out: encoder vecotr; acts as init hidden state of decoder part of model\n",
        "        \"\"\"\n",
        "        #print(\"enc input size: \",inp.shape)\n",
        "        inp = self.drop(inp)\n",
        "        lstm_out, self.hidden = self.lstm(\n",
        "            inp.view(inp.shape[0], inp.shape[1], self.input_size))\n",
        "        #print(\"enc lstm out: \",lstm_out.shape)\n",
        "        return lstm_out.to(Model_Info.device), self.hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        \"\"\"inits hidden state\n",
        "\n",
        "        Args:\n",
        "            batch_size (int): x_input.shape[1] \n",
        "        Return:\n",
        "            zeroed hidden state and cell state\n",
        "        \"\"\"\n",
        "\n",
        "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size).to(Model_Info.device),\n",
        "                torch.zeros(self.num_layers, batch_size, self.hidden_size).to(Model_Info.device))\n",
        "\n",
        "\n",
        "class dec_lstm(nn.Module):\n",
        "    # decodes hidden state output by encoder\n",
        "    def __init__(self, input_size, output_size, hidden_size, dropout=0.25, num_layers=1):\n",
        "        super(dec_lstm, self).__init__()\n",
        "        self.input_size = input_size  # num features in input X\n",
        "        self.hidden_size = hidden_size  # num of features in hidden state h\n",
        "        self.num_layers = num_layers  # number of stacked lstms\n",
        "        self.output_size = output_size\n",
        "        self.dropout = dropout\n",
        "        self.lstm = nn.LSTM(input_size=input_size,\n",
        "                            hidden_size=hidden_size, num_layers=num_layers, dropout=dropout)\n",
        "        self.fc1 = nn.Linear(hidden_size, self.output_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, self.input_size)\n",
        "        self.drop = nn.Dropout(self.dropout)\n",
        "\n",
        "    def forward(self, inp, enc_hidden_states):\n",
        "        # inp: 2d: batch_size, input_size\n",
        "        # enc_hidden_states: hidden states of encoder\n",
        "        lstm_out, self.hidden = self.lstm(inp, enc_hidden_states)\n",
        "        #print(\" dec: before squeeze:\",lstm_out.shape)\n",
        "        output = self.fc1(lstm_out)\n",
        "        #print(\" dec: after squeeze:\",lstm_out.shape)\n",
        "        lstm_out = self.fc2(lstm_out)\n",
        "        #print(\" dec: after fc2:\",lstm_out.shape)\n",
        "\n",
        "        return output.to(Model_Info.device), lstm_out.to(Model_Info.device), self.hidden\n",
        "\n",
        "\n",
        "class seq2seq_lstm(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, output_size, hidden_size, enc_drop=0.25, dec_drop=0.25, num_layers=1, teacher_forcing_ratio=0.5, train_prediction=None):\n",
        "        super(seq2seq_lstm, self).__init__()\n",
        "        self.input_size = input_size  # number of features in input state\n",
        "        self.hidden_size = hidden_size  # number features in hidden state\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        self.enc_drop = enc_drop\n",
        "        self.dec_drop = dec_drop\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "        self.train_prediction = train_prediction\n",
        "\n",
        "        self.enc = enc_lstm(input_size=self.input_size, hidden_size=self.hidden_size,\n",
        "                            dropout=self.enc_drop, num_layers=self.num_layers)\n",
        "        self.dec = dec_lstm(input_size=self.input_size, output_size=self.output_size, hidden_size=self.hidden_size,\n",
        "                            dropout=self.dec_drop, num_layers=self.num_layers)\n",
        "        self.name = \"seq2seq_lstm\"\n",
        "\n",
        "# TODO: need to finish up seq2seq - is only hope, lstm dont work\n",
        "# https://github.com/lkulowski/LSTM_encoder_decoder/blob/master/code/lstm_encoder_decoder.py\n",
        "\n",
        "    def forward(self, inp, model_out=None):\n",
        "        #print(Data_Prep.predict)\n",
        "        print(\"==================\")\n",
        "        print(\"input shape:\",inp.shape)\n",
        "        outputs = torch.zeros(Data_Prep.predict, inp.shape[0], len(Data_Prep.output_data_cols)).to(Model_Info.device)\n",
        "        \n",
        "        print(\"output shape:\",outputs.shape) # prints output size: seq, \n",
        "        enc_hidden = self.enc.init_hidden(batch_size=inp.shape[0])\n",
        "       \n",
        "        enc_out, enc_hidden = self.enc(inp)\n",
        "        \n",
        "        # only use the last encoder output - the rest we not need for previous steps\n",
        "        #dec_inp = inp[-1, :, :]  # reshape the input to (batch_size,input_size)\n",
        "        dec_inp = (inp [:,-1,:]).contiguous()\n",
        "        #print(\"dec inp: \",dec_inp)\n",
        "        dec_hidden_inp = ((enc_hidden[0][:,-1,:]).contiguous(),(enc_hidden[1][:,-1,:]).contiguous())\n",
        "        #print(\"dec hidden: \",dec_hidden_inp[0])\n",
        "        print(\"dec inp shape:\",dec_inp.shape) # get the last input step\n",
        "        print(\"dec hidden inp shape:\",dec_hidden_inp[0].shape)\n",
        "\n",
        "        if self.train_prediction == 'recursive' or model_out is None:\n",
        "            for t in range(Data_Prep.predict):\n",
        "                final_dec_out, dec_out, dec_hidden_inp = self.dec(dec_inp, dec_hidden_inp)\n",
        "                print(\"=====\")\n",
        "                print(\"dec hidden size:\",dec_hidden_inp[0].shape)\n",
        "                print(\"final dec out:\",final_dec_out)\n",
        "                #print(\"dec out:\",dec_out)\n",
        "                print(\"dec out size:\",dec_out.shape)\n",
        "                print(\"final dec out size:\",final_dec_out.shape)\n",
        "                outputs[t] = final_dec_out\n",
        "                dec_inp = dec_out.contiguous()\n",
        "        elif self.train_prediction == 'teacher forcing' and not model_out is None:\n",
        "\n",
        "            if random.random() < self.teacher_forcing_ratio:\n",
        "                for t in range(Data_Prep.predict):\n",
        "                    final_dec_out, dec_out, enc_hidden = self.dec(dec_inp, enc_hidden)\n",
        "                    outputs[t] = dec_out\n",
        "                    dec_inp = model_out[t, :, :]\n",
        "            else:\n",
        "                for t in range(Data_Prep.predict):\n",
        "                    final_dec_out, dec_out, enc_hidden = self.dec(dec_inp, enc_hidden)\n",
        "                    outputs[t] = final_dec_out\n",
        "                    dec_inp = dec_out\n",
        "        elif self.train_prediction == 'mixed teacher forcing' and not model_out is None:\n",
        "            for t in range(Data_Prep.predict):\n",
        "                dec_out, enc_hidden = self.dec(dec_inp, enc_hidden)\n",
        "                outputs[t] = dec_out\n",
        "\n",
        "                if random.random() < self.teacher_forcing_ratio:\n",
        "                    dec_inp = model_out[t, :, :]\n",
        "                else:\n",
        "                    dec_inp = dec_out\n",
        "        else:\n",
        "            raise Exception(\"Error: invalid training option selected\")\n",
        "        outputs = (outputs.swapaxes(0,1)).squeeze().squeeze()\n",
        "        #print(outputs.shape)\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g18baqe7XwB"
      },
      "source": [
        "class multi_input_lstm(nn.Module):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "vJuS4mWR7XwB"
      },
      "outputs": [],
      "source": [
        "class basic_lstm(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_size, layer_count, seq_len, dropout_percentage):\n",
        "        super(basic_lstm,self).__init__()\n",
        "        self.input_size = input_size  # input features\n",
        "        self.hidden_size = hidden_size  # hidden dimensions\n",
        "        self.num_layers = layer_count  # number of hidden layers\n",
        "        # batch first means that dim is (batch_dim, seq_dim, feature_dim)\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                            num_layers=layer_count, batch_first=True, dropout=dropout_percentage)  # lstm\n",
        "        self.fc_1 = nn.Linear(hidden_size, 128)  # fully connected 1\n",
        "        self.fc = nn.Linear(128, output_size)  # fully connected last layer\n",
        "        # fully connected last layer\n",
        "        self.direct_fc = nn.Linear(hidden_size, output_size)\n",
        "        self.drop = nn.Dropout(dropout_percentage)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.name = \"basic_lstm\"\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # num_layers, batch size - bc batched - need to use it, hidden size\n",
        "        h_0 = torch.randn(self.num_layers, inp.shape[0], self.hidden_size).requires_grad_().to(Model_Info.device)\n",
        "        c_0 = torch.randn(self.num_layers, inp.shape[0], self.hidden_size).requires_grad_().to(Model_Info.device)\n",
        "       # Propagate input through LSTM\n",
        "        # fill the output, hidden state and curretn state\n",
        "        (hn, cn) = (h_0, c_0)\n",
        "        # inp = inp.view(inp.shape[1],inp.shape[0],inp.shape[2])\n",
        "\n",
        "        # need to detach as truncated backpropagation through time (BPTT)\n",
        "        # prevents from backpropagating through batches\n",
        "        # output and hidden states (hn,cn) are the same, just that the output contains all output\n",
        "        #out, (hn, cn) = self.lstm(inp, (h_0.detach(), c_0.detach()))\n",
        "        out, (hn, cn) = self.lstm(inp, (h_0, c_0))\n",
        "        #print(\"inp shape:\",inp.shape) \n",
        "        #print(\"hn shape:\",hn.shape)\n",
        "        #print(\"cn shape:\",cn.shape)\n",
        "        #print(\"out lstm shape:\", out.shape)\n",
        "        # print(out.size()) # is batch size, time step, hidden size\n",
        "        \n",
        "        # just want the last time step hidden states so do out[:,-1,:]\n",
        "        # print(\"out lstm shape:\", out.shape)\n",
        "        #out = self.direct_fc(out[:, -1, :])  # will return batch, output size\n",
        "        out = self.direct_fc(hn[0]).flatten()\n",
        "        \n",
        "        # print(out.size()) # is batch size, time step, hidden size\n",
        "        return out\n",
        "\n",
        "    def forward2(self, inp):\n",
        "        print(\"inp shape:\",inp.shape) # batch_size, seq_len, 1\n",
        "        batch_size, seq_len, _ = inp.size()\n",
        "        h_0 = torch.randn(self.num_layers, inp.size(0), self.hidden_size).to(Model_Info.device)  # init hidden state of LSTM\n",
        "        # hidden state = snapshot of current lstm\n",
        "        c_0 = torch.randn(self.num_layers, inp.size(0), self.hidden_size).to(Model_Info.device)  # init internal state of LSTM\n",
        "        # Propagate input through LSTM\n",
        "        # fill the output, hidden state and curretn state\n",
        "        (hn, cn) = (h_0, c_0)\n",
        "        \n",
        "        inp = inp.view(inp.shape[1], inp.shape[0], inp.shape[2]) # seq_len batch_size, 1\n",
        "        print(\"new inp shape:\",inp.shape)\n",
        "        #inp shape: torch.Size([1024, 4, 1])\n",
        "        #new inp shape: torch.Size([4, 1024, 1])\n",
        "        for i in inp:\n",
        "            # print(\"==================\")\n",
        "            # print(\"i shape:\",i.shape)\n",
        "            i = i.view(-1, 1, inp.shape[2])\n",
        "            # print(\"new i view:\",i.shape)\n",
        "            out, (hn, cn) = self.lstm(i, (hn, cn))\n",
        "            # print(\"out shape:\",out.shape)\n",
        "            # print(\"hn shape:\",hn.shape)\n",
        "            # print(\"cn shape:\",cn.shape)\n",
        "            #break\n",
        "        # reshaping the data for Dense layer next\n",
        "        hn = hn.view(-1, self.hidden_size)\n",
        "        out = self.relu(hn)\n",
        "        out = self.fc_1(out)  # first Dense\n",
        "        out = self.relu(out)  # relu\n",
        "        out = self.fc(out)  # Final Output\n",
        "        return out.view(out.shape[0], 1, -1)\n",
        "\n",
        "# inp shape: torch.Size([1024, 40, 3])\n",
        "# i shape: torch.Size([1024, 3])\n",
        "# new i view: torch.Size([1, 1, 3072])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrHSSzJU7XwB"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "CyFCH4NE7XwB",
        "outputId": "eb5a417c-fe58-4ef1-c65b-2bf09f1676ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seq2seq_lstm(\n",
            "  (enc): enc_lstm(\n",
            "    (lstm): LSTM(3, 32, num_layers=32)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "  )\n",
            "  (dec): dec_lstm(\n",
            "    (lstm): LSTM(3, 32, num_layers=32)\n",
            "    (fc1): Linear(in_features=32, out_features=1, bias=True)\n",
            "    (fc2): Linear(in_features=32, out_features=3, bias=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "  )\n",
            ")\n",
            "533380 trainable params\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = seq2seq_lstm(num_features, output_size = len(Data_Prep.output_data_cols), hidden_size=Model_Info.hidden_size, enc_drop=Model_Info.enc_drop, dec_drop=Model_Info.dec_drop, num_layers=Model_Info.num_layers, train_prediction=Model_Info.train_prediction)\n",
        "\n",
        "# gather external data - macroeconomics\n",
        "#model = basic_lstm(input_size = len(Data_Prep.input_data_cols), output_size = len(Data_Prep.output_data_cols), hidden_size = 32, layer_count = 16, seq_len = 1,dropout_percentage = 0.25)\n",
        "model_name = model.name\n",
        "model = model.to(Model_Info.device)\n",
        "optim = optimizer.Adam(model.parameters(), lr=Model_Info.learning_rate)\n",
        "criterion = nn.MSELoss()\n",
        "print(model)\n",
        "\n",
        "def count_params(model):\n",
        "    sum = 0\n",
        "    for param in model.parameters():\n",
        "        if param.requires_grad:\n",
        "            sum += param.numel()\n",
        "    return sum\n",
        "\n",
        "print(f\"{count_params(model)} trainable params\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "6KIfBfIA7XwC",
        "outputId": "1c13b66d-588a-4fd2-d500-593f2bfa3b58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "final dec out: tensor([[0.2708],\n",
            "        [0.2708],\n",
            "        [0.2708],\n",
            "        ...,\n",
            "        [0.2708],\n",
            "        [0.2708],\n",
            "        [0.2708]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2708],\n",
            "        [0.2708],\n",
            "        [0.2708],\n",
            "        ...,\n",
            "        [0.2708],\n",
            "        [0.2708],\n",
            "        [0.2708]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3935],\n",
            "        [0.3584],\n",
            "        [0.3282],\n",
            "        ...,\n",
            "        [0.2836],\n",
            "        [0.2836],\n",
            "        [0.2836]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2836],\n",
            "        [0.2836],\n",
            "        [0.2836],\n",
            "        ...,\n",
            "        [0.2836],\n",
            "        [0.2836],\n",
            "        [0.2836]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2836],\n",
            "        [0.2836],\n",
            "        [0.2836],\n",
            "        ...,\n",
            "        [0.2836],\n",
            "        [0.2836],\n",
            "        [0.2836]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2836],\n",
            "        [0.2836],\n",
            "        [0.2836],\n",
            "        ...,\n",
            "        [0.2836],\n",
            "        [0.2836],\n",
            "        [0.2836]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2836],\n",
            "        [0.2836],\n",
            "        [0.2836],\n",
            "        ...,\n",
            "        [0.2836],\n",
            "        [0.2836],\n",
            "        [0.2836]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3886],\n",
            "        [0.3647],\n",
            "        [0.3403],\n",
            "        ...,\n",
            "        [0.2976],\n",
            "        [0.2976],\n",
            "        [0.2976]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2976],\n",
            "        [0.2976],\n",
            "        [0.2976],\n",
            "        ...,\n",
            "        [0.2976],\n",
            "        [0.2976],\n",
            "        [0.2976]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2976],\n",
            "        [0.2976],\n",
            "        [0.2976],\n",
            "        ...,\n",
            "        [0.2976],\n",
            "        [0.2976],\n",
            "        [0.2976]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2976],\n",
            "        [0.2976],\n",
            "        [0.2976],\n",
            "        ...,\n",
            "        [0.2976],\n",
            "        [0.2976],\n",
            "        [0.2976]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2976],\n",
            "        [0.2976],\n",
            "        [0.2976],\n",
            "        ...,\n",
            "        [0.2976],\n",
            "        [0.2976],\n",
            "        [0.2976]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3781],\n",
            "        [0.3651],\n",
            "        [0.3469],\n",
            "        ...,\n",
            "        [0.3087],\n",
            "        [0.3087],\n",
            "        [0.3087]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3087],\n",
            "        [0.3087],\n",
            "        [0.3087],\n",
            "        ...,\n",
            "        [0.3087],\n",
            "        [0.3087],\n",
            "        [0.3087]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3087],\n",
            "        [0.3087],\n",
            "        [0.3087],\n",
            "        ...,\n",
            "        [0.3087],\n",
            "        [0.3087],\n",
            "        [0.3087]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3087],\n",
            "        [0.3087],\n",
            "        [0.3087],\n",
            "        ...,\n",
            "        [0.3087],\n",
            "        [0.3087],\n",
            "        [0.3087]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3087],\n",
            "        [0.3087],\n",
            "        [0.3087],\n",
            "        ...,\n",
            "        [0.3087],\n",
            "        [0.3087],\n",
            "        [0.3087]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3772],\n",
            "        [0.3767],\n",
            "        [0.3660],\n",
            "        ...,\n",
            "        [0.3353],\n",
            "        [0.3353],\n",
            "        [0.3353]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3353],\n",
            "        [0.3353],\n",
            "        [0.3353],\n",
            "        ...,\n",
            "        [0.3353],\n",
            "        [0.3353],\n",
            "        [0.3353]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3353],\n",
            "        [0.3353],\n",
            "        [0.3353],\n",
            "        ...,\n",
            "        [0.3353],\n",
            "        [0.3353],\n",
            "        [0.3353]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3353],\n",
            "        [0.3353],\n",
            "        [0.3353],\n",
            "        ...,\n",
            "        [0.3353],\n",
            "        [0.3353],\n",
            "        [0.3353]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3353],\n",
            "        [0.3353],\n",
            "        [0.3353],\n",
            "        ...,\n",
            "        [0.3353],\n",
            "        [0.3353],\n",
            "        [0.3353]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4004],\n",
            "        [0.4066],\n",
            "        [0.3976],\n",
            "        ...,\n",
            "        [0.3619],\n",
            "        [0.3619],\n",
            "        [0.3619]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3619],\n",
            "        [0.3619],\n",
            "        [0.3619],\n",
            "        ...,\n",
            "        [0.3619],\n",
            "        [0.3619],\n",
            "        [0.3619]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3619],\n",
            "        [0.3619],\n",
            "        [0.3619],\n",
            "        ...,\n",
            "        [0.3619],\n",
            "        [0.3619],\n",
            "        [0.3619]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3619],\n",
            "        [0.3619],\n",
            "        [0.3619],\n",
            "        ...,\n",
            "        [0.3619],\n",
            "        [0.3619],\n",
            "        [0.3619]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3619],\n",
            "        [0.3619],\n",
            "        [0.3619],\n",
            "        ...,\n",
            "        [0.3619],\n",
            "        [0.3619],\n",
            "        [0.3619]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4166],\n",
            "        [0.4309],\n",
            "        [0.4254],\n",
            "        ...,\n",
            "        [0.3895],\n",
            "        [0.3895],\n",
            "        [0.3895]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3895],\n",
            "        [0.3895],\n",
            "        [0.3895],\n",
            "        ...,\n",
            "        [0.3895],\n",
            "        [0.3895],\n",
            "        [0.3895]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3895],\n",
            "        [0.3895],\n",
            "        [0.3895],\n",
            "        ...,\n",
            "        [0.3895],\n",
            "        [0.3895],\n",
            "        [0.3895]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3895],\n",
            "        [0.3895],\n",
            "        [0.3895],\n",
            "        ...,\n",
            "        [0.3895],\n",
            "        [0.3895],\n",
            "        [0.3895]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3895],\n",
            "        [0.3895],\n",
            "        [0.3895],\n",
            "        ...,\n",
            "        [0.3895],\n",
            "        [0.3895],\n",
            "        [0.3895]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4381],\n",
            "        [0.4639],\n",
            "        [0.4646],\n",
            "        ...,\n",
            "        [0.4329],\n",
            "        [0.4329],\n",
            "        [0.4329]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4329],\n",
            "        [0.4329],\n",
            "        [0.4329],\n",
            "        ...,\n",
            "        [0.4329],\n",
            "        [0.4329],\n",
            "        [0.4329]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4329],\n",
            "        [0.4329],\n",
            "        [0.4329],\n",
            "        ...,\n",
            "        [0.4329],\n",
            "        [0.4329],\n",
            "        [0.4329]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4329],\n",
            "        [0.4329],\n",
            "        [0.4329],\n",
            "        ...,\n",
            "        [0.4329],\n",
            "        [0.4329],\n",
            "        [0.4329]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4329],\n",
            "        [0.4329],\n",
            "        [0.4329],\n",
            "        ...,\n",
            "        [0.4329],\n",
            "        [0.4329],\n",
            "        [0.4329]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4674],\n",
            "        [0.5033],\n",
            "        [0.5084],\n",
            "        ...,\n",
            "        [0.4750],\n",
            "        [0.4750],\n",
            "        [0.4750]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4750],\n",
            "        [0.4750],\n",
            "        [0.4750],\n",
            "        ...,\n",
            "        [0.4750],\n",
            "        [0.4750],\n",
            "        [0.4750]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4750],\n",
            "        [0.4750],\n",
            "        [0.4750],\n",
            "        ...,\n",
            "        [0.4750],\n",
            "        [0.4750],\n",
            "        [0.4750]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4750],\n",
            "        [0.4750],\n",
            "        [0.4750],\n",
            "        ...,\n",
            "        [0.4750],\n",
            "        [0.4750],\n",
            "        [0.4750]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4750],\n",
            "        [0.4750],\n",
            "        [0.4750],\n",
            "        ...,\n",
            "        [0.4750],\n",
            "        [0.4750],\n",
            "        [0.4750]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4739],\n",
            "        [0.5135],\n",
            "        [0.5196],\n",
            "        ...,\n",
            "        [0.4826],\n",
            "        [0.4826],\n",
            "        [0.4826]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4826],\n",
            "        [0.4826],\n",
            "        [0.4826],\n",
            "        ...,\n",
            "        [0.4826],\n",
            "        [0.4826],\n",
            "        [0.4826]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4826],\n",
            "        [0.4826],\n",
            "        [0.4826],\n",
            "        ...,\n",
            "        [0.4826],\n",
            "        [0.4826],\n",
            "        [0.4826]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4826],\n",
            "        [0.4826],\n",
            "        [0.4826],\n",
            "        ...,\n",
            "        [0.4826],\n",
            "        [0.4826],\n",
            "        [0.4826]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4826],\n",
            "        [0.4826],\n",
            "        [0.4826],\n",
            "        ...,\n",
            "        [0.4826],\n",
            "        [0.4826],\n",
            "        [0.4826]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4559],\n",
            "        [0.4948],\n",
            "        [0.5008],\n",
            "        ...,\n",
            "        [0.4631],\n",
            "        [0.4631],\n",
            "        [0.4631]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4631],\n",
            "        [0.4631],\n",
            "        [0.4631],\n",
            "        ...,\n",
            "        [0.4631],\n",
            "        [0.4631],\n",
            "        [0.4631]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4631],\n",
            "        [0.4631],\n",
            "        [0.4631],\n",
            "        ...,\n",
            "        [0.4631],\n",
            "        [0.4631],\n",
            "        [0.4631]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4631],\n",
            "        [0.4631],\n",
            "        [0.4631],\n",
            "        ...,\n",
            "        [0.4631],\n",
            "        [0.4631],\n",
            "        [0.4631]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4631],\n",
            "        [0.4631],\n",
            "        [0.4631],\n",
            "        ...,\n",
            "        [0.4631],\n",
            "        [0.4631],\n",
            "        [0.4631]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4170],\n",
            "        [0.4516],\n",
            "        [0.4564],\n",
            "        ...,\n",
            "        [0.4220],\n",
            "        [0.4220],\n",
            "        [0.4220]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4220],\n",
            "        [0.4220],\n",
            "        [0.4220],\n",
            "        ...,\n",
            "        [0.4220],\n",
            "        [0.4220],\n",
            "        [0.4220]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4220],\n",
            "        [0.4220],\n",
            "        [0.4220],\n",
            "        ...,\n",
            "        [0.4220],\n",
            "        [0.4220],\n",
            "        [0.4220]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4220],\n",
            "        [0.4220],\n",
            "        [0.4220],\n",
            "        ...,\n",
            "        [0.4220],\n",
            "        [0.4220],\n",
            "        [0.4220]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.4220],\n",
            "        [0.4220],\n",
            "        [0.4220],\n",
            "        ...,\n",
            "        [0.4220],\n",
            "        [0.4220],\n",
            "        [0.4220]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3785],\n",
            "        [0.4094],\n",
            "        [0.4137],\n",
            "        ...,\n",
            "        [0.3835],\n",
            "        [0.3835],\n",
            "        [0.3835]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3835],\n",
            "        [0.3835],\n",
            "        [0.3835],\n",
            "        ...,\n",
            "        [0.3835],\n",
            "        [0.3835],\n",
            "        [0.3835]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3835],\n",
            "        [0.3835],\n",
            "        [0.3835],\n",
            "        ...,\n",
            "        [0.3835],\n",
            "        [0.3835],\n",
            "        [0.3835]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3835],\n",
            "        [0.3835],\n",
            "        [0.3835],\n",
            "        ...,\n",
            "        [0.3835],\n",
            "        [0.3835],\n",
            "        [0.3835]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3835],\n",
            "        [0.3835],\n",
            "        [0.3835],\n",
            "        ...,\n",
            "        [0.3835],\n",
            "        [0.3835],\n",
            "        [0.3835]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3351],\n",
            "        [0.3606],\n",
            "        [0.3637],\n",
            "        ...,\n",
            "        [0.3370],\n",
            "        [0.3370],\n",
            "        [0.3370]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3370],\n",
            "        [0.3370],\n",
            "        [0.3370],\n",
            "        ...,\n",
            "        [0.3370],\n",
            "        [0.3370],\n",
            "        [0.3370]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3370],\n",
            "        [0.3370],\n",
            "        [0.3370],\n",
            "        ...,\n",
            "        [0.3370],\n",
            "        [0.3370],\n",
            "        [0.3370]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3370],\n",
            "        [0.3370],\n",
            "        [0.3370],\n",
            "        ...,\n",
            "        [0.3370],\n",
            "        [0.3370],\n",
            "        [0.3370]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3370],\n",
            "        [0.3370],\n",
            "        [0.3370],\n",
            "        ...,\n",
            "        [0.3370],\n",
            "        [0.3370],\n",
            "        [0.3370]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2897],\n",
            "        [0.3104],\n",
            "        [0.3126],\n",
            "        ...,\n",
            "        [0.2901],\n",
            "        [0.2901],\n",
            "        [0.2901]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2901],\n",
            "        [0.2901],\n",
            "        [0.2901],\n",
            "        ...,\n",
            "        [0.2901],\n",
            "        [0.2901],\n",
            "        [0.2901]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2901],\n",
            "        [0.2901],\n",
            "        [0.2901],\n",
            "        ...,\n",
            "        [0.2901],\n",
            "        [0.2901],\n",
            "        [0.2901]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2901],\n",
            "        [0.2901],\n",
            "        [0.2901],\n",
            "        ...,\n",
            "        [0.2901],\n",
            "        [0.2901],\n",
            "        [0.2901]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2901],\n",
            "        [0.2901],\n",
            "        [0.2901],\n",
            "        ...,\n",
            "        [0.2901],\n",
            "        [0.2901],\n",
            "        [0.2901]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2453],\n",
            "        [0.2614],\n",
            "        [0.2630],\n",
            "        ...,\n",
            "        [0.2445],\n",
            "        [0.2445],\n",
            "        [0.2445]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2445],\n",
            "        [0.2445],\n",
            "        [0.2445],\n",
            "        ...,\n",
            "        [0.2445],\n",
            "        [0.2445],\n",
            "        [0.2445]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2445],\n",
            "        [0.2445],\n",
            "        [0.2445],\n",
            "        ...,\n",
            "        [0.2445],\n",
            "        [0.2445],\n",
            "        [0.2445]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2445],\n",
            "        [0.2445],\n",
            "        [0.2445],\n",
            "        ...,\n",
            "        [0.2445],\n",
            "        [0.2445],\n",
            "        [0.2445]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2445],\n",
            "        [0.2445],\n",
            "        [0.2445],\n",
            "        ...,\n",
            "        [0.2445],\n",
            "        [0.2445],\n",
            "        [0.2445]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2065],\n",
            "        [0.2192],\n",
            "        [0.2208],\n",
            "        ...,\n",
            "        [0.2064],\n",
            "        [0.2064],\n",
            "        [0.2064]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2064],\n",
            "        [0.2064],\n",
            "        [0.2064],\n",
            "        ...,\n",
            "        [0.2064],\n",
            "        [0.2064],\n",
            "        [0.2064]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2064],\n",
            "        [0.2064],\n",
            "        [0.2064],\n",
            "        ...,\n",
            "        [0.2064],\n",
            "        [0.2064],\n",
            "        [0.2064]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2064],\n",
            "        [0.2064],\n",
            "        [0.2064],\n",
            "        ...,\n",
            "        [0.2064],\n",
            "        [0.2064],\n",
            "        [0.2064]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2064],\n",
            "        [0.2064],\n",
            "        [0.2064],\n",
            "        ...,\n",
            "        [0.2064],\n",
            "        [0.2064],\n",
            "        [0.2064]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1763],\n",
            "        [0.1865],\n",
            "        [0.1882],\n",
            "        ...,\n",
            "        [0.1767],\n",
            "        [0.1767],\n",
            "        [0.1767]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1767],\n",
            "        [0.1767],\n",
            "        [0.1767],\n",
            "        ...,\n",
            "        [0.1767],\n",
            "        [0.1767],\n",
            "        [0.1767]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1767],\n",
            "        [0.1767],\n",
            "        [0.1767],\n",
            "        ...,\n",
            "        [0.1767],\n",
            "        [0.1767],\n",
            "        [0.1767]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1767],\n",
            "        [0.1767],\n",
            "        [0.1767],\n",
            "        ...,\n",
            "        [0.1767],\n",
            "        [0.1767],\n",
            "        [0.1767]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1767],\n",
            "        [0.1767],\n",
            "        [0.1767],\n",
            "        ...,\n",
            "        [0.1767],\n",
            "        [0.1767],\n",
            "        [0.1767]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1515],\n",
            "        [0.1589],\n",
            "        [0.1600],\n",
            "        ...,\n",
            "        [0.1501],\n",
            "        [0.1501],\n",
            "        [0.1501]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1501],\n",
            "        [0.1501],\n",
            "        [0.1501],\n",
            "        ...,\n",
            "        [0.1501],\n",
            "        [0.1501],\n",
            "        [0.1501]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1501],\n",
            "        [0.1501],\n",
            "        [0.1501],\n",
            "        ...,\n",
            "        [0.1501],\n",
            "        [0.1501],\n",
            "        [0.1501]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1501],\n",
            "        [0.1501],\n",
            "        [0.1501],\n",
            "        ...,\n",
            "        [0.1501],\n",
            "        [0.1501],\n",
            "        [0.1501]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1501],\n",
            "        [0.1501],\n",
            "        [0.1501],\n",
            "        ...,\n",
            "        [0.1501],\n",
            "        [0.1501],\n",
            "        [0.1501]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1311],\n",
            "        [0.1367],\n",
            "        [0.1377],\n",
            "        ...,\n",
            "        [0.1293],\n",
            "        [0.1293],\n",
            "        [0.1293]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1293],\n",
            "        [0.1293],\n",
            "        [0.1293],\n",
            "        ...,\n",
            "        [0.1293],\n",
            "        [0.1293],\n",
            "        [0.1293]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1293],\n",
            "        [0.1293],\n",
            "        [0.1293],\n",
            "        ...,\n",
            "        [0.1293],\n",
            "        [0.1293],\n",
            "        [0.1293]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1293],\n",
            "        [0.1293],\n",
            "        [0.1293],\n",
            "        ...,\n",
            "        [0.1293],\n",
            "        [0.1293],\n",
            "        [0.1293]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1293],\n",
            "        [0.1293],\n",
            "        [0.1293],\n",
            "        ...,\n",
            "        [0.1293],\n",
            "        [0.1293],\n",
            "        [0.1293]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1173],\n",
            "        [0.1224],\n",
            "        [0.1239],\n",
            "        ...,\n",
            "        [0.1170],\n",
            "        [0.1170],\n",
            "        [0.1170]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1170],\n",
            "        [0.1170],\n",
            "        [0.1170],\n",
            "        ...,\n",
            "        [0.1170],\n",
            "        [0.1170],\n",
            "        [0.1170]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1170],\n",
            "        [0.1170],\n",
            "        [0.1170],\n",
            "        ...,\n",
            "        [0.1170],\n",
            "        [0.1170],\n",
            "        [0.1170]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1170],\n",
            "        [0.1170],\n",
            "        [0.1170],\n",
            "        ...,\n",
            "        [0.1170],\n",
            "        [0.1170],\n",
            "        [0.1170]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1170],\n",
            "        [0.1170],\n",
            "        [0.1170],\n",
            "        ...,\n",
            "        [0.1170],\n",
            "        [0.1170],\n",
            "        [0.1170]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1122],\n",
            "        [0.1178],\n",
            "        [0.1198],\n",
            "        ...,\n",
            "        [0.1141],\n",
            "        [0.1141],\n",
            "        [0.1141]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1141],\n",
            "        [0.1141],\n",
            "        [0.1141],\n",
            "        ...,\n",
            "        [0.1141],\n",
            "        [0.1141],\n",
            "        [0.1141]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1141],\n",
            "        [0.1141],\n",
            "        [0.1141],\n",
            "        ...,\n",
            "        [0.1141],\n",
            "        [0.1141],\n",
            "        [0.1141]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1141],\n",
            "        [0.1141],\n",
            "        [0.1141],\n",
            "        ...,\n",
            "        [0.1141],\n",
            "        [0.1141],\n",
            "        [0.1141]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1141],\n",
            "        [0.1141],\n",
            "        [0.1141],\n",
            "        ...,\n",
            "        [0.1141],\n",
            "        [0.1141],\n",
            "        [0.1141]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1128],\n",
            "        [0.1191],\n",
            "        [0.1215],\n",
            "        ...,\n",
            "        [0.1159],\n",
            "        [0.1159],\n",
            "        [0.1159]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1159],\n",
            "        [0.1159],\n",
            "        [0.1159],\n",
            "        ...,\n",
            "        [0.1159],\n",
            "        [0.1159],\n",
            "        [0.1159]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1159],\n",
            "        [0.1159],\n",
            "        [0.1159],\n",
            "        ...,\n",
            "        [0.1159],\n",
            "        [0.1159],\n",
            "        [0.1159]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1159],\n",
            "        [0.1159],\n",
            "        [0.1159],\n",
            "        ...,\n",
            "        [0.1159],\n",
            "        [0.1159],\n",
            "        [0.1159]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1159],\n",
            "        [0.1159],\n",
            "        [0.1159],\n",
            "        ...,\n",
            "        [0.1159],\n",
            "        [0.1159],\n",
            "        [0.1159]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1133],\n",
            "        [0.1201],\n",
            "        [0.1225],\n",
            "        ...,\n",
            "        [0.1171],\n",
            "        [0.1171],\n",
            "        [0.1171]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1171],\n",
            "        [0.1171],\n",
            "        [0.1171],\n",
            "        ...,\n",
            "        [0.1171],\n",
            "        [0.1171],\n",
            "        [0.1171]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1171],\n",
            "        [0.1171],\n",
            "        [0.1171],\n",
            "        ...,\n",
            "        [0.1171],\n",
            "        [0.1171],\n",
            "        [0.1171]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1171],\n",
            "        [0.1171],\n",
            "        [0.1171],\n",
            "        ...,\n",
            "        [0.1171],\n",
            "        [0.1171],\n",
            "        [0.1171]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1171],\n",
            "        [0.1171],\n",
            "        [0.1171],\n",
            "        ...,\n",
            "        [0.1171],\n",
            "        [0.1171],\n",
            "        [0.1171]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1128],\n",
            "        [0.1196],\n",
            "        [0.1220],\n",
            "        ...,\n",
            "        [0.1166],\n",
            "        [0.1166],\n",
            "        [0.1166]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1166],\n",
            "        [0.1166],\n",
            "        [0.1166],\n",
            "        ...,\n",
            "        [0.1166],\n",
            "        [0.1166],\n",
            "        [0.1166]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1166],\n",
            "        [0.1166],\n",
            "        [0.1166],\n",
            "        ...,\n",
            "        [0.1166],\n",
            "        [0.1166],\n",
            "        [0.1166]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1166],\n",
            "        [0.1166],\n",
            "        [0.1166],\n",
            "        ...,\n",
            "        [0.1166],\n",
            "        [0.1166],\n",
            "        [0.1166]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1166],\n",
            "        [0.1166],\n",
            "        [0.1166],\n",
            "        ...,\n",
            "        [0.1166],\n",
            "        [0.1166],\n",
            "        [0.1166]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1147],\n",
            "        [0.1225],\n",
            "        [0.1254],\n",
            "        ...,\n",
            "        [0.1203],\n",
            "        [0.1203],\n",
            "        [0.1203]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1203],\n",
            "        [0.1203],\n",
            "        [0.1203],\n",
            "        ...,\n",
            "        [0.1203],\n",
            "        [0.1203],\n",
            "        [0.1203]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1203],\n",
            "        [0.1203],\n",
            "        [0.1203],\n",
            "        ...,\n",
            "        [0.1203],\n",
            "        [0.1203],\n",
            "        [0.1203]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1203],\n",
            "        [0.1203],\n",
            "        [0.1203],\n",
            "        ...,\n",
            "        [0.1203],\n",
            "        [0.1203],\n",
            "        [0.1203]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1203],\n",
            "        [0.1203],\n",
            "        [0.1203],\n",
            "        ...,\n",
            "        [0.1203],\n",
            "        [0.1203],\n",
            "        [0.1203]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1220],\n",
            "        [0.1318],\n",
            "        [0.1355],\n",
            "        ...,\n",
            "        [0.1306],\n",
            "        [0.1306],\n",
            "        [0.1306]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1306],\n",
            "        [0.1306],\n",
            "        [0.1306],\n",
            "        ...,\n",
            "        [0.1306],\n",
            "        [0.1306],\n",
            "        [0.1306]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1306],\n",
            "        [0.1306],\n",
            "        [0.1306],\n",
            "        ...,\n",
            "        [0.1306],\n",
            "        [0.1306],\n",
            "        [0.1306]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1306],\n",
            "        [0.1306],\n",
            "        [0.1306],\n",
            "        ...,\n",
            "        [0.1306],\n",
            "        [0.1306],\n",
            "        [0.1306]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1306],\n",
            "        [0.1306],\n",
            "        [0.1306],\n",
            "        ...,\n",
            "        [0.1306],\n",
            "        [0.1306],\n",
            "        [0.1306]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1333],\n",
            "        [0.1451],\n",
            "        [0.1493],\n",
            "        ...,\n",
            "        [0.1443],\n",
            "        [0.1443],\n",
            "        [0.1443]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1443],\n",
            "        [0.1443],\n",
            "        [0.1443],\n",
            "        ...,\n",
            "        [0.1443],\n",
            "        [0.1443],\n",
            "        [0.1443]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1443],\n",
            "        [0.1443],\n",
            "        [0.1443],\n",
            "        ...,\n",
            "        [0.1443],\n",
            "        [0.1443],\n",
            "        [0.1443]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1443],\n",
            "        [0.1443],\n",
            "        [0.1443],\n",
            "        ...,\n",
            "        [0.1443],\n",
            "        [0.1443],\n",
            "        [0.1443]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1443],\n",
            "        [0.1443],\n",
            "        [0.1443],\n",
            "        ...,\n",
            "        [0.1443],\n",
            "        [0.1443],\n",
            "        [0.1443]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1485],\n",
            "        [0.1636],\n",
            "        [0.1690],\n",
            "        ...,\n",
            "        [0.1642],\n",
            "        [0.1642],\n",
            "        [0.1642]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1642],\n",
            "        [0.1642],\n",
            "        [0.1642],\n",
            "        ...,\n",
            "        [0.1642],\n",
            "        [0.1642],\n",
            "        [0.1642]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1642],\n",
            "        [0.1642],\n",
            "        [0.1642],\n",
            "        ...,\n",
            "        [0.1642],\n",
            "        [0.1642],\n",
            "        [0.1642]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1642],\n",
            "        [0.1642],\n",
            "        [0.1642],\n",
            "        ...,\n",
            "        [0.1642],\n",
            "        [0.1642],\n",
            "        [0.1642]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1642],\n",
            "        [0.1642],\n",
            "        [0.1642],\n",
            "        ...,\n",
            "        [0.1642],\n",
            "        [0.1642],\n",
            "        [0.1642]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1687],\n",
            "        [0.1869],\n",
            "        [0.1931],\n",
            "        ...,\n",
            "        [0.1881],\n",
            "        [0.1881],\n",
            "        [0.1881]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1881],\n",
            "        [0.1881],\n",
            "        [0.1881],\n",
            "        ...,\n",
            "        [0.1881],\n",
            "        [0.1881],\n",
            "        [0.1881]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1881],\n",
            "        [0.1881],\n",
            "        [0.1881],\n",
            "        ...,\n",
            "        [0.1881],\n",
            "        [0.1881],\n",
            "        [0.1881]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1881],\n",
            "        [0.1881],\n",
            "        [0.1881],\n",
            "        ...,\n",
            "        [0.1881],\n",
            "        [0.1881],\n",
            "        [0.1881]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1881],\n",
            "        [0.1881],\n",
            "        [0.1881],\n",
            "        ...,\n",
            "        [0.1881],\n",
            "        [0.1881],\n",
            "        [0.1881]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1908],\n",
            "        [0.2115],\n",
            "        [0.2181],\n",
            "        ...,\n",
            "        [0.2122],\n",
            "        [0.2122],\n",
            "        [0.2122]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2122],\n",
            "        [0.2122],\n",
            "        [0.2122],\n",
            "        ...,\n",
            "        [0.2122],\n",
            "        [0.2122],\n",
            "        [0.2122]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2122],\n",
            "        [0.2122],\n",
            "        [0.2122],\n",
            "        ...,\n",
            "        [0.2122],\n",
            "        [0.2122],\n",
            "        [0.2122]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2122],\n",
            "        [0.2122],\n",
            "        [0.2122],\n",
            "        ...,\n",
            "        [0.2122],\n",
            "        [0.2122],\n",
            "        [0.2122]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2122],\n",
            "        [0.2122],\n",
            "        [0.2122],\n",
            "        ...,\n",
            "        [0.2122],\n",
            "        [0.2122],\n",
            "        [0.2122]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2138],\n",
            "        [0.2372],\n",
            "        [0.2444],\n",
            "        ...,\n",
            "        [0.2380],\n",
            "        [0.2380],\n",
            "        [0.2380]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2380],\n",
            "        [0.2380],\n",
            "        [0.2380],\n",
            "        ...,\n",
            "        [0.2380],\n",
            "        [0.2380],\n",
            "        [0.2380]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2380],\n",
            "        [0.2380],\n",
            "        [0.2380],\n",
            "        ...,\n",
            "        [0.2380],\n",
            "        [0.2380],\n",
            "        [0.2380]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2380],\n",
            "        [0.2380],\n",
            "        [0.2380],\n",
            "        ...,\n",
            "        [0.2380],\n",
            "        [0.2380],\n",
            "        [0.2380]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2380],\n",
            "        [0.2380],\n",
            "        [0.2380],\n",
            "        ...,\n",
            "        [0.2380],\n",
            "        [0.2380],\n",
            "        [0.2380]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2365],\n",
            "        [0.2629],\n",
            "        [0.2711],\n",
            "        ...,\n",
            "        [0.2646],\n",
            "        [0.2646],\n",
            "        [0.2646]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2646],\n",
            "        [0.2646],\n",
            "        [0.2646],\n",
            "        ...,\n",
            "        [0.2646],\n",
            "        [0.2646],\n",
            "        [0.2646]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2646],\n",
            "        [0.2646],\n",
            "        [0.2646],\n",
            "        ...,\n",
            "        [0.2646],\n",
            "        [0.2646],\n",
            "        [0.2646]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2646],\n",
            "        [0.2646],\n",
            "        [0.2646],\n",
            "        ...,\n",
            "        [0.2646],\n",
            "        [0.2646],\n",
            "        [0.2646]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2646],\n",
            "        [0.2646],\n",
            "        [0.2646],\n",
            "        ...,\n",
            "        [0.2646],\n",
            "        [0.2646],\n",
            "        [0.2646]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2611],\n",
            "        [0.2919],\n",
            "        [0.3017],\n",
            "        ...,\n",
            "        [0.2956],\n",
            "        [0.2956],\n",
            "        [0.2956]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2956],\n",
            "        [0.2956],\n",
            "        [0.2956],\n",
            "        ...,\n",
            "        [0.2956],\n",
            "        [0.2956],\n",
            "        [0.2956]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2956],\n",
            "        [0.2956],\n",
            "        [0.2956],\n",
            "        ...,\n",
            "        [0.2956],\n",
            "        [0.2956],\n",
            "        [0.2956]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2956],\n",
            "        [0.2956],\n",
            "        [0.2956],\n",
            "        ...,\n",
            "        [0.2956],\n",
            "        [0.2956],\n",
            "        [0.2956]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2956],\n",
            "        [0.2956],\n",
            "        [0.2956],\n",
            "        ...,\n",
            "        [0.2956],\n",
            "        [0.2956],\n",
            "        [0.2956]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2862],\n",
            "        [0.3209],\n",
            "        [0.3320],\n",
            "        ...,\n",
            "        [0.3259],\n",
            "        [0.3259],\n",
            "        [0.3259]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3259],\n",
            "        [0.3259],\n",
            "        [0.3259],\n",
            "        ...,\n",
            "        [0.3259],\n",
            "        [0.3259],\n",
            "        [0.3259]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3259],\n",
            "        [0.3259],\n",
            "        [0.3259],\n",
            "        ...,\n",
            "        [0.3259],\n",
            "        [0.3259],\n",
            "        [0.3259]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3259],\n",
            "        [0.3259],\n",
            "        [0.3259],\n",
            "        ...,\n",
            "        [0.3259],\n",
            "        [0.3259],\n",
            "        [0.3259]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3259],\n",
            "        [0.3259],\n",
            "        [0.3259],\n",
            "        ...,\n",
            "        [0.3259],\n",
            "        [0.3259],\n",
            "        [0.3259]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3075],\n",
            "        [0.3461],\n",
            "        [0.3587],\n",
            "        ...,\n",
            "        [0.3530],\n",
            "        [0.3530],\n",
            "        [0.3530]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3530],\n",
            "        [0.3530],\n",
            "        [0.3530],\n",
            "        ...,\n",
            "        [0.3530],\n",
            "        [0.3530],\n",
            "        [0.3530]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3530],\n",
            "        [0.3530],\n",
            "        [0.3530],\n",
            "        ...,\n",
            "        [0.3530],\n",
            "        [0.3530],\n",
            "        [0.3530]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3530],\n",
            "        [0.3530],\n",
            "        [0.3530],\n",
            "        ...,\n",
            "        [0.3530],\n",
            "        [0.3530],\n",
            "        [0.3530]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3530],\n",
            "        [0.3530],\n",
            "        [0.3530],\n",
            "        ...,\n",
            "        [0.3530],\n",
            "        [0.3530],\n",
            "        [0.3530]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3228],\n",
            "        [0.3628],\n",
            "        [0.3757],\n",
            "        ...,\n",
            "        [0.3698],\n",
            "        [0.3698],\n",
            "        [0.3698]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3698],\n",
            "        [0.3698],\n",
            "        [0.3698],\n",
            "        ...,\n",
            "        [0.3698],\n",
            "        [0.3698],\n",
            "        [0.3698]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3698],\n",
            "        [0.3698],\n",
            "        [0.3698],\n",
            "        ...,\n",
            "        [0.3698],\n",
            "        [0.3698],\n",
            "        [0.3698]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3698],\n",
            "        [0.3698],\n",
            "        [0.3698],\n",
            "        ...,\n",
            "        [0.3698],\n",
            "        [0.3698],\n",
            "        [0.3698]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3698],\n",
            "        [0.3698],\n",
            "        [0.3698],\n",
            "        ...,\n",
            "        [0.3698],\n",
            "        [0.3698],\n",
            "        [0.3698]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3273],\n",
            "        [0.3670],\n",
            "        [0.3795],\n",
            "        ...,\n",
            "        [0.3730],\n",
            "        [0.3730],\n",
            "        [0.3730]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3730],\n",
            "        [0.3730],\n",
            "        [0.3730],\n",
            "        ...,\n",
            "        [0.3730],\n",
            "        [0.3730],\n",
            "        [0.3730]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3730],\n",
            "        [0.3730],\n",
            "        [0.3730],\n",
            "        ...,\n",
            "        [0.3730],\n",
            "        [0.3730],\n",
            "        [0.3730]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3730],\n",
            "        [0.3730],\n",
            "        [0.3730],\n",
            "        ...,\n",
            "        [0.3730],\n",
            "        [0.3730],\n",
            "        [0.3730]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3730],\n",
            "        [0.3730],\n",
            "        [0.3730],\n",
            "        ...,\n",
            "        [0.3730],\n",
            "        [0.3730],\n",
            "        [0.3730]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3230],\n",
            "        [0.3617],\n",
            "        [0.3736],\n",
            "        ...,\n",
            "        [0.3668],\n",
            "        [0.3668],\n",
            "        [0.3668]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3668],\n",
            "        [0.3668],\n",
            "        [0.3668],\n",
            "        ...,\n",
            "        [0.3668],\n",
            "        [0.3668],\n",
            "        [0.3668]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3668],\n",
            "        [0.3668],\n",
            "        [0.3668],\n",
            "        ...,\n",
            "        [0.3668],\n",
            "        [0.3668],\n",
            "        [0.3668]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3668],\n",
            "        [0.3668],\n",
            "        [0.3668],\n",
            "        ...,\n",
            "        [0.3668],\n",
            "        [0.3668],\n",
            "        [0.3668]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3668],\n",
            "        [0.3668],\n",
            "        [0.3668],\n",
            "        ...,\n",
            "        [0.3668],\n",
            "        [0.3668],\n",
            "        [0.3668]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3202],\n",
            "        [0.3595],\n",
            "        [0.3718],\n",
            "        ...,\n",
            "        [0.3656],\n",
            "        [0.3656],\n",
            "        [0.3656]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3656],\n",
            "        [0.3656],\n",
            "        [0.3656],\n",
            "        ...,\n",
            "        [0.3656],\n",
            "        [0.3656],\n",
            "        [0.3656]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3656],\n",
            "        [0.3656],\n",
            "        [0.3656],\n",
            "        ...,\n",
            "        [0.3656],\n",
            "        [0.3656],\n",
            "        [0.3656]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3656],\n",
            "        [0.3656],\n",
            "        [0.3656],\n",
            "        ...,\n",
            "        [0.3656],\n",
            "        [0.3656],\n",
            "        [0.3656]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3656],\n",
            "        [0.3656],\n",
            "        [0.3656],\n",
            "        ...,\n",
            "        [0.3656],\n",
            "        [0.3656],\n",
            "        [0.3656]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3168],\n",
            "        [0.3559],\n",
            "        [0.3684],\n",
            "        ...,\n",
            "        [0.3628],\n",
            "        [0.3628],\n",
            "        [0.3628]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3628],\n",
            "        [0.3628],\n",
            "        [0.3628],\n",
            "        ...,\n",
            "        [0.3628],\n",
            "        [0.3628],\n",
            "        [0.3628]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3628],\n",
            "        [0.3628],\n",
            "        [0.3628],\n",
            "        ...,\n",
            "        [0.3628],\n",
            "        [0.3628],\n",
            "        [0.3628]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3628],\n",
            "        [0.3628],\n",
            "        [0.3628],\n",
            "        ...,\n",
            "        [0.3628],\n",
            "        [0.3628],\n",
            "        [0.3628]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3628],\n",
            "        [0.3628],\n",
            "        [0.3628],\n",
            "        ...,\n",
            "        [0.3628],\n",
            "        [0.3628],\n",
            "        [0.3628]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3153],\n",
            "        [0.3530],\n",
            "        [0.3648],\n",
            "        ...,\n",
            "        [0.3591],\n",
            "        [0.3591],\n",
            "        [0.3591]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3591],\n",
            "        [0.3591],\n",
            "        [0.3591],\n",
            "        ...,\n",
            "        [0.3591],\n",
            "        [0.3591],\n",
            "        [0.3591]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3591],\n",
            "        [0.3591],\n",
            "        [0.3591],\n",
            "        ...,\n",
            "        [0.3591],\n",
            "        [0.3591],\n",
            "        [0.3591]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3591],\n",
            "        [0.3591],\n",
            "        [0.3591],\n",
            "        ...,\n",
            "        [0.3591],\n",
            "        [0.3591],\n",
            "        [0.3591]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3591],\n",
            "        [0.3591],\n",
            "        [0.3591],\n",
            "        ...,\n",
            "        [0.3591],\n",
            "        [0.3591],\n",
            "        [0.3591]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3060],\n",
            "        [0.3387],\n",
            "        [0.3478],\n",
            "        ...,\n",
            "        [0.3402],\n",
            "        [0.3402],\n",
            "        [0.3402]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3402],\n",
            "        [0.3402],\n",
            "        [0.3402],\n",
            "        ...,\n",
            "        [0.3402],\n",
            "        [0.3402],\n",
            "        [0.3402]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3402],\n",
            "        [0.3402],\n",
            "        [0.3402],\n",
            "        ...,\n",
            "        [0.3402],\n",
            "        [0.3402],\n",
            "        [0.3402]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3402],\n",
            "        [0.3402],\n",
            "        [0.3402],\n",
            "        ...,\n",
            "        [0.3402],\n",
            "        [0.3402],\n",
            "        [0.3402]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3402],\n",
            "        [0.3402],\n",
            "        [0.3402],\n",
            "        ...,\n",
            "        [0.3402],\n",
            "        [0.3402],\n",
            "        [0.3402]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2869],\n",
            "        [0.3139],\n",
            "        [0.3205],\n",
            "        ...,\n",
            "        [0.3115],\n",
            "        [0.3115],\n",
            "        [0.3115]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3115],\n",
            "        [0.3115],\n",
            "        [0.3115],\n",
            "        ...,\n",
            "        [0.3115],\n",
            "        [0.3115],\n",
            "        [0.3115]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3115],\n",
            "        [0.3115],\n",
            "        [0.3115],\n",
            "        ...,\n",
            "        [0.3115],\n",
            "        [0.3115],\n",
            "        [0.3115]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3115],\n",
            "        [0.3115],\n",
            "        [0.3115],\n",
            "        ...,\n",
            "        [0.3115],\n",
            "        [0.3115],\n",
            "        [0.3115]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3115],\n",
            "        [0.3115],\n",
            "        [0.3115],\n",
            "        ...,\n",
            "        [0.3115],\n",
            "        [0.3115],\n",
            "        [0.3115]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2682],\n",
            "        [0.2906],\n",
            "        [0.2951],\n",
            "        ...,\n",
            "        [0.2850],\n",
            "        [0.2850],\n",
            "        [0.2850]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2850],\n",
            "        [0.2850],\n",
            "        [0.2850],\n",
            "        ...,\n",
            "        [0.2850],\n",
            "        [0.2850],\n",
            "        [0.2850]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2850],\n",
            "        [0.2850],\n",
            "        [0.2850],\n",
            "        ...,\n",
            "        [0.2850],\n",
            "        [0.2850],\n",
            "        [0.2850]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2850],\n",
            "        [0.2850],\n",
            "        [0.2850],\n",
            "        ...,\n",
            "        [0.2850],\n",
            "        [0.2850],\n",
            "        [0.2850]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2850],\n",
            "        [0.2850],\n",
            "        [0.2850],\n",
            "        ...,\n",
            "        [0.2850],\n",
            "        [0.2850],\n",
            "        [0.2850]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2548],\n",
            "        [0.2731],\n",
            "        [0.2758],\n",
            "        ...,\n",
            "        [0.2648],\n",
            "        [0.2648],\n",
            "        [0.2648]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2648],\n",
            "        [0.2648],\n",
            "        [0.2648],\n",
            "        ...,\n",
            "        [0.2648],\n",
            "        [0.2648],\n",
            "        [0.2648]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2648],\n",
            "        [0.2648],\n",
            "        [0.2648],\n",
            "        ...,\n",
            "        [0.2648],\n",
            "        [0.2648],\n",
            "        [0.2648]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2648],\n",
            "        [0.2648],\n",
            "        [0.2648],\n",
            "        ...,\n",
            "        [0.2648],\n",
            "        [0.2648],\n",
            "        [0.2648]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2648],\n",
            "        [0.2648],\n",
            "        [0.2648],\n",
            "        ...,\n",
            "        [0.2648],\n",
            "        [0.2648],\n",
            "        [0.2648]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2454],\n",
            "        [0.2603],\n",
            "        [0.2613],\n",
            "        ...,\n",
            "        [0.2494],\n",
            "        [0.2494],\n",
            "        [0.2494]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2494],\n",
            "        [0.2494],\n",
            "        [0.2494],\n",
            "        ...,\n",
            "        [0.2494],\n",
            "        [0.2494],\n",
            "        [0.2494]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2494],\n",
            "        [0.2494],\n",
            "        [0.2494],\n",
            "        ...,\n",
            "        [0.2494],\n",
            "        [0.2494],\n",
            "        [0.2494]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2494],\n",
            "        [0.2494],\n",
            "        [0.2494],\n",
            "        ...,\n",
            "        [0.2494],\n",
            "        [0.2494],\n",
            "        [0.2494]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2494],\n",
            "        [0.2494],\n",
            "        [0.2494],\n",
            "        ...,\n",
            "        [0.2494],\n",
            "        [0.2494],\n",
            "        [0.2494]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2356],\n",
            "        [0.2474],\n",
            "        [0.2470],\n",
            "        ...,\n",
            "        [0.2347],\n",
            "        [0.2347],\n",
            "        [0.2347]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2347],\n",
            "        [0.2347],\n",
            "        [0.2347],\n",
            "        ...,\n",
            "        [0.2347],\n",
            "        [0.2347],\n",
            "        [0.2347]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2347],\n",
            "        [0.2347],\n",
            "        [0.2347],\n",
            "        ...,\n",
            "        [0.2347],\n",
            "        [0.2347],\n",
            "        [0.2347]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2347],\n",
            "        [0.2347],\n",
            "        [0.2347],\n",
            "        ...,\n",
            "        [0.2347],\n",
            "        [0.2347],\n",
            "        [0.2347]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2347],\n",
            "        [0.2347],\n",
            "        [0.2347],\n",
            "        ...,\n",
            "        [0.2347],\n",
            "        [0.2347],\n",
            "        [0.2347]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2280],\n",
            "        [0.2368],\n",
            "        [0.2350],\n",
            "        ...,\n",
            "        [0.2221],\n",
            "        [0.2221],\n",
            "        [0.2221]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2221],\n",
            "        [0.2221],\n",
            "        [0.2221],\n",
            "        ...,\n",
            "        [0.2221],\n",
            "        [0.2221],\n",
            "        [0.2221]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2221],\n",
            "        [0.2221],\n",
            "        [0.2221],\n",
            "        ...,\n",
            "        [0.2221],\n",
            "        [0.2221],\n",
            "        [0.2221]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2221],\n",
            "        [0.2221],\n",
            "        [0.2221],\n",
            "        ...,\n",
            "        [0.2221],\n",
            "        [0.2221],\n",
            "        [0.2221]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2221],\n",
            "        [0.2221],\n",
            "        [0.2221],\n",
            "        ...,\n",
            "        [0.2221],\n",
            "        [0.2221],\n",
            "        [0.2221]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2187],\n",
            "        [0.2250],\n",
            "        [0.2222],\n",
            "        ...,\n",
            "        [0.2091],\n",
            "        [0.2091],\n",
            "        [0.2091]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2091],\n",
            "        [0.2091],\n",
            "        [0.2091],\n",
            "        ...,\n",
            "        [0.2091],\n",
            "        [0.2091],\n",
            "        [0.2091]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2091],\n",
            "        [0.2091],\n",
            "        [0.2091],\n",
            "        ...,\n",
            "        [0.2091],\n",
            "        [0.2091],\n",
            "        [0.2091]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2091],\n",
            "        [0.2091],\n",
            "        [0.2091],\n",
            "        ...,\n",
            "        [0.2091],\n",
            "        [0.2091],\n",
            "        [0.2091]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2091],\n",
            "        [0.2091],\n",
            "        [0.2091],\n",
            "        ...,\n",
            "        [0.2091],\n",
            "        [0.2091],\n",
            "        [0.2091]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2117],\n",
            "        [0.2162],\n",
            "        [0.2128],\n",
            "        ...,\n",
            "        [0.1999],\n",
            "        [0.1999],\n",
            "        [0.1999]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1999],\n",
            "        [0.1999],\n",
            "        [0.1999],\n",
            "        ...,\n",
            "        [0.1999],\n",
            "        [0.1999],\n",
            "        [0.1999]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1999],\n",
            "        [0.1999],\n",
            "        [0.1999],\n",
            "        ...,\n",
            "        [0.1999],\n",
            "        [0.1999],\n",
            "        [0.1999]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1999],\n",
            "        [0.1999],\n",
            "        [0.1999],\n",
            "        ...,\n",
            "        [0.1999],\n",
            "        [0.1999],\n",
            "        [0.1999]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1999],\n",
            "        [0.1999],\n",
            "        [0.1999],\n",
            "        ...,\n",
            "        [0.1999],\n",
            "        [0.1999],\n",
            "        [0.1999]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2072],\n",
            "        [0.2105],\n",
            "        [0.2066],\n",
            "        ...,\n",
            "        [0.1939],\n",
            "        [0.1939],\n",
            "        [0.1939]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1939],\n",
            "        [0.1939],\n",
            "        [0.1939],\n",
            "        ...,\n",
            "        [0.1939],\n",
            "        [0.1939],\n",
            "        [0.1939]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1939],\n",
            "        [0.1939],\n",
            "        [0.1939],\n",
            "        ...,\n",
            "        [0.1939],\n",
            "        [0.1939],\n",
            "        [0.1939]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1939],\n",
            "        [0.1939],\n",
            "        [0.1939],\n",
            "        ...,\n",
            "        [0.1939],\n",
            "        [0.1939],\n",
            "        [0.1939]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1939],\n",
            "        [0.1939],\n",
            "        [0.1939],\n",
            "        ...,\n",
            "        [0.1939],\n",
            "        [0.1939],\n",
            "        [0.1939]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2038],\n",
            "        [0.2060],\n",
            "        [0.2018],\n",
            "        ...,\n",
            "        [0.1893],\n",
            "        [0.1893],\n",
            "        [0.1893]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1893],\n",
            "        [0.1893],\n",
            "        [0.1893],\n",
            "        ...,\n",
            "        [0.1893],\n",
            "        [0.1893],\n",
            "        [0.1893]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1893],\n",
            "        [0.1893],\n",
            "        [0.1893],\n",
            "        ...,\n",
            "        [0.1893],\n",
            "        [0.1893],\n",
            "        [0.1893]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1893],\n",
            "        [0.1893],\n",
            "        [0.1893],\n",
            "        ...,\n",
            "        [0.1893],\n",
            "        [0.1893],\n",
            "        [0.1893]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1893],\n",
            "        [0.1893],\n",
            "        [0.1893],\n",
            "        ...,\n",
            "        [0.1893],\n",
            "        [0.1893],\n",
            "        [0.1893]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2042],\n",
            "        [0.2061],\n",
            "        [0.2018],\n",
            "        ...,\n",
            "        [0.1895],\n",
            "        [0.1895],\n",
            "        [0.1895]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1895],\n",
            "        [0.1895],\n",
            "        [0.1895],\n",
            "        ...,\n",
            "        [0.1895],\n",
            "        [0.1895],\n",
            "        [0.1895]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1895],\n",
            "        [0.1895],\n",
            "        [0.1895],\n",
            "        ...,\n",
            "        [0.1895],\n",
            "        [0.1895],\n",
            "        [0.1895]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1895],\n",
            "        [0.1895],\n",
            "        [0.1895],\n",
            "        ...,\n",
            "        [0.1895],\n",
            "        [0.1895],\n",
            "        [0.1895]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1895],\n",
            "        [0.1895],\n",
            "        [0.1895],\n",
            "        ...,\n",
            "        [0.1895],\n",
            "        [0.1895],\n",
            "        [0.1895]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2090],\n",
            "        [0.2097],\n",
            "        [0.2046],\n",
            "        ...,\n",
            "        [0.1915],\n",
            "        [0.1915],\n",
            "        [0.1915]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1915],\n",
            "        [0.1915],\n",
            "        [0.1915],\n",
            "        ...,\n",
            "        [0.1915],\n",
            "        [0.1915],\n",
            "        [0.1915]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1915],\n",
            "        [0.1915],\n",
            "        [0.1915],\n",
            "        ...,\n",
            "        [0.1915],\n",
            "        [0.1915],\n",
            "        [0.1915]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1915],\n",
            "        [0.1915],\n",
            "        [0.1915],\n",
            "        ...,\n",
            "        [0.1915],\n",
            "        [0.1915],\n",
            "        [0.1915]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1915],\n",
            "        [0.1915],\n",
            "        [0.1915],\n",
            "        ...,\n",
            "        [0.1915],\n",
            "        [0.1915],\n",
            "        [0.1915]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2106],\n",
            "        [0.2099],\n",
            "        [0.2040],\n",
            "        ...,\n",
            "        [0.1904],\n",
            "        [0.1904],\n",
            "        [0.1904]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1904],\n",
            "        [0.1904],\n",
            "        [0.1904],\n",
            "        ...,\n",
            "        [0.1904],\n",
            "        [0.1904],\n",
            "        [0.1904]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1904],\n",
            "        [0.1904],\n",
            "        [0.1904],\n",
            "        ...,\n",
            "        [0.1904],\n",
            "        [0.1904],\n",
            "        [0.1904]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1904],\n",
            "        [0.1904],\n",
            "        [0.1904],\n",
            "        ...,\n",
            "        [0.1904],\n",
            "        [0.1904],\n",
            "        [0.1904]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1904],\n",
            "        [0.1904],\n",
            "        [0.1904],\n",
            "        ...,\n",
            "        [0.1904],\n",
            "        [0.1904],\n",
            "        [0.1904]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2085],\n",
            "        [0.2065],\n",
            "        [0.2000],\n",
            "        ...,\n",
            "        [0.1861],\n",
            "        [0.1861],\n",
            "        [0.1861]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1861],\n",
            "        [0.1861],\n",
            "        [0.1861],\n",
            "        ...,\n",
            "        [0.1861],\n",
            "        [0.1861],\n",
            "        [0.1861]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1861],\n",
            "        [0.1861],\n",
            "        [0.1861],\n",
            "        ...,\n",
            "        [0.1861],\n",
            "        [0.1861],\n",
            "        [0.1861]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1861],\n",
            "        [0.1861],\n",
            "        [0.1861],\n",
            "        ...,\n",
            "        [0.1861],\n",
            "        [0.1861],\n",
            "        [0.1861]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1861],\n",
            "        [0.1861],\n",
            "        [0.1861],\n",
            "        ...,\n",
            "        [0.1861],\n",
            "        [0.1861],\n",
            "        [0.1861]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2055],\n",
            "        [0.2028],\n",
            "        [0.1960],\n",
            "        ...,\n",
            "        [0.1822],\n",
            "        [0.1822],\n",
            "        [0.1822]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1822],\n",
            "        [0.1822],\n",
            "        [0.1822],\n",
            "        ...,\n",
            "        [0.1822],\n",
            "        [0.1822],\n",
            "        [0.1822]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1822],\n",
            "        [0.1822],\n",
            "        [0.1822],\n",
            "        ...,\n",
            "        [0.1822],\n",
            "        [0.1822],\n",
            "        [0.1822]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1822],\n",
            "        [0.1822],\n",
            "        [0.1822],\n",
            "        ...,\n",
            "        [0.1822],\n",
            "        [0.1822],\n",
            "        [0.1822]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1822],\n",
            "        [0.1822],\n",
            "        [0.1822],\n",
            "        ...,\n",
            "        [0.1822],\n",
            "        [0.1822],\n",
            "        [0.1822]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2023],\n",
            "        [0.1987],\n",
            "        [0.1916],\n",
            "        ...,\n",
            "        [0.1778],\n",
            "        [0.1778],\n",
            "        [0.1778]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1778],\n",
            "        [0.1778],\n",
            "        [0.1778],\n",
            "        ...,\n",
            "        [0.1778],\n",
            "        [0.1778],\n",
            "        [0.1778]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1778],\n",
            "        [0.1778],\n",
            "        [0.1778],\n",
            "        ...,\n",
            "        [0.1778],\n",
            "        [0.1778],\n",
            "        [0.1778]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1778],\n",
            "        [0.1778],\n",
            "        [0.1778],\n",
            "        ...,\n",
            "        [0.1778],\n",
            "        [0.1778],\n",
            "        [0.1778]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1778],\n",
            "        [0.1778],\n",
            "        [0.1778],\n",
            "        ...,\n",
            "        [0.1778],\n",
            "        [0.1778],\n",
            "        [0.1778]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2037],\n",
            "        [0.1988],\n",
            "        [0.1909],\n",
            "        ...,\n",
            "        [0.1767],\n",
            "        [0.1767],\n",
            "        [0.1767]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1767],\n",
            "        [0.1767],\n",
            "        [0.1767],\n",
            "        ...,\n",
            "        [0.1767],\n",
            "        [0.1767],\n",
            "        [0.1767]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1767],\n",
            "        [0.1767],\n",
            "        [0.1767],\n",
            "        ...,\n",
            "        [0.1767],\n",
            "        [0.1767],\n",
            "        [0.1767]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1767],\n",
            "        [0.1767],\n",
            "        [0.1767],\n",
            "        ...,\n",
            "        [0.1767],\n",
            "        [0.1767],\n",
            "        [0.1767]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1767],\n",
            "        [0.1767],\n",
            "        [0.1767],\n",
            "        ...,\n",
            "        [0.1767],\n",
            "        [0.1767],\n",
            "        [0.1767]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2085],\n",
            "        [0.2021],\n",
            "        [0.1932],\n",
            "        ...,\n",
            "        [0.1777],\n",
            "        [0.1777],\n",
            "        [0.1777]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1777],\n",
            "        [0.1777],\n",
            "        [0.1777],\n",
            "        ...,\n",
            "        [0.1777],\n",
            "        [0.1777],\n",
            "        [0.1777]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1777],\n",
            "        [0.1777],\n",
            "        [0.1777],\n",
            "        ...,\n",
            "        [0.1777],\n",
            "        [0.1777],\n",
            "        [0.1777]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1777],\n",
            "        [0.1777],\n",
            "        [0.1777],\n",
            "        ...,\n",
            "        [0.1777],\n",
            "        [0.1777],\n",
            "        [0.1777]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1777],\n",
            "        [0.1777],\n",
            "        [0.1777],\n",
            "        ...,\n",
            "        [0.1777],\n",
            "        [0.1777],\n",
            "        [0.1777]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2130],\n",
            "        [0.2056],\n",
            "        [0.1960],\n",
            "        ...,\n",
            "        [0.1796],\n",
            "        [0.1796],\n",
            "        [0.1796]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1796],\n",
            "        [0.1796],\n",
            "        [0.1796],\n",
            "        ...,\n",
            "        [0.1796],\n",
            "        [0.1796],\n",
            "        [0.1796]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1796],\n",
            "        [0.1796],\n",
            "        [0.1796],\n",
            "        ...,\n",
            "        [0.1796],\n",
            "        [0.1796],\n",
            "        [0.1796]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1796],\n",
            "        [0.1796],\n",
            "        [0.1796],\n",
            "        ...,\n",
            "        [0.1796],\n",
            "        [0.1796],\n",
            "        [0.1796]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1796],\n",
            "        [0.1796],\n",
            "        [0.1796],\n",
            "        ...,\n",
            "        [0.1796],\n",
            "        [0.1796],\n",
            "        [0.1796]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2188],\n",
            "        [0.2112],\n",
            "        [0.2012],\n",
            "        ...,\n",
            "        [0.1841],\n",
            "        [0.1841],\n",
            "        [0.1841]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1841],\n",
            "        [0.1841],\n",
            "        [0.1841],\n",
            "        ...,\n",
            "        [0.1841],\n",
            "        [0.1841],\n",
            "        [0.1841]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1841],\n",
            "        [0.1841],\n",
            "        [0.1841],\n",
            "        ...,\n",
            "        [0.1841],\n",
            "        [0.1841],\n",
            "        [0.1841]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1841],\n",
            "        [0.1841],\n",
            "        [0.1841],\n",
            "        ...,\n",
            "        [0.1841],\n",
            "        [0.1841],\n",
            "        [0.1841]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1841],\n",
            "        [0.1841],\n",
            "        [0.1841],\n",
            "        ...,\n",
            "        [0.1841],\n",
            "        [0.1841],\n",
            "        [0.1841]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2261],\n",
            "        [0.2183],\n",
            "        [0.2079],\n",
            "        ...,\n",
            "        [0.1900],\n",
            "        [0.1900],\n",
            "        [0.1900]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1900],\n",
            "        [0.1900],\n",
            "        [0.1900],\n",
            "        ...,\n",
            "        [0.1900],\n",
            "        [0.1900],\n",
            "        [0.1900]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1900],\n",
            "        [0.1900],\n",
            "        [0.1900],\n",
            "        ...,\n",
            "        [0.1900],\n",
            "        [0.1900],\n",
            "        [0.1900]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1900],\n",
            "        [0.1900],\n",
            "        [0.1900],\n",
            "        ...,\n",
            "        [0.1900],\n",
            "        [0.1900],\n",
            "        [0.1900]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1900],\n",
            "        [0.1900],\n",
            "        [0.1900],\n",
            "        ...,\n",
            "        [0.1900],\n",
            "        [0.1900],\n",
            "        [0.1900]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2319],\n",
            "        [0.2241],\n",
            "        [0.2136],\n",
            "        ...,\n",
            "        [0.1953],\n",
            "        [0.1953],\n",
            "        [0.1953]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1953],\n",
            "        [0.1953],\n",
            "        [0.1953],\n",
            "        ...,\n",
            "        [0.1953],\n",
            "        [0.1953],\n",
            "        [0.1953]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1953],\n",
            "        [0.1953],\n",
            "        [0.1953],\n",
            "        ...,\n",
            "        [0.1953],\n",
            "        [0.1953],\n",
            "        [0.1953]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1953],\n",
            "        [0.1953],\n",
            "        [0.1953],\n",
            "        ...,\n",
            "        [0.1953],\n",
            "        [0.1953],\n",
            "        [0.1953]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.1953],\n",
            "        [0.1953],\n",
            "        [0.1953],\n",
            "        ...,\n",
            "        [0.1953],\n",
            "        [0.1953],\n",
            "        [0.1953]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2399],\n",
            "        [0.2320],\n",
            "        [0.2212],\n",
            "        ...,\n",
            "        [0.2023],\n",
            "        [0.2023],\n",
            "        [0.2023]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2023],\n",
            "        [0.2023],\n",
            "        [0.2023],\n",
            "        ...,\n",
            "        [0.2023],\n",
            "        [0.2023],\n",
            "        [0.2023]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2023],\n",
            "        [0.2023],\n",
            "        [0.2023],\n",
            "        ...,\n",
            "        [0.2023],\n",
            "        [0.2023],\n",
            "        [0.2023]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2023],\n",
            "        [0.2023],\n",
            "        [0.2023],\n",
            "        ...,\n",
            "        [0.2023],\n",
            "        [0.2023],\n",
            "        [0.2023]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2023],\n",
            "        [0.2023],\n",
            "        [0.2023],\n",
            "        ...,\n",
            "        [0.2023],\n",
            "        [0.2023],\n",
            "        [0.2023]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2471],\n",
            "        [0.2393],\n",
            "        [0.2284],\n",
            "        ...,\n",
            "        [0.2089],\n",
            "        [0.2089],\n",
            "        [0.2089]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2089],\n",
            "        [0.2089],\n",
            "        [0.2089],\n",
            "        ...,\n",
            "        [0.2089],\n",
            "        [0.2089],\n",
            "        [0.2089]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2089],\n",
            "        [0.2089],\n",
            "        [0.2089],\n",
            "        ...,\n",
            "        [0.2089],\n",
            "        [0.2089],\n",
            "        [0.2089]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2089],\n",
            "        [0.2089],\n",
            "        [0.2089],\n",
            "        ...,\n",
            "        [0.2089],\n",
            "        [0.2089],\n",
            "        [0.2089]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2089],\n",
            "        [0.2089],\n",
            "        [0.2089],\n",
            "        ...,\n",
            "        [0.2089],\n",
            "        [0.2089],\n",
            "        [0.2089]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2499],\n",
            "        [0.2424],\n",
            "        [0.2315],\n",
            "        ...,\n",
            "        [0.2119],\n",
            "        [0.2119],\n",
            "        [0.2119]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2119],\n",
            "        [0.2119],\n",
            "        [0.2119],\n",
            "        ...,\n",
            "        [0.2119],\n",
            "        [0.2119],\n",
            "        [0.2119]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2119],\n",
            "        [0.2119],\n",
            "        [0.2119],\n",
            "        ...,\n",
            "        [0.2119],\n",
            "        [0.2119],\n",
            "        [0.2119]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2119],\n",
            "        [0.2119],\n",
            "        [0.2119],\n",
            "        ...,\n",
            "        [0.2119],\n",
            "        [0.2119],\n",
            "        [0.2119]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2119],\n",
            "        [0.2119],\n",
            "        [0.2119],\n",
            "        ...,\n",
            "        [0.2119],\n",
            "        [0.2119],\n",
            "        [0.2119]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2496],\n",
            "        [0.2429],\n",
            "        [0.2323],\n",
            "        ...,\n",
            "        [0.2130],\n",
            "        [0.2130],\n",
            "        [0.2130]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2130],\n",
            "        [0.2130],\n",
            "        [0.2130],\n",
            "        ...,\n",
            "        [0.2130],\n",
            "        [0.2130],\n",
            "        [0.2130]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2130],\n",
            "        [0.2130],\n",
            "        [0.2130],\n",
            "        ...,\n",
            "        [0.2130],\n",
            "        [0.2130],\n",
            "        [0.2130]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2130],\n",
            "        [0.2130],\n",
            "        [0.2130],\n",
            "        ...,\n",
            "        [0.2130],\n",
            "        [0.2130],\n",
            "        [0.2130]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2130],\n",
            "        [0.2130],\n",
            "        [0.2130],\n",
            "        ...,\n",
            "        [0.2130],\n",
            "        [0.2130],\n",
            "        [0.2130]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2523],\n",
            "        [0.2464],\n",
            "        [0.2363],\n",
            "        ...,\n",
            "        [0.2172],\n",
            "        [0.2172],\n",
            "        [0.2172]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2172],\n",
            "        [0.2172],\n",
            "        [0.2172],\n",
            "        ...,\n",
            "        [0.2172],\n",
            "        [0.2172],\n",
            "        [0.2172]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2172],\n",
            "        [0.2172],\n",
            "        [0.2172],\n",
            "        ...,\n",
            "        [0.2172],\n",
            "        [0.2172],\n",
            "        [0.2172]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2172],\n",
            "        [0.2172],\n",
            "        [0.2172],\n",
            "        ...,\n",
            "        [0.2172],\n",
            "        [0.2172],\n",
            "        [0.2172]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2172],\n",
            "        [0.2172],\n",
            "        [0.2172],\n",
            "        ...,\n",
            "        [0.2172],\n",
            "        [0.2172],\n",
            "        [0.2172]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2547],\n",
            "        [0.2494],\n",
            "        [0.2395],\n",
            "        ...,\n",
            "        [0.2204],\n",
            "        [0.2204],\n",
            "        [0.2204]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2204],\n",
            "        [0.2204],\n",
            "        [0.2204],\n",
            "        ...,\n",
            "        [0.2204],\n",
            "        [0.2204],\n",
            "        [0.2204]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2204],\n",
            "        [0.2204],\n",
            "        [0.2204],\n",
            "        ...,\n",
            "        [0.2204],\n",
            "        [0.2204],\n",
            "        [0.2204]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2204],\n",
            "        [0.2204],\n",
            "        [0.2204],\n",
            "        ...,\n",
            "        [0.2204],\n",
            "        [0.2204],\n",
            "        [0.2204]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2204],\n",
            "        [0.2204],\n",
            "        [0.2204],\n",
            "        ...,\n",
            "        [0.2204],\n",
            "        [0.2204],\n",
            "        [0.2204]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2529],\n",
            "        [0.2483],\n",
            "        [0.2387],\n",
            "        ...,\n",
            "        [0.2198],\n",
            "        [0.2198],\n",
            "        [0.2198]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2198],\n",
            "        [0.2198],\n",
            "        [0.2198],\n",
            "        ...,\n",
            "        [0.2198],\n",
            "        [0.2198],\n",
            "        [0.2198]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2198],\n",
            "        [0.2198],\n",
            "        [0.2198],\n",
            "        ...,\n",
            "        [0.2198],\n",
            "        [0.2198],\n",
            "        [0.2198]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2198],\n",
            "        [0.2198],\n",
            "        [0.2198],\n",
            "        ...,\n",
            "        [0.2198],\n",
            "        [0.2198],\n",
            "        [0.2198]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2198],\n",
            "        [0.2198],\n",
            "        [0.2198],\n",
            "        ...,\n",
            "        [0.2198],\n",
            "        [0.2198],\n",
            "        [0.2198]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2508],\n",
            "        [0.2473],\n",
            "        [0.2383],\n",
            "        ...,\n",
            "        [0.2199],\n",
            "        [0.2199],\n",
            "        [0.2199]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2199],\n",
            "        [0.2199],\n",
            "        [0.2199],\n",
            "        ...,\n",
            "        [0.2199],\n",
            "        [0.2199],\n",
            "        [0.2199]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2199],\n",
            "        [0.2199],\n",
            "        [0.2199],\n",
            "        ...,\n",
            "        [0.2199],\n",
            "        [0.2199],\n",
            "        [0.2199]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2199],\n",
            "        [0.2199],\n",
            "        [0.2199],\n",
            "        ...,\n",
            "        [0.2199],\n",
            "        [0.2199],\n",
            "        [0.2199]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2199],\n",
            "        [0.2199],\n",
            "        [0.2199],\n",
            "        ...,\n",
            "        [0.2199],\n",
            "        [0.2199],\n",
            "        [0.2199]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2541],\n",
            "        [0.2513],\n",
            "        [0.2425],\n",
            "        ...,\n",
            "        [0.2240],\n",
            "        [0.2240],\n",
            "        [0.2240]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2240],\n",
            "        [0.2240],\n",
            "        [0.2240],\n",
            "        ...,\n",
            "        [0.2240],\n",
            "        [0.2240],\n",
            "        [0.2240]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2240],\n",
            "        [0.2240],\n",
            "        [0.2240],\n",
            "        ...,\n",
            "        [0.2240],\n",
            "        [0.2240],\n",
            "        [0.2240]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2240],\n",
            "        [0.2240],\n",
            "        [0.2240],\n",
            "        ...,\n",
            "        [0.2240],\n",
            "        [0.2240],\n",
            "        [0.2240]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2240],\n",
            "        [0.2240],\n",
            "        [0.2240],\n",
            "        ...,\n",
            "        [0.2240],\n",
            "        [0.2240],\n",
            "        [0.2240]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2621],\n",
            "        [0.2605],\n",
            "        [0.2521],\n",
            "        ...,\n",
            "        [0.2334],\n",
            "        [0.2334],\n",
            "        [0.2334]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2334],\n",
            "        [0.2334],\n",
            "        [0.2334],\n",
            "        ...,\n",
            "        [0.2334],\n",
            "        [0.2334],\n",
            "        [0.2334]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2334],\n",
            "        [0.2334],\n",
            "        [0.2334],\n",
            "        ...,\n",
            "        [0.2334],\n",
            "        [0.2334],\n",
            "        [0.2334]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2334],\n",
            "        [0.2334],\n",
            "        [0.2334],\n",
            "        ...,\n",
            "        [0.2334],\n",
            "        [0.2334],\n",
            "        [0.2334]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2334],\n",
            "        [0.2334],\n",
            "        [0.2334],\n",
            "        ...,\n",
            "        [0.2334],\n",
            "        [0.2334],\n",
            "        [0.2334]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2752],\n",
            "        [0.2747],\n",
            "        [0.2665],\n",
            "        ...,\n",
            "        [0.2467],\n",
            "        [0.2467],\n",
            "        [0.2467]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2467],\n",
            "        [0.2467],\n",
            "        [0.2467],\n",
            "        ...,\n",
            "        [0.2467],\n",
            "        [0.2467],\n",
            "        [0.2467]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2467],\n",
            "        [0.2467],\n",
            "        [0.2467],\n",
            "        ...,\n",
            "        [0.2467],\n",
            "        [0.2467],\n",
            "        [0.2467]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2467],\n",
            "        [0.2467],\n",
            "        [0.2467],\n",
            "        ...,\n",
            "        [0.2467],\n",
            "        [0.2467],\n",
            "        [0.2467]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2467],\n",
            "        [0.2467],\n",
            "        [0.2467],\n",
            "        ...,\n",
            "        [0.2467],\n",
            "        [0.2467],\n",
            "        [0.2467]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2887],\n",
            "        [0.2893],\n",
            "        [0.2811],\n",
            "        ...,\n",
            "        [0.2604],\n",
            "        [0.2604],\n",
            "        [0.2604]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2604],\n",
            "        [0.2604],\n",
            "        [0.2604],\n",
            "        ...,\n",
            "        [0.2604],\n",
            "        [0.2604],\n",
            "        [0.2604]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2604],\n",
            "        [0.2604],\n",
            "        [0.2604],\n",
            "        ...,\n",
            "        [0.2604],\n",
            "        [0.2604],\n",
            "        [0.2604]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2604],\n",
            "        [0.2604],\n",
            "        [0.2604],\n",
            "        ...,\n",
            "        [0.2604],\n",
            "        [0.2604],\n",
            "        [0.2604]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2604],\n",
            "        [0.2604],\n",
            "        [0.2604],\n",
            "        ...,\n",
            "        [0.2604],\n",
            "        [0.2604],\n",
            "        [0.2604]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3033],\n",
            "        [0.3053],\n",
            "        [0.2975],\n",
            "        ...,\n",
            "        [0.2758],\n",
            "        [0.2758],\n",
            "        [0.2758]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2758],\n",
            "        [0.2758],\n",
            "        [0.2758],\n",
            "        ...,\n",
            "        [0.2758],\n",
            "        [0.2758],\n",
            "        [0.2758]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2758],\n",
            "        [0.2758],\n",
            "        [0.2758],\n",
            "        ...,\n",
            "        [0.2758],\n",
            "        [0.2758],\n",
            "        [0.2758]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2758],\n",
            "        [0.2758],\n",
            "        [0.2758],\n",
            "        ...,\n",
            "        [0.2758],\n",
            "        [0.2758],\n",
            "        [0.2758]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2758],\n",
            "        [0.2758],\n",
            "        [0.2758],\n",
            "        ...,\n",
            "        [0.2758],\n",
            "        [0.2758],\n",
            "        [0.2758]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3114],\n",
            "        [0.3134],\n",
            "        [0.3053],\n",
            "        ...,\n",
            "        [0.2828],\n",
            "        [0.2828],\n",
            "        [0.2828]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2828],\n",
            "        [0.2828],\n",
            "        [0.2828],\n",
            "        ...,\n",
            "        [0.2828],\n",
            "        [0.2828],\n",
            "        [0.2828]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2828],\n",
            "        [0.2828],\n",
            "        [0.2828],\n",
            "        ...,\n",
            "        [0.2828],\n",
            "        [0.2828],\n",
            "        [0.2828]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2828],\n",
            "        [0.2828],\n",
            "        [0.2828],\n",
            "        ...,\n",
            "        [0.2828],\n",
            "        [0.2828],\n",
            "        [0.2828]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2828],\n",
            "        [0.2828],\n",
            "        [0.2828],\n",
            "        ...,\n",
            "        [0.2828],\n",
            "        [0.2828],\n",
            "        [0.2828]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3100],\n",
            "        [0.3118],\n",
            "        [0.3037],\n",
            "        ...,\n",
            "        [0.2812],\n",
            "        [0.2812],\n",
            "        [0.2812]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2812],\n",
            "        [0.2812],\n",
            "        [0.2812],\n",
            "        ...,\n",
            "        [0.2812],\n",
            "        [0.2812],\n",
            "        [0.2812]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2812],\n",
            "        [0.2812],\n",
            "        [0.2812],\n",
            "        ...,\n",
            "        [0.2812],\n",
            "        [0.2812],\n",
            "        [0.2812]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2812],\n",
            "        [0.2812],\n",
            "        [0.2812],\n",
            "        ...,\n",
            "        [0.2812],\n",
            "        [0.2812],\n",
            "        [0.2812]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2812],\n",
            "        [0.2812],\n",
            "        [0.2812],\n",
            "        ...,\n",
            "        [0.2812],\n",
            "        [0.2812],\n",
            "        [0.2812]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.3033],\n",
            "        [0.3054],\n",
            "        [0.2977],\n",
            "        ...,\n",
            "        [0.2757],\n",
            "        [0.2757],\n",
            "        [0.2757]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2757],\n",
            "        [0.2757],\n",
            "        [0.2757],\n",
            "        ...,\n",
            "        [0.2757],\n",
            "        [0.2757],\n",
            "        [0.2757]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2757],\n",
            "        [0.2757],\n",
            "        [0.2757],\n",
            "        ...,\n",
            "        [0.2757],\n",
            "        [0.2757],\n",
            "        [0.2757]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2757],\n",
            "        [0.2757],\n",
            "        [0.2757],\n",
            "        ...,\n",
            "        [0.2757],\n",
            "        [0.2757],\n",
            "        [0.2757]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2757],\n",
            "        [0.2757],\n",
            "        [0.2757],\n",
            "        ...,\n",
            "        [0.2757],\n",
            "        [0.2757],\n",
            "        [0.2757]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2993],\n",
            "        [0.3029],\n",
            "        [0.2960],\n",
            "        ...,\n",
            "        [0.2750],\n",
            "        [0.2750],\n",
            "        [0.2750]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2750],\n",
            "        [0.2750],\n",
            "        [0.2750],\n",
            "        ...,\n",
            "        [0.2750],\n",
            "        [0.2750],\n",
            "        [0.2750]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2750],\n",
            "        [0.2750],\n",
            "        [0.2750],\n",
            "        ...,\n",
            "        [0.2750],\n",
            "        [0.2750],\n",
            "        [0.2750]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2750],\n",
            "        [0.2750],\n",
            "        [0.2750],\n",
            "        ...,\n",
            "        [0.2750],\n",
            "        [0.2750],\n",
            "        [0.2750]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2750],\n",
            "        [0.2750],\n",
            "        [0.2750],\n",
            "        ...,\n",
            "        [0.2750],\n",
            "        [0.2750],\n",
            "        [0.2750]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2996],\n",
            "        [0.3036],\n",
            "        [0.2968],\n",
            "        ...,\n",
            "        [0.2759],\n",
            "        [0.2759],\n",
            "        [0.2759]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2759],\n",
            "        [0.2759],\n",
            "        [0.2759],\n",
            "        ...,\n",
            "        [0.2759],\n",
            "        [0.2759],\n",
            "        [0.2759]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2759],\n",
            "        [0.2759],\n",
            "        [0.2759],\n",
            "        ...,\n",
            "        [0.2759],\n",
            "        [0.2759],\n",
            "        [0.2759]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2759],\n",
            "        [0.2759],\n",
            "        [0.2759],\n",
            "        ...,\n",
            "        [0.2759],\n",
            "        [0.2759],\n",
            "        [0.2759]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2759],\n",
            "        [0.2759],\n",
            "        [0.2759],\n",
            "        ...,\n",
            "        [0.2759],\n",
            "        [0.2759],\n",
            "        [0.2759]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "==================\n",
            "input shape: torch.Size([128, 20, 3])\n",
            "output shape: torch.Size([5, 128, 1])\n",
            "dec inp shape: torch.Size([128, 3])\n",
            "dec hidden inp shape: torch.Size([32, 32])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2987],\n",
            "        [0.3016],\n",
            "        [0.2942],\n",
            "        ...,\n",
            "        [0.2725],\n",
            "        [0.2725],\n",
            "        [0.2725]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2725],\n",
            "        [0.2725],\n",
            "        [0.2725],\n",
            "        ...,\n",
            "        [0.2725],\n",
            "        [0.2725],\n",
            "        [0.2725]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2725],\n",
            "        [0.2725],\n",
            "        [0.2725],\n",
            "        ...,\n",
            "        [0.2725],\n",
            "        [0.2725],\n",
            "        [0.2725]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2725],\n",
            "        [0.2725],\n",
            "        [0.2725],\n",
            "        ...,\n",
            "        [0.2725],\n",
            "        [0.2725],\n",
            "        [0.2725]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n",
            "=====\n",
            "dec hidden size: torch.Size([32, 32])\n",
            "final dec out: tensor([[0.2725],\n",
            "        [0.2725],\n",
            "        [0.2725],\n",
            "        ...,\n",
            "        [0.2725],\n",
            "        [0.2725],\n",
            "        [0.2725]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "dec out size: torch.Size([128, 3])\n",
            "final dec out size: torch.Size([128, 1])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-192-f40542ab3ed0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0mbest_vloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1_000_000.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mavg_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mavg_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavg_train_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-192-f40542ab3ed0>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch, dl)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# print(\"model_inp shape:\",model_inp.shape,model_inp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "\n",
        "def train_one_epoch(epoch: int, dl):\n",
        "    model.train(True)\n",
        "    last_loss = 0.\n",
        "    print_batch_loss = len(dl)/Model_Info.count_print_batch\n",
        "    print_batch_count = 0.0\n",
        "    run_loss = 0.0\n",
        "    total_loss = 0.0\n",
        "    num_run = 0.0\n",
        "    for i, (model_inp, model_out) in enumerate(dl):\n",
        "\n",
        "        optim.zero_grad()\n",
        "\n",
        "        if model_name == \"seq2seq_lstm\":\n",
        "            pass\n",
        "            #print(\"seq2seq\")\n",
        "            #model_inp = model_inp.swapaxes(0, 1)\n",
        "            #model_out = model_out.swapaxes(0, 1)\n",
        "        elif model_name == \"basic_lstm\":\n",
        "            model_out = model_out.view(model_out.shape[0],-1)   \n",
        "        if torch.cuda.is_available():\n",
        "            model_inp = model_inp.cuda()\n",
        "            model_out = model_out.cuda()\n",
        "        if model_name == \"seq2seq_lstm\":\n",
        "            pred_out = model.forward(model_inp, model_out)\n",
        "        else:\n",
        "            pred_out = model.forward(model_inp)\n",
        "            \n",
        "        if torch.cuda.is_available():\n",
        "            pred_out = pred_out.cuda()\n",
        "        torch.set_printoptions(threshold=15)\n",
        "        # print(\"pred out shape:\",pred_out.shape,pred_out)\n",
        "        # print(\"actual out shape:\",torch.squeeze(model_out).shape,model_out)\n",
        "        # print(\"model_inp shape:\",model_inp.shape,model_inp)\n",
        "        loss = criterion(pred_out, torch.squeeze(model_out))\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        run_loss += loss.item()*model_inp.size(0)\n",
        "        total_loss += loss.item()*model_inp.size(0)\n",
        "        num_run += model_inp.size(0)\n",
        "        print_batch_count += 1\n",
        "        if Model_Info.display_batch_train_data:\n",
        "            if (((i+1) % print_batch_loss) == 0 and i != 0):\n",
        "                last_loss = total_loss/num_run\n",
        "                train_loss.append(((i+1)+epoch*len(dl), last_loss))\n",
        "                print('    epoch {} batch {}/{} loss: {}'.format(epoch,\n",
        "                    i+1, len(dl), last_loss))\n",
        "                run_loss = 0.0\n",
        "                print_batch_count = 0.0\n",
        "    return total_loss/num_run\n",
        "\n",
        "\n",
        "def test_one_epoch(epoch: int, dl):\n",
        "    model.train(False)\n",
        "    run_loss = 0.0\n",
        "    batch_count = 0\n",
        "    for i, (val_inp, val_out) in enumerate(dl):\n",
        "        if model_name == \"seq2seq_lstm\":\n",
        "            pass\n",
        "            #print(\"seq2seq\")\n",
        "            #val_inp = val_inp.swapaxes(0, 1)\n",
        "            #val_out = val_out.swapaxes(0, 1)\n",
        "        elif model_name == \"basic_lstm\":\n",
        "            val_out = val_out.view(val_out.shape[0],-1)\n",
        "        if torch.cuda.is_available():\n",
        "            val_inp = val_inp.cuda()\n",
        "            val_out = val_out.cuda()\n",
        "        \n",
        "\n",
        "        out = model.forward(val_inp)\n",
        "        batch_count += val_inp.size(0)\n",
        "        # SQUEEZING THE 1 DIM:\n",
        "        #print(\"SQUEEZE DIM\")\n",
        "        #print(val_out)\n",
        "        #print(val_out.shape)\n",
        "        #print(val_out.view(val_out.shape[0],-1).shape)\n",
        "        #val_out = val_out.view(val_out.shape[0],-1)\n",
        "        \n",
        "        #print(val_out)\n",
        "        #print(\"END SQUEEZE DIM\")\n",
        "        loss = criterion(out, torch.squeeze(val_out))\n",
        "        run_loss += loss.item()*val_inp.size(0)\n",
        "    return run_loss/batch_count\n",
        "\n",
        "# train loop:\n",
        "best_vloss = 1_000_000.\n",
        "for i in range(100_000):\n",
        "    avg_train_loss = train_one_epoch(i, train_dl)\n",
        "    avg_val_loss = test_one_epoch(i, test_dl)\n",
        "    train_loss.append((i,avg_train_loss))\n",
        "    val_loss.append((i, avg_val_loss))\n",
        "    \n",
        "    print(f\"epoch {i}: avg train loss: {avg_train_loss} avg val loss: {avg_val_loss}\")\n",
        "    if Model_Info.save_model:\n",
        "        if avg_val_loss < best_vloss:\n",
        "            best_vloss = avg_val_loss\n",
        "            print(f\"saving: {best_vloss}\")\n",
        "            model_path = '{}{}_{}_{}'.format(\n",
        "                Model_Info.model_save_path, \"model_name\", best_vloss, i)\n",
        "            torch.save(model.state_dict(), model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "dn8N6t7_7XwC",
        "outputId": "91fc67a5-b360-4000-d396-3d257765dfc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgddZn28e/dezaSEMIIJJAgKElISEIT4oTVoAMuRBRMEBAYlHHhVQdHjYqIjIzg8AIucYkCEwENvHHQqGAchk1mANNBtrCMYZs0CCQhCVm6k16e94+q7pycVHefXk4vyf25rr66Tv1+VfWc6j51n6o6p0oRgZmZWb6Svi7AzMz6JweEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJA7MYk3Snp3J7u25ckvSjppCLM915JH0uHz5L0h0L6dmE5B0raLKm0q7X2N5L+RtL9kjZJ+r99XU9XSLpM0s19XUd/44DoZ9KNR8tPs6S6nMdndWZeEXFKRCzq6b79kaT5ku7PGL+PpO2SDi90XhFxS0S8u4fq2inQIuJ/I2JoRDT1xPzzlhWSDunp+RbgQmAtsFdEfL67M5N0nqSmvNfCZkn7d79U6wwHRD+TbjyGRsRQ4H+B9+eMu6Wln6SyvquyX7oZ+FtJ4/PGzwOeiIgn+6CmPcVBwFPRhW/dtvN//GDuayH9eaV7ZVpnOSAGCEknSKqV9CVJrwI3Shop6beS1khanw6PyZkm97DJeZIekHR12vcFSad0se/4nEMKd0la0NbueYE1/rOk/0rn9wdJ++S0nyPpJUnrJH21rfUTEbXA3cA5eU0fBX7WUR15NZ8n6YGcx++S9IykjZK+Dyin7a2S7k7rWyvpFkkj0rabgAOB36TvgL8oaVz6Tr8s7bO/pKWS3pC0StLHc+Z9maTbJP0sXTcrJVW3tQ7aIml4Oo816bq8RFJJ2naIpPvS57ZW0q3peEm6VtLrkt6U9ETWXpikfwPOBb6YPseTJFVKuk7SK+nPdZIq0/67/B934fm8KOnLkp5K/5Y3SqrKaf94ui7fSNft/jltkyT9R9r2mqSv5My6oq11ndb7ctr2rKTZna17IHJADCxvAfYmecd2Icnf78b08YFAHfD9dqY/GngW2Af4NnC9JHWh78+BPwGjgMvYdaOcq5AaPwKcD+wLVAD/BCBpIvDDdP77p8vL3KinFuXWIuntwNS03s6uq5Z57AP8O3AJybp4DpiV2wX4VlrfBGAsyTohIs5h573Ab2csYjFQm05/OvAvkt6Z035q2mcEsLSQmjN8DxgOHAwcTxKa56dt/wz8ARhJsm6/l45/N3Ac8LZ02g8D6/JnHBHnAbcA306f413AV4GZJOv+CGAGyfprkf9/3BVnAX8HvDWt8RKAdN19K613P+AlkvWHpGHAXcDvSdb3IcB/5swzc12n/0cXAUdFxLB0uS92se6BJSL8009/SP4JT0qHTwC2A1Xt9J8KrM95fC/wsXT4PGBVTttgIIC3dKYvyca1ERic034zcHOBzymrxktyHn8K+H06fCmwOKdtSLoOTmpj3oOBN4G/TR9fAfy6i+vqgXT4o8BDOf1EskH/WBvz/QDw56y/Yfp4XLouy0jCpAkYltP+LeDf0uHLgLty2iYCde2s2wAOyRtXmq6ziTnj/gG4Nx3+GbAQGJM33TuB/yHZ0Jd08Df9N+CbOY+fA96T8/jvgBc78X98Xvo/tiHn57m8dfqJnMfvaWkHricJq5a2oUBDut7PzP3b5C2zzXVNEiSvAycB5d15TQ+0H+9BDCxrIqK+5YGkwZJ+nB42eBO4Hxihtj8h82rLQERsTQeHdrLv/sAbOeMAVrdVcIE1vpozvDWnpv1z5x0RW8h4F5tX5/8DPpru7ZxFsgHsyrpqkV9D5D5W8gmexenhhzdJwnKfXWfT5rzfiIhNOeNeAg7IeZy/bqrUufNP+wDl6XyzlvFFktD7U3pY5e8BIuJuknfQC4DXJS2UtFeBy9w/Y3m5J5h3+j9uw0MRMSLn56157bn/c7nz32nZEbGZ5H/mAJJAfq6dZWau64hYBXyOJEReT//ee8QJcwfEwJJ/EvDzwNuBoyNiL5JDApBzjLwI/grsLWlwzrix7fTvTo1/zZ13usxRHUyziOTwwruAYcBvullHfg1i5+f7LyR/l8npfM/Om2d7J25fIVmXw3LGHQi83EFNnbGW5B30QVnLiIhXI+LjEbE/yZ7FD5R+EioivhsRR5K8m34b8IUCl/lKxvJyTzD3xCWkc/8GufPfadmShpD8z7xMEioHd2VhEfHziDgmnXcAV3VlPgONA2JgG0ZyLH2DpL2Brxd7gRHxElADXCapQtI7gPcXqcYlwPskHSOpAricjv9n/0hySGIhyeGp7d2s43fAJEkfTN+5f4bkUFuLYcBmYKOkA9h1I/oabWyUImI18N/AtyRVSZoCXECyF9JVFem8qnJO3N4GXCFpmKSDgItbliHpDO04Wb+eZOPXLOkoSUdLKge2APVAc4E1/AK4RNLo9BzOpd18Tlk+LWlM+rf8KnBrzrLPlzQ1PTH+L8DDEfEi8FtgP0mfS0+kD5N0dEcLkvR2Se9M51dP8n9U6LoY0BwQA9t1wCCSd4kPkZx86w1nAe8g2XX/JsmLc1sbfbtcY0SsBD5NcpL5ryQbsNoOpgmSw0oHpb+7VUdErAXOAK4keb6HAv+V0+UbwHRgI0mY/HveLL5FsrHcIOmfMhZxJsnx8VeA24GvR3Kit6tWkmzAWn7OB/4PyUb+eeABkvV5Q9r/KOBhSZtJTsx+NiKeB/YCfkKyzl8iee7/WmAN3yR5E/E48ATwSDquM96hXb8HcVRO+89JTq4/T3LY6JsA6br7GvBLkv+Zt5J81Jn0UN67SN7QvAr8BTixgFoqSf7+a9Pp9gW+3MnnMyApPQlj1mVKPhr5TEQUfQ/GTNKLJB8S6E6QWgG8B2Gdlh5+eKukEkknA3OAX/V1XWbWs/xtXOuKt5AcShlFcsjnkxHx574tycx6mg8xmZlZJh9iMjOzTLvNIaZ99tknxo0b19dlmJkNKCtWrFgbEaOz2nabgBg3bhw1NTV9XYaZ2YAi6aW22nyIyczMMjkgzMwskwPCzMwyOSDMzCyTA8LMzDI5IMzMLJMDwszMMu0234PoqtffrOdnD77EiMHljBhcwcj094jB5YwcXMFeVWWUlTpHzWzPU9SASK/0+R2S++L+NCKuzGuvJLlm/5Ek15ufGxEvpjeH+TFQTXJjjs9GxL3FqPHlDXX84N5VNLdzSaq9qsoyw2P4oPKdxuX2GVZZRklJMW/sZmZWXEULiPRevwtIbtBRCyyXtDQinsrpdgHJjeMPkTSP5DZ+c4GPA0TEZEn7AndKOioievwuTtMOHMmqK97Dpm2NbNi6nfVbG9iwdTsb0t/rtzawsa6B9TnjXli7hQ1bt/NmfWOb8y0RSXAMKm8NjxGDyxkxKA2RIUnbyNZwSfoMqSgluaulmVnfKuYexAxgVXp3KiQtJrlvQG5AzCG5ETgkt5f8fnrP34nA3QAR8bqkDSR7E38qRqElJWL4oHKGDyrnoI7ueJyjsamZN+sbdwqPDVtzwqQuDZitDbz2Zj3PvrqJDVu3s2V7U5vzLC9Va7CMHFzB8MF5eymDdt2TGTG4nKry0h5YE2ZmOxQzIA4guUl4i1og//6vrX0iolHSRpJ7DDwGnCrpFyQ3Jz8y/V2UgOiqstIS9h5Swd5DKjo13fbGZjbUtYRKEigbW4KlbuegWf3GVp6oTYa3Nba9A1VVXsKIQTuHxo4QKW9tyz0MNnxQORVlPr9iZtn660nqG4AJJPe1fYnkxu67vO2WdCFwIcCBBx7Ym/V1S0VZCfsOq2LfYVUdd85R39DUuneyI1TS4boG1m/ZETCrXt/cerissZ0TLEMry5JzKUPKswMmbRs+aOdgKfX5FbPdXjED4mWSd/0txqTjsvrUSioDhgPr0hvP/2NLJ0n/DfxP/gIiYiGwEKC6unq3v/NRVXkp+w0fxH7DBxU8TUSwZXsT67ds3+VcyoY0YFr2ZtZv3c4rG+paA6e9E/eVZSVUlZdSVV5CZVnyu6q8tHV8ZVkpleUlVOX8bqtvy/jKXcbnzq+Ecn+azKxXFTMglgOHShpPEgTzgI/k9VkKnAs8CJwO3B0RIWkwyd3utkh6F9CYd3LbCiSJoZVlDK0s2ymtO9LcHGyqb2w9j5J/4r6+oYltjc3UNzTlDTezZVsj6zZvZ1tj8nhbYxPbGpqpb2yioanrOV5aIqrKSqgsL6UqDY6KDoIqP2Raps2dR1bf1tAqK/Gn0WyPVbSASM8pXAQsI/mY6w0RsVLS5UBNRCwFrgdukrQKeIMkRAD2BZZJaiYJl3OKVadlKykRwweXM3xw507cd6SpOVqDo72QaQmVzL6tgbPz+A3peZrcedSnwdSdO+tWlJVk7zFl7CVVZoRMS2hVte5J7dhbGpQG005tDiXrJ3abe1JXV1eHbxhkWSKChqbYESwNTTvt3dS3FUQZ7dsygyp7Htvb+VBBRyrKSlr3cAZVlO44RNcSKDkhVNUaMjsHTX4wVbYGUsku/R1Iey5JKyKiOqutv56kNusxkqgoU/KJrc59LqBbmpuD7U07wqYlVOq279iz2Zbb1tBEfWNz0p4TZq3TNybDG+saeD1jfH1DNwKptCRvryYNkZxzQ/nBNKi8dEdgtRVMueGVcyjPH3IYGBwQZkVSUiKqSkp77TsqEbHT3k9LINXnBc221pBqaj1MV5+3Z9USUvUNTWyqb2TNpm07HQ6s62YglZdqx15NRVa47AiqQeWlVFXsOBw3qKWtIgmdQRW5h+pKWx8P8uG6bnNAmO0mJLVuJHtDSyBty9uLyQ+Rbbu0NbfuSW3LCLDcQKrbnsynrqGpy4fsKnNCpGWvZ1D5jnGVOaEzKA2dqpz++cHTGlo7jds994ocEGbWJbmBNJzyoi+v5QMOLaHREix1DTv2iOpawml7E3V5YZXsFTXv1HfD1oZkmpx51jW0faWD9lSUliThUZG7B5QTKhnjW8a1hM6OPaOd94SqKnYc/uvNj3s7IMxsQCgtEYMryhhcUdzNVsueUcthth2BtOPwW11D7rgm6rY37/y4Ycd02xqaWbt5e+u43JBr77tGbSkr0Y49n4okWN552N8w/5TDenxdOCDMzHL01qG6iJYPMTTn7PXk7wnlBU/enk7LuL2HFGcPzgFhZtYHJKVfxixl+KDiH6LrCl+7wMzMMjkgzMwskwPCzMwyOSDMzCyTA8LMzDI5IMzMLJMDwszMMjkgzMwskwPCzMwyOSDMzCyTA8LMzDI5IMzMLJMDwszMMjkgzMwskwPCzMwyOSDMzCxTUQNC0smSnpW0StL8jPZKSbem7Q9LGpeOL5e0SNITkp6W9OVi1mlmZrsqWkBIKgUWAKcAE4EzJU3M63YBsD4iDgGuBa5Kx58BVEbEZOBI4B9awsPMzHpHMfcgZgCrIuL5iNgOLAbm5PWZAyxKh5cAsyUJCGCIpDJgELAdeLOItZqZWZ5iBsQBwOqcx7XpuMw+EdEIbARGkYTFFuCvwP8CV0fEG/kLkHShpBpJNWvWrOn5Z2BmtgfrryepZwBNwP7AeODzkg7O7xQRCyOiOiKqR48e3ds1mpnt1ooZEC8DY3Mej0nHZfZJDycNB9YBHwF+HxENEfE68F9AdRFrNTOzPMUMiOXAoZLGS6oA5gFL8/osBc5Nh08H7o6IIDms9E4ASUOAmcAzRazVzMzyFC0g0nMKFwHLgKeB2yJipaTLJZ2adrseGCVpFXAx0PJR2AXAUEkrSYLmxoh4vFi1mpnZrpS8YR/4qquro6ampq/LMDMbUCStiIjMQ/j99SS1mZn1MQeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWaaiBoSkkyU9K2mVpPkZ7ZWSbk3bH5Y0Lh1/lqRHc36aJU0tZq1mZrazogWEpFJgAXAKMBE4U9LEvG4XAOsj4hDgWuAqgIi4JSKmRsRU4BzghYh4tFi1mpnZroq5BzEDWBURz0fEdmAxMCevzxxgUTq8BJgtSXl9zkynNTOzXlTMgDgAWJ3zuDYdl9knIhqBjcCovD5zgV9kLUDShZJqJNWsWbOmR4o2M7NEvz5JLeloYGtEPJnVHhELI6I6IqpHjx7dy9WZme3eihkQLwNjcx6PScdl9pFUBgwH1uW0z6ONvQczMyuuYgbEcuBQSeMlVZBs7Jfm9VkKnJsOnw7cHREBIKkE+DA+/2Bm1ifKijXjiGiUdBGwDCgFboiIlZIuB2oiYilwPXCTpFXAGyQh0uI4YHVEPF+sGs3MrG1K37APeNXV1VFTU9PXZZiZDSiSVkREdVZbvz5JbWZmfccBYWZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmRwQZmaWyQFhZmaZinYtJjPb/TU0NFBbW0t9fX1fl2IdqKqqYsyYMZSXlxc8jQPCzLqstraWYcOGMW7cOHa9GaT1FxHBunXrqK2tZfz48QVP50NMZtZl9fX1jBo1yuHQz0li1KhRnd7Tc0CYWbc4HAaGrvydHBBmtkcZOnQoAK+88gqnn356Zp8TTjiBjm4fcN1117F169bWx+95z3vYsGFDt+u77LLLuPrqq7s9n57ggDCzPdL+++/PkiVLujx9fkDccccdjBgxoidK6zccEGY2YM2fP58FCxa0Pm55971582Zmz57N9OnTmTx5Mr/+9a93mfbFF1/k8MMPB6Curo558+YxYcIETjvtNOrq6lr7ffKTn6S6uppJkybx9a9/HYDvfve7vPLKK5x44omceOKJAIwbN461a9cCcM0113D44Ydz+OGHc91117Uub8KECXz84x9n0qRJvPvd795pOVkeffRRZs6cyZQpUzjttNNYv3596/InTpzIlClTmDcvuRHnfffdx9SpU5k6dSrTpk1j06ZNXVqnufwpJjPrEd/4zUqeeuXNHp3nxP334uvvn9Rm+9y5c/nc5z7Hpz/9aQBuu+02li1bRlVVFbfffjt77bUXa9euZebMmZx66qltHof/4Q9/yODBg3n66ad5/PHHmT59emvbFVdcwd57701TUxOzZ8/m8ccf5zOf+QzXXHMN99xzD/vss89O81qxYgU33ngjDz/8MBHB0UcfzfHHH8/IkSP5y1/+wi9+8Qt+8pOf8OEPf5hf/vKXnH322W0+v49+9KN873vf4/jjj+fSSy/lG9/4Btdddx1XXnklL7zwApWVla2Hta6++moWLFjArFmz2Lx5M1VVVQWv57Z4D8LMBqxp06bx+uuv88orr/DYY48xcuRIxo4dS0Twla98hSlTpnDSSSfx8ssv89prr7U5n/vvv791Qz1lyhSmTJnS2nbbbbcxffp0pk2bxsqVK3nqqafaremBBx7gtNNOY8iQIQwdOpQPfvCD/PGPfwRg/PjxTJ06FYAjjzySF198sc35bNy4kQ0bNnD88ccDcO6553L//fe31njWWWdx8803U1aWvM+fNWsWF198Md/97nfZsGFD6/ju8B6EmfWI9t7pF9MZZ5zBkiVLePXVV5k7dy4At9xyC2vWrGHFihWUl5czbty4Ln2Z74UXXuDqq69m+fLljBw5kvPOO69bXwqsrKxsHS4tLe3wEFNbfve733H//ffzm9/8hiuuuIInnniC+fPn8973vpc77riDWbNmsWzZMg477LAu1woF7kFI+qykvZS4XtIjkt7drSWbmfWAuXPnsnjxYpYsWcIZZ5wBJO++9913X8rLy7nnnnt46aWX2p3Hcccdx89//nMAnnzySR5//HEA3nzzTYYMGcLw4cN57bXXuPPOO1unGTZsWOZx/mOPPZZf/epXbN26lS1btnD77bdz7LHHdvp5DR8+nJEjR7bufdx0000cf/zxNDc3s3r1ak488USuuuoqNm7cyObNm3nuueeYPHkyX/rSlzjqqKN45plnOr3MfIXuQfx9RHxH0t8BI4FzgJuAP3S7AjOzbpg0aRKbNm3igAMOYL/99gPgrLPO4v3vfz+TJ0+murq6w3fSn/zkJzn//POZMGECEyZM4MgjjwTgiCOOYNq0aRx22GGMHTuWWbNmtU5z4YUXcvLJJ7P//vtzzz33tI6fPn065513HjNmzADgYx/7GNOmTWv3cFJbFi1axCc+8Qm2bt3KwQcfzI033khTUxNnn302GzduJCL4zGc+w4gRI/ja177GPffcQ0lJCZMmTeKUU07p9PLyKSI67iQ9HhFTJH0HuDcibpf054iY1sF0JwPfAUqBn0bElXntlcDPgCOBdcDciHgxbZsC/BjYC2gGjoqINvftqquro6PPLZtZz3r66aeZMGFCX5dhBcr6e0laERHVWf0LPUm9QtIfgPcAyyQNI9lot0lSKbAAOAWYCJwpaWJetwuA9RFxCHAtcFU6bRlwM/CJiJgEnAA0FFirmZn1gEID4gJgPsm7+K1AOXB+B9PMAFZFxPMRsR1YDMzJ6zMHWJQOLwFmK/kc2ruBxyPiMYCIWBcRTQXWamZmPaDQgHgH8GxEbJB0NnAJsLGDaQ4AVuc8rk3HZfaJiMZ0nqOAtwEhaVl6QvyLWQuQdKGkGkk1a9asKfCpmJlZIQoNiB8CWyUdAXweeI7k3EGxlAHHAGelv0+TNDu/U0QsjIjqiKgePXp0EcsxM9vzFBoQjZGczZ4DfD8iFgDDOpjmZWBszuMx6bjMPul5h+EkJ6trgfsjYm16SOsOYDpmZtZrCg2ITZK+TPLx1t9JKiE5D9Ge5cChksZLqgDmAUvz+iwFzk2HTwfuToNoGTBZ0uA0OI4H2v/6opmZ9ahCA2IusI3k+xCvkuwN/Gt7E6TnFC4i2dg/DdwWESslXS7p1LTb9cAoSauAi0lOhBMR64FrSELmUeCRiPhdp56Zme32NmzYwA9+8IMuTdvZy3P3p8tw95aCvigXEa9KugU4StL7gD9FRIfnICLiDpLDQ7njLs0ZrgfOaGPam0k+6mpmlqklID71qU/t0tbY2Nju9YjuuOOONtssUeilNj4M/IlkY/5h4GFJ2XfaMDPrJfPnz+e5555j6tSpfOELX+Dee+/l2GOP5dRTT2XixORrVx/4wAc48sgjmTRpEgsXLmydtuXy3APxMty9pdBLbXyV5DsQrwNIGg3cRfLdBTMzuHM+vPpEz87zLZPhlCvbbL7yyit58sknefTRRwG49957eeSRR3jyyScZP348ADfccAN77703dXV1HHXUUXzoQx9i1KhRO81noF2Gu7cUeg6ipCUcUus6Ma2ZWa+ZMWNGazhA8q7+iCOOYObMmaxevZq//OUvu0wz0C7D3VsKrfT3kpYBv0gfzyXv3IKZ7eHaeaffm4YMGdI6fO+993LXXXfx4IMPMnjwYE444YTMy3UPtMtw95ZCT1J/QdKHgJZLGS6MiNuLV5aZWcfauuR2i40bNzJy5EgGDx7MM888w0MPPdTtZeZehvvYY4/NvAz3Mcccw+LFi9m8eTPr1q1j8uTJTJ48meXLl/PMM8/sXgEBEBG/BH5ZxFrMzDpl1KhRzJo1i8MPP5xTTjmF9773vTu1n3zyyfzoRz9iwoQJvP3tb2fmzJk9sty+vgx3b2n3ct+SNgFZHQREROxVrMI6y5f7Nut9vtz3wNLZy323uwcRER1dTsPMzHZT/iSSmZllckCYmVkmB4SZdUshty22vteVv5MDwsy6rKqqinXr1jkk+rmIYN26dZ3+FvfA+UqfmfU7Y8aMoba2Ft/Rsf+rqqpizJgxnZrGAWFmXVZeXr7TZS1s9+JDTGZmlskBYWZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmRwQZmaWqagBIelkSc9KWiVpfkZ7paRb0/aHJY1Lx4+TVCfp0fTnR8Ws08zMdlW0S21IKgUWAO8CaoHlkpZGxFM53S4A1kfEIZLmAVcBc9O25yJiarHqMzOz9hVzD2IGsCoino+I7cBiYE5enznAonR4CTBbkopYk5mZFaiYAXEAsDrncW06LrNPRDQCG4FRadt4SX+WdJ+kY7MWIOlCSTWSanw1STOzntVfT1L/FTgwIqYBFwM/l7RXfqeIWBgR1RFRPXr06F4v0sxsd1bMgHgZGJvzeEw6LrOPpDJgOLAuIrZFxDqAiFgBPAe8rYi1mplZnmIGxHLgUEnjJVUA84CleX2WAuemw6cDd0dESBqdnuRG0sHAocDzRazVzMzyFO1TTBHRKOkiYBlQCtwQESslXQ7URMRS4HrgJkmrgDdIQgTgOOBySQ1AM/CJiHijWLWamdmutLvcS7a6ujpqamr6ugwzswFF0oqIqM5q668nqc3MrI85IMzMLJMDwszMMjkgzMwskwPCzMwyOSDMzCyTA8LMzDI5IMzMLJMDwszMMjkgzMwskwPCzMwyOSDMzCyTA8LMzDI5IMzMLJMDwszMMjkgzMwskwPCzMwyOSDMzCyTA8LMzDI5IMzMLJMDwszMMjkgzMwsU1EDQtLJkp6VtErS/Iz2Skm3pu0PSxqX136gpM2S/qmYdZqZ2a6KFhCSSoEFwCnAROBMSRPzul0ArI+IQ4Brgavy2q8B7ixWjWZm1rZi7kHMAFZFxPMRsR1YDMzJ6zMHWJQOLwFmSxKApA8ALwAri1ijmZm1oZgBcQCwOudxbTous09ENAIbgVGShgJfAr7R3gIkXSipRlLNmjVreqxwMzPrvyepLwOujYjN7XWKiIURUR0R1aNHj+6dyszM9hBlRZz3y8DYnMdj0nFZfWollQHDgXXA0cDpkr4NjACaJdVHxPeLWK+ZmeUoZkAsBw6VNJ4kCOYBH8nrsxQ4F3gQOB24OyICOLalg6TLgM0OBzOz3lW0gIiIRkkXAcuAUuCGiFgp6XKgJiKWAtcDN0laBbxBEiJmZtYPKHnDPvBVV1dHTU1NX5dhZiwKwwQAAAnxSURBVDagSFoREdVZbf31JLWZmfUxB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZpqIGhKSTJT0raZWk+RntlZJuTdsfljQuHT9D0qPpz2OSTitmnWZmtquiBYSkUmABcAowEThT0sS8bhcA6yPiEOBa4Kp0/JNAdURMBU4GfiyprFi1mpnZroq5BzEDWBURz0fEdmAxMCevzxxgUTq8BJgtSRGxNSIa0/FVQBSxTjMzy1DMd+UHAKtzHtcCR7fVJyIaJW0ERgFrJR0N3AAcBJyTExitJF0IXAhw4IEH9vgT2GM0NcL2zbB9S/J72+b0ccvwpqStdfwWIEAlO/+gnMfatX2X8Rl9yB/X0eO88btMnzVtB33anUfL9O30IWs5Sle2diwDcpZXYHtrP7Pi67eHbSLiYWCSpAnAIkl3RkR9Xp+FwEKA6urqPWcvo6kBtm3K26Dnb8SzNvSbc/psSn9vgca6AhcsqBgKFYOTjV40Z/zQxvj0xzuDPaSLAdNmO92cvq12uj595riO5lFgW27Qdmv6/PDuidoy/hYdTb/fVJh2Fj2tmAHxMjA25/GYdFxWn9r0HMNwYF1uh4h4WtJm4HCgpnjlFlHjtgLeledvxDfljNuy8wa9aVthy1VJukEfCpXp74ohMGLsjuHKoVAxLP09JO07LHu4fDCU9MBRyYj2Q6S1vY1+REbfrOnb6UNH07VVY7QzfVv1N+143kT6m5zhyGung/aOpm+vnW5O31473Zw+2hjXXlt0oo0dbS1/n27Nky5O19bfvMDpstZfQ92AC4jlwKGSxpMEwTzgI3l9lgLnAg8CpwN3R0Sk06xODzsdBBwGvFjEWneIgMb6At6Jd7RB37zjXX5zQ2HLVmn2Bnvovrtu0FuH8zfoQ3eEQvmg/nlIQkqeK6V9XYmZtaNoAZFu3C8ClpFsCW6IiJWSLgdqImIpcD1wk6RVwBskIQJwDDBfUgPQDHwqItYWpdBXn4Qlf7/zBr/lHV9HSivSDXPOBr1yGOy1X8Y79zaGc8eVVfbPDbqZ7ZGKeg4iIu4A7sgbd2nOcD1wRsZ0NwE3FbO2VhVDYN/D8jbcuRv9nA1//nBZRa+UaGbWF/rtSepes/d4+PDP+roKM7N+x5faMDOzTA4IMzPL5IAwM7NMDggzM8vkgDAzs0wOCDMzy+SAMDOzTA4IMzPLpMi9iNUAJmkN8FI3ZrEPUJzLeXSP6+oc19U5rqtzdse6DoqI0VkNu01AdJekmoio7us68rmuznFdneO6OmdPq8uHmMzMLJMDwszMMjkgdljY1wW0wXV1juvqHNfVOXtUXT4HYWZmmbwHYWZmmRwQZmaWaY8KCEknS3pW0ipJ8zPaKyXdmrY/LGlcP6nrPElrJD2a/nysl+q6QdLrkp5so12SvpvW/bik6f2krhMkbcxZX5dm9StCXWMl3SPpKUkrJX02o0+vr7MC6+r1dSapStKfJD2W1vWNjD69/possK6+ek2WSvqzpN9mtPX8uoqIPeKH5L7YzwEHAxXAY8DEvD6fAn6UDs8Dbu0ndZ0HfL8P1tlxwHTgyTba3wPcCQiYCTzcT+o6AfhtH6yv/YDp6fAw4H8y/pa9vs4KrKvX11m6Doamw+XAw8DMvD598ZospK6+ek1eDPw8629VjHW1J+1BzABWRcTzEbEdWAzMyeszB1iUDi8BZktSP6irT0TE/cAb7XSZA/wsEg8BIyTt1w/q6hMR8deIeCQd3gQ8DRyQ163X11mBdfW6dB1sTh+Wpz/5n5rp9ddkgXX1OkljgPcCP22jS4+vqz0pIA4AVuc8rmXXF0lrn4hoBDYCo/pBXQAfSg9JLJE0tsg1FarQ2vvCO9JDBHdKmtTbC09376eRvPvM1afrrJ26oA/WWXrI5FHgdeA/IqLN9dWLr8lC6oLef01eB3wRaG6jvcfX1Z4UEAPZb4BxETEF+A92vEuwbI+QXF/mCOB7wK96c+GShgK/BD4XEW/25rLb00FdfbLOIqIpIqYCY4AZkg7vjeV2pIC6evU1Kel9wOsRsaKYy8m3JwXEy0Buyo9Jx2X2kVQGDAfW9XVdEbEuIralD38KHFnkmgpVyDrtdRHxZsshgoi4AyiXtE9vLFtSOclG+JaI+PeMLn2yzjqqqy/XWbrMDcA9wMl5TX3xmuywrj54Tc4CTpX0Islh6HdKujmvT4+vqz0pIJYDh0oaL6mC5CTO0rw+S4Fz0+HTgbsjPePTl3XlHaM+leQYcn+wFPho+smcmcDGiPhrXxcl6S0tx14lzSD5Py/6RiVd5vXA0xFxTRvden2dFVJXX6wzSaMljUiHBwHvAp7J69brr8lC6urt12REfDkixkTEOJJtxN0RcXZetx5fV2XdmXggiYhGSRcBy0g+OXRDRKyUdDlQExFLSV5EN0laRXISdF4/qeszkk4FGtO6zit2XQCSfkHy6ZZ9JNUCXyc5YUdE/Ai4g+RTOauArcD5/aSu04FPSmoE6oB5vRD0kLzLOwd4Ij1+DfAV4MCc2vpinRVSV1+ss/2ARZJKSQLptoj4bV+/Jgusq09ek/mKva58qQ0zM8u0Jx1iMjOzTnBAmJlZJgeEmZllckCYmVkmB4SZmWVyQJj1ESVXUN3lqpxm/YUDwszMMjkgzDog6ez0/gCPSvpxeiG3zZKuTe8X8J+SRqd9p0p6KL2I2+2SRqbjD5F0V3oxvEckvTWd/dD0Ym/PSLol59vMVyq5f8Pjkq7uo6duezgHhFk7JE0A5gKz0ou3NQFnAUNIvsE6CbiP5NvcAD8DvpRexO2JnPG3AAvSi+H9LdByeY1pwOeAiST3BJklaRRwGjApnc83i/sszbI5IMzaN5vkQmzL08tUzCbZkDcDt6Z9bgaOkTQcGBER96XjFwHHSRoGHBARtwNERH1EbE37/CkiaiOiGXgUGEdymeZ64HpJHyS5JIdZr3NAmLVPwKKImJr+vD0iLsvo19Vr1mzLGW4CytJr+c8guenL+4Dfd3HeZt3igDBr338Cp0vaF0DS3pIOInntnJ72+QjwQERsBNZLOjYdfw5wX3oXt1pJH0jnUSlpcFsLTO/bMDy97PY/AkcU44mZdWSPuZqrWVdExFOSLgH+IKkEaAA+DWwhuZHMJSR3HZubTnIu8KM0AJ5nx9VazwF+nF59swE4o53FDgN+LamKZA/m4h5+WmYF8dVczbpA0uaIGNrXdZgVkw8xmZlZJu9BmJlZJu9BmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWab/D7jRV2MzLLs2AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "tl = np.array(train_loss).T\n",
        "vl = np.array(val_loss).T\n",
        "plt.plot(vl[0], vl[1], label=\"validation loss\")\n",
        "plt.plot(tl[0], tl[1], label=\"train loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training and Validation Loss for Epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "WmzYS6jZ7XwC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "65473395-0158-4294-f3d8-f6e21438193e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ninput shape: torch.Size([128, 20, 3])\\noutput shape: torch.Size([5, 128, 1])\\nenc out shape: torch.Size([128, 20, 64])\\ndec inp shape: torch.Size([128, 3])\\ndec hidden inp shape: torch.Size([32, 64])\\ndec hidden size: torch.Size([32, 20, 64])\\ndec out size: torch.Size([128, 3])\\nfinal dec out size: torch.Size([128, 1])\\ndec hidden size: torch.Size([32, 20, 64])\\ndec out size: torch.Size([128, 3])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 124
        }
      ],
      "source": [
        "def predict_tensor_seq_to_seq(model: seq2seq_lstm, inp_tensor, target_len: int):\n",
        "    \"\"\"predicts the output for a specific input\n",
        "\n",
        "    Args:\n",
        "        model (seq2seq_lstm): the model\n",
        "        inp_tensor (tensor): input tensor that is already normalized\n",
        "        target_len (int): the target prediction length\n",
        "\n",
        "    Returns:\n",
        "        numpy array of outputs: the predicted seq for the specifed price\n",
        "    \"\"\"\n",
        "    inp_tensor = inp_tensor.unsqueeze(0)  # add in batch size of 1\n",
        "    #print(\"input_tensor shape:\",inp_tensor.shape)\n",
        "    model.train(False)\n",
        "    enc_out, enc_hidden = model.enc(inp_tensor)\n",
        "    \n",
        "    #print(\"input_tensor shape:\",inp_tensor.shape)\n",
        "    outputs = torch.zeros(Data_Prep.predict,1,len(Data_Prep.output_data_cols)).to(Model_Info.device)\n",
        "    #print(\"output_tensor shape:\",outputs.shape)\n",
        "    dec_hidden_inp = ((enc_hidden[0][:,-1,:]).contiguous(),(enc_hidden[1][:,-1,:]).contiguous())\n",
        "    dec_inp = (inp_tensor[:,-1,:])\n",
        "    for t in range(target_len):\n",
        "        final_dec_out, dec_out, dec_hidden_inp = model.dec(dec_inp, dec_hidden_inp)\n",
        "        #print(final_dec_out.shape)\n",
        "        #print(dec_out.shape)\n",
        "        outputs[t] = final_dec_out.squeeze()  # collapse the 1 batch size\n",
        "        dec_inp = dec_out.contiguous()  # move over the input\n",
        "    #print(\"final output shape:\",outputs.squeeze(1).shape)\n",
        "    np_out = outputs.cpu().data.numpy()\n",
        "    return np_out\n",
        "\n",
        "\"\"\"\n",
        "input_tensor shape: torch.Size([20, 1, 3])\n",
        "input_tensor shape: torch.Size([20, 1, 3])\n",
        "output_tensor shape: torch.Size([5, 1, 1])\n",
        "torch.Size([20, 1])\n",
        "torch.Size([20, 3])\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "input shape: torch.Size([128, 20, 3])\n",
        "output shape: torch.Size([5, 128, 1])\n",
        "enc out shape: torch.Size([128, 20, 64])\n",
        "dec inp shape: torch.Size([128, 3])\n",
        "dec hidden inp shape: torch.Size([32, 64])\n",
        "dec hidden size: torch.Size([32, 20, 64])\n",
        "dec out size: torch.Size([128, 3])\n",
        "final dec out size: torch.Size([128, 1])\n",
        "dec hidden size: torch.Size([32, 20, 64])\n",
        "dec out size: torch.Size([128, 3])\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ltSD7q4KetEL"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "AwXaqnis7XwD",
        "outputId": "8d598460-7ace-4c1b-f31e-e7bb7a54074a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('001', 'Asia Pacific & ANZ', 'Channel - Industrial')\n",
            "(394, 20, 3)\n",
            "(394, 5, 1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-186-bd9599146e84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#print(\"pred shape:\", pred.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#print(pred.squeeze(1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpred_inv_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_transformations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m#print(\"pred inv shape:\", pred_inv_t.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'detach'"
          ]
        }
      ],
      "source": [
        "for key, val in enumerate(transformed_data):\n",
        "    # print(val)\n",
        "    x, y = prep_data(\n",
        "        transformed_data[val], Data_Prep.lookback, Data_Prep.predict, Data_Prep.input_data_cols, Data_Prep.output_data_cols)\n",
        "    print(val)\n",
        "    print(x.shape)\n",
        "    print(y.shape)\n",
        "    index_graphing = 0\n",
        "    \n",
        "    all_pred_data = []\n",
        "    all_actual_data = []\n",
        "    verbose = False\n",
        "    # x_axis = np.array(transformed_data[val][\"year_week_ordered\"][i+len(x[1]):i+len(x[1])+Data_Prep.predict])\n",
        "    for i in range(len(x)):\n",
        "        \n",
        "        model_inp = torch.from_numpy(x[i]).float().to(Model_Info.device)\n",
        "        \n",
        "        #print(model_inp.shape)\n",
        "        if model_name == \"basic_lstm\":\n",
        "            \n",
        "            pred = model(model_inp[None, :])\n",
        "            pred = torch.unsqueeze(pred,1)\n",
        "        else:\n",
        "            pred = predict_tensor_seq_to_seq(model, model_inp, Data_Prep.predict)\n",
        "        #print(\"pred shape:\", pred.shape)\n",
        "        #print(pred.squeeze(1))\n",
        "        pred_inv_t = output_transformations[val].inverse_transform(pred.squeeze(1))\n",
        "        #print(\"pred inv shape:\", pred_inv_t.shape)\n",
        "        \n",
        "        \n",
        "        actual_in_t = reg_data[val][\"sales_amount\"][i + len(x[1]):i+len(x[1])+Data_Prep.predict]\n",
        "\n",
        "        all_pred_data.append(np.squeeze(pred_inv_t,1)[0])\n",
        "        all_actual_data.append(actual_in_t)\n",
        "        \n",
        "        #print(actual_in_t.shape)\n",
        "        if verbose:\n",
        "            print(\"actual pred data:\", pred)\n",
        "            print(\"actual pred data:\",pred_inv_t)\n",
        "            print(\"actual data:\", actual_in_t)\n",
        "            print(\"shape\", y[i].shape)\n",
        "            \n",
        "        # plt.plot(x_axis, pred_inv_t.T[0], label=\"pred 0\")\n",
        "        # plt.plot(x_axis, input_transformations[val].inverse_transform(y[i]).T[0], label=\"act 0\")\n",
        "        # plt.plot(x_axis,pred_inv_t.T[1],label=\"pred 1\")\n",
        "        # plt.plot(x_axis,transformations[val].inverse_transform(y[i]).T[1],label = \"act 1\")\n",
        "        # plt.plot(x_axis,pred_inv_t.T[2],label=\"pred 2\")\n",
        "        # plt.plot(x_axis,transformations[val].inverse_transform(y[i]).T[2],label = \"act 2\")\n",
        "    plt.plot(all_pred_data, label=\"pred\")\n",
        "    plt.plot(all_actual_data, label=\"actual\")\n",
        "    plt.legend()\n",
        "    plt.title(f\"{Data_Prep.input_data_cols[index_graphing]} predicted vs actual\")\n",
        "    plt.ylabel(Data_Prep.input_data_cols[index_graphing])\n",
        "    plt.xlabel(\"batches\")\n",
        "    plt.show()\n",
        "\n",
        "    # print(x.shape)\n",
        "    # print(y.shape)\n",
        "    # print(transformations[val])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "CS7DAed07XwD",
        "outputId": "024f2bc9-6ab6-4ccf-efb8-56ef6120c2bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sales_amount', 'sales_quantity', 'Price']\n",
            "['sales_amount']\n",
            "\n",
            "\n",
            "('001', 'Asia Pacific & ANZ', 'Channel - Industrial')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     fiscal_year_historical  fiscal_quarter_historical  \\\n",
              "0                      2015                          1   \n",
              "1                      2015                          1   \n",
              "2                      2015                          1   \n",
              "3                      2015                          1   \n",
              "4                      2015                          1   \n",
              "..                      ...                        ...   \n",
              "413                    2022                          4   \n",
              "414                    2022                          4   \n",
              "415                    2022                          4   \n",
              "416                    2022                          4   \n",
              "417                    2022                          4   \n",
              "\n",
              "     fiscal_month_historical  fiscal_week_historical business_unit_group_name  \\\n",
              "0                          1                       1     Channel - Industrial   \n",
              "1                          1                       2     Channel - Industrial   \n",
              "2                          1                       3     Channel - Industrial   \n",
              "3                          1                       4     Channel - Industrial   \n",
              "4                          2                       5     Channel - Industrial   \n",
              "..                       ...                     ...                      ...   \n",
              "413                       12                      49     Channel - Industrial   \n",
              "414                       12                      50     Channel - Industrial   \n",
              "415                       12                      51     Channel - Industrial   \n",
              "416                       12                      52     Channel - Industrial   \n",
              "417                       12                      53     Channel - Industrial   \n",
              "\n",
              "    company_region_name_level_1 product_line_code      product_line_name  \\\n",
              "0            Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "1            Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "2            Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "3            Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "4            Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "..                          ...               ...                    ...   \n",
              "413          Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "414          Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "415          Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "416          Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "417          Asia Pacific & ANZ               001  Miscellaneous AMPMODU   \n",
              "\n",
              "     sales_quantity  sales_amount  year_week_ordered     Price  \n",
              "0          0.307948      0.093309             201501  0.018802  \n",
              "1          0.409376      0.129342             201502  0.018802  \n",
              "2          0.409376      0.129342             201503  0.018802  \n",
              "3          0.443185      0.141354             201504  0.018802  \n",
              "4          0.321262      0.125958             201505  0.060800  \n",
              "..              ...           ...                ...       ...  \n",
              "413        0.782539      0.437068             202249  0.132730  \n",
              "414        0.872838      0.488609             202250  0.132730  \n",
              "415        0.782539      0.437068             202251  0.132730  \n",
              "416        0.963136      0.540150             202252  0.132730  \n",
              "417        0.963136      0.540150             202253  0.132730  \n",
              "\n",
              "[418 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54b18ad0-054e-4322-8d22-2dd5a07b8ea2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fiscal_year_historical</th>\n",
              "      <th>fiscal_quarter_historical</th>\n",
              "      <th>fiscal_month_historical</th>\n",
              "      <th>fiscal_week_historical</th>\n",
              "      <th>business_unit_group_name</th>\n",
              "      <th>company_region_name_level_1</th>\n",
              "      <th>product_line_code</th>\n",
              "      <th>product_line_name</th>\n",
              "      <th>sales_quantity</th>\n",
              "      <th>sales_amount</th>\n",
              "      <th>year_week_ordered</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.307948</td>\n",
              "      <td>0.093309</td>\n",
              "      <td>201501</td>\n",
              "      <td>0.018802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.409376</td>\n",
              "      <td>0.129342</td>\n",
              "      <td>201502</td>\n",
              "      <td>0.018802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.409376</td>\n",
              "      <td>0.129342</td>\n",
              "      <td>201503</td>\n",
              "      <td>0.018802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.443185</td>\n",
              "      <td>0.141354</td>\n",
              "      <td>201504</td>\n",
              "      <td>0.018802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.321262</td>\n",
              "      <td>0.125958</td>\n",
              "      <td>201505</td>\n",
              "      <td>0.060800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>49</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.782539</td>\n",
              "      <td>0.437068</td>\n",
              "      <td>202249</td>\n",
              "      <td>0.132730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>50</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.872838</td>\n",
              "      <td>0.488609</td>\n",
              "      <td>202250</td>\n",
              "      <td>0.132730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>51</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.782539</td>\n",
              "      <td>0.437068</td>\n",
              "      <td>202251</td>\n",
              "      <td>0.132730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>52</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.963136</td>\n",
              "      <td>0.540150</td>\n",
              "      <td>202252</td>\n",
              "      <td>0.132730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>53</td>\n",
              "      <td>Channel - Industrial</td>\n",
              "      <td>Asia Pacific &amp; ANZ</td>\n",
              "      <td>001</td>\n",
              "      <td>Miscellaneous AMPMODU</td>\n",
              "      <td>0.963136</td>\n",
              "      <td>0.540150</td>\n",
              "      <td>202253</td>\n",
              "      <td>0.132730</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>418 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54b18ad0-054e-4322-8d22-2dd5a07b8ea2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54b18ad0-054e-4322-8d22-2dd5a07b8ea2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54b18ad0-054e-4322-8d22-2dd5a07b8ea2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "source": [
        "data_filter = ['Channel - Industrial']\n",
        "reg_data, transformed_data, input_transformations, output_transformations = transform_norm_rem_out(\n",
        "    grouped_df, Data_Prep.input_data_cols, Data_Prep.output_data_cols, data_filter)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nkenQkV7XwD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWNSNKMt7XwD",
        "outputId": "3a420b57-4fb2-45d9-e6ea-c9b32ec7e554"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(398, 20, 3)\n",
            "(398, 1, 1)\n",
            "(20, 3)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 3 and the array at index 1 has size 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-adddb113e17b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_np_inp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mmodel_np_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_np_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloc_sales_amt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_np_inp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mmodel_np_inp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc_sales_amt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_np_inp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc_sales_amt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mappend\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   4669\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4670\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4671\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 3 and the array at index 1 has size 1"
          ]
        }
      ],
      "source": [
        "loc_sales_amt = 0;\n",
        "for key, val in enumerate(transformed_data):\n",
        "    # print(val)\n",
        "    x, y = prep_data(\n",
        "        transformed_data[val], Data_Prep.lookback, Data_Prep.predict, Data_Prep.input_data_cols, Data_Prep.output_data_cols)\n",
        "    print(x.shape)\n",
        "    print(y.shape)\n",
        "    index_graphing = 0\n",
        "    \n",
        "    all_pred_data = []\n",
        "    all_actual_data = []\n",
        "    verbose = False\n",
        "    # x_axis = np.array(transformed_data[val][\"year_week_ordered\"][i+len(x[1]):i+len(x[1])+Data_Prep.predict])\n",
        "    \n",
        "    model_np_inp = x[0]\n",
        "    for i in range(len(x)):\n",
        "        #print(model_np_inp.shape)\n",
        "        if i != 0:\n",
        "            print(model_np_inp.shape)\n",
        "            model_np_inp = np.append(model_np_inp, pred.detach().cpu(),axis = loc_sales_amt)\n",
        "            print(model_np_inp.shape)\n",
        "            model_np_inp[loc_sales_amt] = model_np_inp[loc_sales_amt][1:]\n",
        "            print(model_np_inp.shape)\n",
        "        #model_inp = torch.unsqueeze(torch.from_numpy(model_np_inp).float().to(Model_Info.device),1)\n",
        "        #print(\"model np inp\", model_np_inp.shape)\n",
        "        #print(\"model_inp shape\", model_inp.shape)\n",
        "        if model_name == \"basic_lstm\":\n",
        "            \n",
        "            pred = model(model_inp[None, :])\n",
        "            pred = torch.unsqueeze(pred,1)\n",
        "        else:\n",
        "            pred = predict_tensor_seq_to_seq(model, model_inp, Data_Prep.predict)\n",
        "        #print(pred)\n",
        "        #print(\"pred shape:\", pred.shape)\n",
        "        pred_inv_t = output_transformations[val].inverse_transform(pred.detach().cpu())\n",
        "        #print(\"pred inv shape:\", pred_inv_t.shape)\n",
        "        \n",
        "        \n",
        "        actual_in_t = reg_data[val][\"sales_amount\"][i + len(x[1]):i+len(x[1])+Data_Prep.predict]\n",
        "\n",
        "        all_pred_data.append(np.squeeze(pred_inv_t,1)[0])\n",
        "        all_actual_data.append(actual_in_t)\n",
        "        \n",
        "        #print(actual_in_t.shape)\n",
        "        if verbose:\n",
        "            print(\"actual pred data:\", pred)\n",
        "            print(\"actual pred data:\",pred_inv_t)\n",
        "            print(\"actual data:\", actual_in_t)\n",
        "            print(\"shape\", y[i].shape)\n",
        "            \n",
        "        #plt.plot(x_axis, pred_inv_t.T[0], label=\"pred 0\")\n",
        "        \n",
        "        #plt.plot(x_axis, input_transformations[val].inverse_transform(y[i]).T[0], label=\"act 0\")\n",
        "        # plt.plot(x_axis,pred_inv_t.T[1],label=\"pred 1\")\n",
        "        # plt.plot(x_axis,transformations[val].inverse_transform(y[i]).T[1],label = \"act 1\")\n",
        "        # plt.plot(x_axis,pred_inv_t.T[2],label=\"pred 2\")\n",
        "        # plt.plot(x_axis,transformations[val].inverse_transform(y[i]).T[2],label = \"act 2\")\n",
        "    plt.plot(all_pred_data, label=\"pred\")\n",
        "    plt.plot(all_actual_data, label=\"actual\")\n",
        "    plt.legend()\n",
        "    plt.title(f\"{Data_Prep.input_data_cols[index_graphing]} predicted vs actual\")\n",
        "    plt.ylabel(Data_Prep.input_data_cols[index_graphing])\n",
        "    plt.xlabel(\"batches\")\n",
        "    plt.show()\n",
        "\n",
        "    # print(x.shape)\n",
        "    # print(y.shape)\n",
        "    # print(transformations[val])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkbd-OIV7XwD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRuw85ay7XwD",
        "outputId": "a9ae27db-c025-408c-94f6-1fe8a4a2c1c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(398, 20, 3)\n",
            "(398, 1, 1)\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'predict_tensor' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-fd83625adf1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             transformed_data[val][\"year_week_ordered\"][i+len(x[1]):i+len(x[1])+Data_Prep.predict])\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel_Info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mData_Prep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pred shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predict_tensor' is not defined"
          ]
        }
      ],
      "source": [
        "for key, val in enumerate(transformed_data):\n",
        "    # print(val)\n",
        "    x, y = prep_data(\n",
        "        transformed_data[val], Data_Prep.lookback, Data_Prep.predict, Data_Prep.input_data_cols, Data_Prep.output_data_cols)\n",
        "    print(x.shape)\n",
        "    print(y.shape)\n",
        "    index_graphing = 0\n",
        "    for i in range(len(x)):\n",
        "        x_axis = np.array(\n",
        "            transformed_data[val][\"year_week_ordered\"][i+len(x[1]):i+len(x[1])+Data_Prep.predict])\n",
        "        model_inp = torch.from_numpy(x[i]).float().to(Model_Info.device)\n",
        "        pred = predict_tensor(model, model_inp, Data_Prep.predict)\n",
        "        print(pred)\n",
        "        print(\"pred shape:\", pred.shape)\n",
        "        pred_inv_t = input_transformations[val].inverse_transform(pred)\n",
        "        print(\"pred inv shape:\", pred_inv_t.shape)\n",
        "        print(\"x_axis shape:\", x_axis.shape)\n",
        "        actual_in_t = reg_data[val][\"sales_amount\"][i +\n",
        "                                                    len(x[1]):i+len(x[1])+Data_Prep.predict]\n",
        "        print(actual_in_t.shape)\n",
        "        print(\"actual data:\", actual_in_t)\n",
        "        plt.plot(x_axis, pred_inv_t.T[0], label=\"pred 0\")\n",
        "        print(\"shape\", y[i].shape)\n",
        "        plt.plot(x_axis, input_transformations[val].inverse_transform(\n",
        "            y[i]).T[0], label=\"act 0\")\n",
        "        # plt.plot(x_axis,pred_inv_t.T[1],label=\"pred 1\")\n",
        "        # plt.plot(x_axis,input_transformations[val].inverse_transform(y[i]).T[1],label = \"act 1\")\n",
        "        # plt.plot(x_axis,pred_inv_t.T[2],label=\"pred 2\")\n",
        "        # plt.plot(x_axis,input_transformations[val].inverse_transform(y[i]).T[2],label = \"act 2\")\n",
        "\n",
        "        plt.plot(x_axis, actual_in_t, label=\"actual\")\n",
        "        if i == 2:\n",
        "            print(\"BREAKING\")\n",
        "            break\n",
        "        plt.legend()\n",
        "        plt.title(f\"{input_data_cols[index_graphing]} predicted vs actual\")\n",
        "        plt.ylabel(input_data_cols[index_graphing])\n",
        "        plt.xlabel(\"batches\")\n",
        "        plt.show()\n",
        "\n",
        "    # print(x.shape)\n",
        "    # print(y.shape)\n",
        "    # print(input_transformations[val])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQZpn44o7XwE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}